{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-58ac44785124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpymongo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import pymongo\n",
    "import json\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient('54.201.199.246', 27016)\n",
    "\n",
    "wiki_db = client.wikipedia\n",
    "\n",
    "wiki_col = wiki_db.my_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1636"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_col.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_cursor = wiki_col.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'*': '{{Multiple issues|{{refimprove|date=July 2017}}{{more footnotes|date=July 2017}}}}\\n\\n\\'\\'\\'Data exploration\\'\\'\\' is an approach similar to initial data analysis, whereby a data analyst uses visual exploration to understand what is in a dataset and the characteristics of the data, rather than through traditional data management systems<ref name=\"Foster\">[https://www.fosteropenscience.eu/sites/default/files/pdf/2933.pdf FOSTER Open Science], Overview of Data Exploration Techniques: Stratos Idreos, Olga Papaemmonouil, Surajit Chaudhuri.</ref>. These characteristics can include size or amount of data, completeness of the data, correctness of the data, possible relationships amongst data elements or files/tables in the data.\\n\\nData exploration is typically conducted using a combination of automated and manual activities.<ref name=\"Foster\" /><ref name=\"Stanford2011\">[http://vis.stanford.edu/files/2011-Wrangler-CHI.pdf Stanford.edu], 2011 Wrangler: Interactive Visual Specification of Data Transformation Scripts, Kandel, Paepcke, Hellerstein Heer.</ref> Automated activities can include data profiling or data visualization or tabular reports to give the analyst an initial view into the data and an understanding of key characteristics.\\n\\nThis is often followed by manual drill-down or filtering of the data to identify anomalies or patterns identified through the automated actions.  Data exploration can also require manual scripting and queries into the data (e.g. using languages such as SQL or R) or using Excel or similar tools to view the raw data.<ref name=\"Stanford2012\">[http://vis.stanford.edu/files/2012-EnterpriseAnalysisInterviews-VAST.pdf Stanford.edu], IEEE Visual Analytics Science & Technology (VAST), Oct 2012 Enterprise Data Analysis and Visualization: An Interview Study., Sean Kandel, Andreas Paepcke, Joseph Hellerstein, Jeffrey Heer Proc.</ref>\\n\\nAll of these activities are aimed at creating a clear mental model and understanding of the data in the mind of the analyst, and defining basic metadata (statistics, structure, relationships) for the data set that can be used in further analysis.\\n\\nOnce this initial understanding of the data is had, the data can be pruned or refined by removing unusable parts of the data, correcting poorly formatted elements and defining relevant relationships across datasets<ref name=\"Stanford2011\" />. This process is also known as determining [[data quality]]<ref name=\"Stanford2012\" />.\\n\\nAt this stage, the data can be considered ready for deeper analysis or be handed off to other analysts or users who have specific needs for the data.\\n\\nData exploration can also refer to the adhoc querying and visualization of data to identify potential relationships or insights that may be hidden in the data<ref name=\"Foster\" />.  In this scenario, hypotheses may be created and then the data is explored to identify whether those hypotheses are correct. \\n\\nTraditionally, this had been a key area of focus for statisticians, with [[John Tukey]] being a key evangelist in the field. Today, data exploration is more widespread and is the focus of data analysts and [[data scientists]]; the latter being a relatively new role within enterprises and larger organizations.\\n\\n== Interactive Data Exploration ==\\nThis area of data exploration has become an area of interest in the field of machine learning. This is a relatively new field and is still evolving.<ref name=\"Stanford2012\" />  As it’s most basic level, a machine-learning algorithm can be fed a data set and can be used to identify whether a hypothesis is true based on the dataset. Common machine learning algorithms can focus on identifying specific patterns in the data.<ref name=\"Stanford2011\" /> Common patterns include regression, classification or clustering, but there are many possible patterns and algorithms that can be applied to data via machine learning.\\n\\nBy employing machine learning, it is possible to find patterns or relationships in the data that would be difficult or impossible to find via manual inspection, trial and error or traditional exploration techniques.\\n\\n==Software==\\n* [[Trifacta]] – a data preparation and analysis platform\\n* [[Paxata]] – self-service data preparation software\\n* [[Alteryx]] – data blending and advanced data analytics software\\n* IBM Infosphere Analyzer – a data profiling tool\\n* Microsoft [[Power BI]] -  interactive visualization and data analysis tool\\n* [[OpenRefine]] -  a standalone open source desktop application for data clean-up and data transformation \\n* [[Tableau software]] – interactive data visualization software\\n\\n==See also==\\n{{Portal|Information technology}}\\n* [[Exploratory Data Analysis]]\\n* [[Machine Learning]]\\n* [[Data profiling]]\\n* [[Data Visualization]]\\n{{-}}\\n\\n== References ==\\n{{reflist}}\\n\\n[[Category:Machine learning| ]]\\n[[Category:Data analysis]]\\n[[Category:Data management]]\\n[[Category:Data quality]]',\n",
       " 'contentformat': 'text/x-wiki',\n",
       " 'contentmodel': 'wikitext'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(wiki_cursor)['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
