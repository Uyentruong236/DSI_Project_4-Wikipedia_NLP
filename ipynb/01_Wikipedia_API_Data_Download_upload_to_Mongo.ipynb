{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import pymongo\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient('54.201.199.246', 27016)\n",
    "\n",
    "wiki_db = client.wikipedia\n",
    "\n",
    "wiki_col = wiki_db.my_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions to get data from Wiki API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def category_request(category):\n",
    "    \"\"\"\n",
    "    Scrape a category page from Wikipedia API.\n",
    "    \n",
    "    Params:\n",
    "    --------\n",
    "    category: str\n",
    "        The name of the category to be scraped.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame\n",
    "        Pandas DataFrame containing categories \n",
    "        \n",
    "    \"\"\"\n",
    "    my_params = {\n",
    "        'action':'query',\n",
    "        'format':'json',\n",
    "        'list':'categorymembers',\n",
    "        'cmtitle': 'Category:{}'.format(category),\n",
    "        'cmlimit': 'max'\n",
    "        }\n",
    "    page = requests.get('http://en.wikipedia.org/w/api.php', params=my_params)\n",
    "    return pd.DataFrame(page.json()['query']['categorymembers'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(title):\n",
    "    \"\"\"\n",
    "    Scrape a page from Wikipedia API to get the conecnt.\n",
    "    \n",
    "    Params:\n",
    "    --------\n",
    "    title: str\n",
    "        The name of the page to be scraped.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    List of dictionaries\n",
    "        list of the content of the page\n",
    "        \n",
    "    \"\"\"\n",
    "    my_params = {\n",
    "        'action':'query',\n",
    "        'format':'json',\n",
    "        'titles': title,\n",
    "        'prop': 'revisions',\n",
    "        'rvprop': 'content'\n",
    "    }\n",
    "    content = requests.get('http://en.wikipedia.org/w/api.php', params=my_params)\n",
    "    return list(content.json()['query']['pages'].values())[0]['revisions'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cats_and_pages(category):\n",
    "    \"\"\"\n",
    "    Returns the pages and subcategories of a category\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    category : str\n",
    "        Name of a category\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sub_categories: list \n",
    "        list of sub categories \n",
    "    pages: list\n",
    "        list of pages on the category\n",
    "        \n",
    "    \"\"\"\n",
    "    cats = pd.DataFrame(category_request(category))\n",
    "    cats['title'] = cats.title.astype(str) \n",
    "    #returns a boolean mask of all titles with 'category' in the str\n",
    "    subs_mask = cats['title'].str.contains('Category:')\n",
    "    \n",
    "    #creates list of new sub catagories\n",
    "    children = list(cats['title'][subs_mask].str.replace('Category:', \"\"))\n",
    "    pages = list(cats['title'][~cats.title.str.contains('Category:')])\n",
    "    page_id = list(cats['pageid'][~cats.title.str.contains('Category:')])\n",
    "    return page_id, pages, children\n",
    "\n",
    "#sub_categories, pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_traverse(category):\n",
    "    \"\"\" \n",
    "    Returns a list of dictionary of categories, page titles and page contents\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    category : str\n",
    "        Name of a category\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    page_content: list \n",
    "        list of dictionaries with categories, page titles and page contents \n",
    "        \n",
    "    \"\"\"\n",
    "        \n",
    "    q = []\n",
    "    q.append(category) \n",
    "\n",
    "    page_content = []\n",
    " \n",
    "    #while the q is not empty\n",
    "    while q: \n",
    "        current_node = q.pop(0) #pop the first element off the list you've created \n",
    "#         print(current_node)\n",
    "        \n",
    "        page_id, pages, children = get_cats_and_pages(current_node)\n",
    "        \n",
    "        for child in children:\n",
    "            q.append(child)   \n",
    "     \n",
    "        for index, article in enumerate(pages):    \n",
    "            article_dict = {}\n",
    "            article_dict['category'] = current_node\n",
    "            article_dict['article'] = article\n",
    "            article_dict['content'] = get_content(article)\n",
    "            article_dict['page_id'] = str(page_id[index])\n",
    "            \n",
    "            #this line adds each article onto mongo database as each article is being called \n",
    "#             wiki_col.insert_one(article_dict) \n",
    "            \n",
    "            page_content.append(article_dict)      \n",
    "            \n",
    "    return page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'article': 'Deep learning',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': '{{About||deep versus shallow learning in educational psychology|Student approaches to learning|more information|Artificial neural network}}\\n\\n{{machine learning bar}}\\n\\n\\'\\'\\'Deep learning\\'\\'\\' (also known as \\'\\'\\'deep structured learning\\'\\'\\' or \\'\\'\\'hierarchical learning\\'\\'\\') is part of a broader family of [[machine learning]] methods based on [[learning representation|learning data representation]]s, as opposed to task-specific algorithms. Learning can be [[Supervised learning|supervised]], partially supervised or [[Unsupervised learning|unsupervised]].<ref name=\"BENGIO2012\" /><ref name=\"SCHIDHUB\" /><ref name=\"NatureBengio\">{{cite journal |last1=Bengio |first1=Yoshua |last2=LeCun |first2= Yann| last3=Hinton | first3= Geoffrey|year=2015 |title=Deep Learning |journal=Nature |volume=521 |pages=436–444 |doi=10.1038/nature14539 |pmid=26017442}}</ref><ref name=\"scholarpedia\">[[Jürgen Schmidhuber]] (2015). Deep Learning. Scholarpedia, 10(11):32832. [http://www.scholarpedia.org/article/Deep_Learning Online]</ref>\\n\\nSome representations are loosely based on interpretation of information processing and communication patterns in a biological [[nervous system]], such as [[neural coding]] that attempts to define a relationship between various stimuli and associated neuronal responses in the [[brain]].<ref>{{cite journal|year=1996|title=Emergence of simple-cell receptive field properties by learning a sparse code for natural images|journal=Nature|volume=381|issue=6583|pages=607–609|doi=10.1038/381607a0|pmid=8637596|last1=Olshausen|first1=B. A.|bibcode=1996Natur.381..607O}}</ref>\\n\\nDeep learning architectures such as [[#Deep_neural_networks|deep neural network]]s, [[deep belief network]]s and [[recurrent neural networks]] have been applied to fields including [[computer vision]], [[automatic speech recognition|speech recognition]], [[natural language processing]], audio recognition, social network filtering, [[machine translation]], [[bioinformatics]]<ref>{{Cite journal|last=Movahedi|first=F.|last2=Coyle|first2=J. L.|last3=Sejdić|first3=E.|date=2017|title=Deep belief networks for electroencephalography: A review of recent contributions and future outlooks|url=http://ieeexplore.ieee.org/document/7981315/|journal=IEEE Journal of Biomedical and Health Informatics|volume=PP|issue=99|pages=1–1|doi=10.1109/JBHI.2017.2727218|issn=2168-2194}}</ref> and [[drug design]]<ref>{{Cite journal |last=Ghasemi |first=F. |last2=Mehridehnavi|first2=AR. |last3=Fassihi |first3=A. |last4=Perez-Sanchez |first4=H.| date=2017|title=Deep Neural Network in Biological Activity Prediction using Deep Belief Network|url=http://sciencedirect.com/science/article/pii/S1568494617305793|journal=Applied Soft Computing}}</ref>, where they have produced results comparable to and in some cases superior<ref name=\":9\">{{Cite journal|last=Ciresan|first=Dan|last2=Meier|first2=U.|last3=Schmidhuber|first3=J.|date=June 2012|title=Multi-column deep neural networks for image classification|url=http://ieeexplore.ieee.org/document/6248110/|journal=2012 IEEE Conference on Computer Vision and Pattern Recognition|pages=3642–3649|doi=10.1109/cvpr.2012.6248110|via=}}</ref> to human experts.<ref name=\"krizhevsky2012\">{{cite journal|last1=Krizhevsky|first1=Alex|last2=Sutskever|first2=Ilya|last3=Hinton|first3=Geoffry|date=2012|title=ImageNet Classification with Deep Convolutional Neural Networks|url=https://www.cs.toronto.edu/~kriz/imagenet_classification_with_deep_convolutional.pdf|journal=NIPS 2012: Neural Information Processing Systems, Lake Tahoe, Nevada}}\\n</ref>{{toclimit|3}}\\n\\n== Definitions ==\\nDeep learning is a class of [[machine learning]] [[algorithm]]s that:<ref name=\"BOOK2014\">{{cite journal|last2=Yu|first2=D.|year=2014|title=Deep Learning: Methods and Applications|url=http://research.microsoft.com/pubs/209355/DeepLearning-NowPublishing-Vol7-SIG-039.pdf|journal=Foundations and Trends in Signal Processing|volume=7|issue=3–4|pages=1–199|doi=10.1561/2000000039|last1=Deng|first1=L.}}</ref>{{rp|pages=199–200}}\\n* use a cascade of multiple layers of [[Nonlinear filter|nonlinear processing]] units for [[feature extraction]] and transformation. Each successive layer uses the output from the previous layer as input. \\n* learn in [[Supervised learning|supervised]] (e.g., classification) and/or [[Unsupervised learning|unsupervised]] (e.g., pattern analysis) manners.\\n* learn multiple levels of representations that correspond to different levels of abstraction; the levels form a hierarchy of concepts. \\n* use some form of [[gradient descent]] for training via [[backpropagation]].\\n\\nLayers that have been used in deep learning include hidden layers of an [[artificial neural network]] and sets of [[propositional formula]]s.<ref name=\"BENGIODEEP\">{{cite journal|last=Bengio|first=Yoshua|year=2009|title=Learning Deep Architectures for AI|url=http://sanghv.com/download/soft/machine%20learning,%20artificial%20intelligence,%20mathematics%20ebooks/ML/learning%20deep%20architectures%20for%20AI%20%282009%29.pdf|journal=Foundations and Trends in Machine Learning|volume=2|issue=1|pages=1–127|doi=10.1561/2200000006}}</ref> They may also include latent variables organized layer-wise in deep [[generative model]]s such as the nodes in [[Deep belief network|Deep Belief Networks]] and Deep [[Boltzmann machine|Boltzmann Machines]].\\n\\n=== Credit assignment ===\\n* Credit assignment path (CAP)<ref name=\"SCHIDHUB\" /> – A chain of transformations from input to output. CAPs describe potentially causal connections between input and output.\\n* CAP depth – for a [[feedforward neural network]], the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized), but for [[recurrent neural network]]s, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited. \\n* Deep/shallow – No universally agreed upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth > 2.\\n\\n=== Concepts ===\\nThe assumption underlying distributed representations is that observed data are generated by the interactions of layered factors.\\n\\nDeep learning adds the assumption that these layers of factors{{Clarify|date=September 2017}} correspond to levels of abstraction or composition{{Clarify|date=September 2017}}{{Explain|date=September 2017}}. Varying numbers of layers and layer sizes can provide different degrees of abstraction.<ref name=\"BENGIO2012\">{{cite journal|last2=Courville|first2=A.|last3=Vincent|first3=P.|year=2013|title=Representation Learning: A Review and New Perspectives|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|volume=35|issue=8|pages=1798–1828|arxiv=1206.5538|doi=10.1109/tpami.2013.50|last1=Bengio|first1=Y.}}</ref>\\n\\nDeep learning exploits this idea of hierarchical explanatory factors{{Clarify|date=September 2017}} where higher level, more abstract concepts are learned from the lower level ones. {{Clarify|date=September 2017}}{{Explain|date=September 2017}}.<ref name=\"ivak1965\" /><ref name=\"ivak1971\" />\\n\\nDeep learning architectures are often constructed with a [[greedy algorithm|greedy]] layer-by-layer method{{Clarify|date=September 2017}}{{Explain|date=September 2017}}{{Citation needed|date=September 2017}}. Deep learning helps to disentangle these abstractions and pick out which features are useful for improving performance.<ref name=\"BENGIO2012\" />\\n\\nFor [[supervised learning]] tasks, deep learning methods obviate [[feature engineering]], by translating the data into compact intermediate representations akin to [[Principal Component Analysis|principal components]], and derive layered structures that remove redundancy in representation.<ref name=\"SCHMID1992\" /><ref name=\"BOOK2014\" />\\n\\nDeep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data are more abundant than labeled data. Examples of deep structures that can be trained in an unsupervised manner are neural history compressors<ref name=\"SCHMID1992\" /><ref name=\"scholarpedia\"/> and [[deep belief network]]s.<ref name=\"BENGIO2012\" /><ref name=\"SCHOLARDBNS\">{{cite journal | last1 = Hinton | first1 = G.E. | year = 2009| title = Deep belief networks | url= | journal = Scholarpedia | volume = 4 | issue = 5| page = 5947 | doi=10.4249/scholarpedia.5947}}</ref>\\n\\n== Interpretations ==\\nDeep neural networks are generally interpreted in terms of the [[universal approximation theorem]]<ref name=\"ReferenceB\">Balázs Csanád Csáji (2001). Approximation with Artificial Neural Networks; Faculty of Sciences; Eötvös Loránd University, Hungary</ref><ref name=cyb>{{cite journal | last1 = Cybenko | year = 1989 | title = Approximations by superpositions of sigmoidal functions |url=http://deeplearning.cs.cmu.edu/pdfs/Cybenko.pdf | format = PDF | journal = [[Mathematics of Control, Signals, and Systems]] | volume = 2 | issue = 4| pages = 303–314 | doi=10.1007/bf02551274}}</ref><ref name=horn>{{cite journal | last1 = Hornik | first1 = Kurt | year = 1991 | title = Approximation Capabilities of Multilayer Feedforward Networks | url= | journal = Neural Networks | volume = 4 | issue = 2| pages = 251–257 | doi=10.1016/0893-6080(91)90009-t}}</ref><ref name=\"Haykin, Simon 1998\">{{cite book|first=Simon S. |last=Haykin|title=Neural Networks: A Comprehensive Foundation|url={{google books |plainurl=y |id=bX4pAQAAMAAJ}}|year=1999|publisher=Prentice Hall|isbn=978-0-13-273350-2}}</ref><ref name=\"Hassoun, M. 1995 p. 48\">{{cite book|first=Mohamad H. |last=Hassoun|title=Fundamentals of Artificial Neural Networks|url={{google books |plainurl=y |id=Otk32Y3QkxQC|page=48}}|year=1995|publisher=MIT Press|isbn=978-0-262-08239-6|p=48}}</ref> or [[Bayesian inference|probabilistic inference]].<ref name=\"BOOK2014\" /><ref name=\"BENGIODEEP\" /><ref name=\"BENGIO2012\" /><ref name=\"SCHIDHUB\">{{cite journal|last=Schmidhuber|first=J.|year=2015|title=Deep Learning in Neural Networks: An Overview|journal=Neural Networks|volume=61|pages=85–117|arxiv=1404.7828|doi=10.1016/j.neunet.2014.09.003|pmid=25462637}}</ref><ref name=\"SCHOLARDBNS\" /><ref name = MURPHY>{{cite book|first=Kevin P. |last=Murphy|title=Machine Learning: A Probabilistic Perspective|url={{google books |plainurl=y |id=NZP6AQAAQBAJ}}|date=24 August 2012|publisher=MIT Press|isbn=978-0-262-01802-9}}</ref>\\n\\nThe universal approximation theorem concerns the capacity of [[feedforward neural networks]] with a single hidden layer of finite size to approximate [[continuous functions]].<ref name=\"ReferenceB\"/><ref name=\"cyb\"/><ref name=\"horn\"/><ref name=\"Haykin, Simon 1998\"/><ref name=\"Hassoun, M. 1995 p. 48\"/> In 1989, the first proof was published by [[George Cybenko|Cybenko]] for [[sigmoid function|sigmoid]] activation functions<ref name=\"cyb\" /> and was generalised to feed-forward multi-layer architectures in 1991 by Hornik.<ref name=\"horn\" />\\n\\nThe [[probabilistic]] interpretation<ref name=\"MURPHY\" /> derives from the field of [[machine learning]]. It features inference,<ref name=\"BOOK2014\" /><ref name=\"BENGIODEEP\" /><ref name=\"BENGIO2012\" /><ref name=\"SCHIDHUB\" /><ref name=\"SCHOLARDBNS\" /><ref name=\"MURPHY\" /> as well as the [[optimization]] concepts of [[training]] and [[test (assessment)|testing]], related to fitting and [[generalization]], respectively. More specifically, the probabilistic interpretation considers the activation nonlinearity as a [[cumulative distribution function]].<ref name=\"MURPHY\" /> The probabilistic interpretation led to the introduction of [[dropout (neural networks)|dropout]] as [[Regularization (mathematics)|regularizer]] in neural networks.<ref name=\"DROPOUT\">{{cite arXiv |last1=Hinton |first1=G. E. |last2=Srivastava| first2 =N.|last3=Krizhevsky| first3=A.| last4 =Sutskever| first4=I.| last5=Salakhutdinov| first5=R.R.|eprint=1207.0580 |class=math.LG |title=Improving neural networks by preventing co-adaptation of feature detectors |date=2012}}</ref> The probabilistic interpretation was introduced by researchers including [[John Hopfield|Hopfield]], [[Bernard Widrow|Widrow]] and [[Kumpati S. Narendra|Narendra]] and popularized in surveys such as the one by [[Christopher Bishop|Bishop]].<ref name=\"prml\">{{cite book|title=Pattern Recognition and Machine Learning|author=Bishop, Christopher M.|year=2006|publisher=Springer|url=http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf|isbn=978-0-387-31073-2}}</ref>\\n\\n==History==\\nThe term \\'\\'Deep Learning\\'\\' was introduced to the machine learning community by [[Rina Dechter]] in 1986,<ref name=\"dechter1986\">[[Rina Dechter]] (1986). Learning while searching in constraint-satisfaction problems. University of California, Computer Science Department, Cognitive Systems Laboratory.[https://www.researchgate.net/publication/221605378_Learning_While_Searching_in_Constraint-Satisfaction-Problems Online]</ref><ref name=\"scholarpedia\" /> and [[Artificial Neural Networks]] by Igor Aizenberg and colleagues in 2000, in the context of Boolean threshold neurons.<ref name=\"aizenberg2000\">Igor Aizenberg, Naum N. Aizenberg, Joos P.L. Vandewalle (2000). Multi-Valued and Universal Binary Neurons: Theory, Learning and Applications. Springer Science & Business Media.</ref> In 2005, Faustino Gomez and [[Jürgen Schmidhuber]] published a paper on \\'\\'learning deep\\'\\' [[Partially observable Markov decision process|POMDPs]]<ref name=\"LearningDeepPOMDPs\">F. Gomez and J. Schmidhuber. Co-evolving recurrent neurons learn deep memory POMDPs. Proc. GECCO, Washington, D. C., pp. 1795-1802, ACM Press, New York, NY, USA, 2005.</ref> through neural networks for [[reinforcement learning]]. In 2006, a publication by [[Geoffrey Hinton|Geoff Hinton]], Osindero and Teh<ref name=hinton06>{{Cite journal | last1 = Hinton | first1 = G. E. |authorlink1=Geoff Hinton| last2 = Osindero | first2 = S. | last3 = Teh | first3 = Y. W. | doi = 10.1162/neco.2006.18.7.1527 | title = A Fast Learning Algorithm for Deep Belief Nets | journal = [[Neural Computation (journal)|Neural Computation]]| volume = 18 | issue = 7 | pages = 1527–1554 | year = 2006 | pmid = 16764513| pmc = | url = http://www.cs.toronto.edu/~hinton/absps/fastnc.pdf}}</ref><ref name=bengio2012>{{cite arXiv |last=Bengio |first=Yoshua |author-link=Yoshua Bengio |eprint=1206.5533 |title=Practical recommendations for gradient-based training of deep architectures |class=cs.LG|year=2012 }}</ref> showed how a many-layered [[feedforward neural network]] could be effectively pre-trained one layer at a time, treating each layer in turn as an unsupervised [[restricted Boltzmann machine]], then fine-tuning it using supervised [[backpropagation]].<ref name=\"HINTON2007\">G. E. Hinton., \"Learning multiple layers of representation,\" \\'\\'Trends in Cognitive Sciences\\'\\', 11, pp. 428–434, 2007.</ref> The paper referred to \\'\\'learning\\'\\' for \\'\\'deep belief nets.\\'\\' A [[Google Ngram Viewer|Google Ngram]] chart shows that the usage of the term has increased since 2000.<ref name=\"DLchart\">Google Ngram chart of the usage of the expression \"deep learning\" posted by Jürgen Schmidhuber (2015) [https://plus.google.com/100849856540000067209/posts/7N6z251w2Wd?pid=6127540521703625346&oid=100849856540000067209 Online]</ref> The underlying concepts and many of the techniques, however, date to earlier decades.\\n\\nThe first general, working learning algorithm for supervised, deep, feedforward, multilayer [[perceptron]]s was published by [[Alexey Grigorevich Ivakhnenko|Akexey Ivakhnenko]] and Lapa in 1965.<ref name=\"ivak1965\">{{cite book|first=A. G. |last=Ivakhnenko|title=Cybernetic Predicting Devices|url={{google books |plainurl=y |id=FhwVNQAACAAJ}}|year=1973|publisher=CCM Information Corporation}}</ref> A 1971 paper described a deep network with 8 layers trained by the [[group method of data handling]] algorithm.<ref name=\"ivak1971\">{{Cite journal|last=Ivakhnenko|first=Alexey|date=1971|title=Polynomial theory of complex systems|url=|journal=IEEE Transactions on Systems, Man and Cybernetics (4)|pages=364–378|doi=10.1109/TSMC.1971.4308320|pmid=|access-date=|volume=1}}</ref>\\n\\nThese ideas were implemented in a computer identification system by the World School Council London called \"Alpha\", which demonstrated the learning process.{{Citation needed|date=August 2017}}\\n\\nOther deep learning working architectures, specifically those built for [[computer vision]], began with the [[Neocognitron]] introduced by [[Kunihiko Fukushima]] in 1980.<ref name=\"FUKU1980\">{{cite journal | last1 = Fukushima | first1 = K. | year = 1980 | title = Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position | url= | journal = Biol. Cybern. | volume = 36 | issue = | pages = 193–202 | doi=10.1007/bf00344251 | pmid=7370364}}</ref> In 1989, [[Yann LeCun]] et al. applied the standard backpropagation algorithm, which had been around as the reverse mode of [[automatic differentiation]] since 1970,<ref name=\"lin1970\">[[Seppo Linnainmaa]] (1970). The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors. Master\\'s Thesis (in Finnish), Univ. Helsinki, 6-7.</ref><ref name=\"grie2012\">{{Cite journal|last=Griewank|first=Andreas|date=2012|title=Who Invented the Reverse Mode of Differentiation?|url=http://www.math.uiuc.edu/documenta/vol-ismp/52_griewank-andreas-b.pdf|journal=Documenta Matematica, Extra Volume ISMP|pages=389–400|via=}}</ref><ref name=\"WERBOS1974\">{{Cite journal|last=Werbos|first=P.|date=1974|title=Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences |url=https://www.researchgate.net/publication/35657389_Beyond_regression_new_tools_for_prediction_and_analysis_in_the_behavioral_sciences |journal=Harvard University |accessdate=12 June 2017}}</ref><ref name=\"werbos1982\">{{Cite book|url=ftp://ftp.idsia.ch/pub/juergen/habilitation.pdf|title=System modeling and optimization|last=Werbos|first=Paul|publisher=Springer|year=1982|isbn=|location=|pages=762–770|chapter=Applications of advances in nonlinear sensitivity analysis}}</ref> to a deep neural network with the purpose of recognizing handwritten [[ZIP code]]s on mail. While the algorithm worked, training required 3 days.<ref name=\"LECUN1989\">LeCun \\'\\'et al.\\'\\', \"Backpropagation Applied to Handwritten Zip Code Recognition,\" \\'\\'Neural Computation\\'\\', 1, pp. 541–551, 1989.</ref>\\n\\nBy 1991 such systems were used for recognizing isolated 2-D hand-written digits, while recognizing 3-D objects was done by matching 2-D images with a handcrafted 3-D object model. Weng \\'\\'et al.\\'\\' suggested that a human brain does not use a monolithic 3-D object model and in 1992 they published Cresceptron,<ref name=\"Weng1992\">J. Weng, N. Ahuja and T. S. Huang, \"[http://www.cse.msu.edu/~weng/research/CresceptronIJCNN1992.pdf Cresceptron: a self-organizing neural network which grows adaptively],\" \\'\\'Proc. International Joint Conference on Neural Networks\\'\\', Baltimore, Maryland, vol I, pp. 576-581, June, 1992.</ref><ref name=\"Weng1993\">J. Weng, N. Ahuja and T. S. Huang, \"[http://www.cse.msu.edu/~weng/research/CresceptronICCV1993.pdf Learning recognition and segmentation of 3-D objects from 2-D images],\" \\'\\'Proc. 4th International Conf. Computer Vision\\'\\', Berlin, Germany, pp. 121-128, May, 1993.</ref><ref name=\"Weng1997\">J. Weng, N. Ahuja and T. S. Huang, \"[http://www.cse.msu.edu/~weng/research/CresceptronIJCV.pdf Learning recognition and segmentation using the Cresceptron],\" \\'\\'International Journal of Computer Vision\\'\\', vol. 25, no. 2, pp. 105-139, Nov. 1997.</ref> a method for performing 3-D object recognition in cluttered scenes. Cresceptron is a cascade of layers similar to Neocognitron. But while Neocognitron required a human programmer to hand-merge features, Cresceptron learned an open number of features in each layer without supervision, where each feature is represented by a [[Convolution|convolution kernel]]. Cresceptron segmented each learned object from a cluttered scene through back-analysis through the network. [[Max pooling]], now often adopted by deep neural networks (e.g. [[ImageNet]] tests), was first used in Cresceptron to reduce the position resolution by a factor of (2x2) to 1 through the cascade for better generalization.\\n\\nIn 1992, Schmidhuber used unsupervised pre-training for deep hierarchies of data-compressing recurrent neural networks, and showed its benefits for speeding up supervised learning.<ref name=\"SCHMID1992\">J. Schmidhuber., \"Learning complex, extended sequences using the principle of history compression,\" \\'\\'Neural Computation\\'\\', 4, pp. 234–242, 1992.</ref><ref name=\"scholarpedia\"/>\\n\\nIn 1994, André C. P. L. F. de Carvalho, together with Fairhurst and Bisset, published experimental results of a multi-layer [[Boolean algebra|boolean]] neural network, also known as a weightless neural network, composed of a self-organising feature extraction neural network module followed by a classification neural network module, which were independently trained.<ref>{{Cite journal |title=An integrated Boolean neural network for pattern classification |journal=Pattern Recognition Letters |date=1994-08-08 |pages=807–813 |volume=15 |issue=8 |doi=10.1016/0167-8655(94)90009-4 |first=Andre C. L. F. |last1=de Carvalho |first2 = Mike C. |last2=Fairhurst |first3=David |last3 = Bisset}}</ref>\\n\\nIn 1995, [[Brendan Frey]] demonstrated that it was possible to train (over two days) a network containing six fully connected layers and several hundred hidden units using the [[wake-sleep algorithm]], co-developed with [[Peter Dayan]] and [[Geoffrey Hinton|Hinton]].<ref>{{Cite journal|title = The wake-sleep algorithm for unsupervised neural networks |journal = Science|date = 1995-05-26|pages = 1158–1161|volume = 268|issue = 5214|doi = 10.1126/science.7761831|first = Geoffrey E.|last = Hinton|first2 = Peter|last2 = Dayan|first3 = Brendan J.|last3 = Frey|first4 = Radford|last4 = Neal}}</ref> Many factors contribute to the slow speed, including the [[vanishing gradient problem]] analyzed in 1991 by [[Sepp Hochreiter]].<ref name=\"HOCH1991\">S. Hochreiter., \"[http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf Untersuchungen zu dynamischen neuronalen Netzen],\" \\'\\'Diploma thesis. Institut f. Informatik, Technische Univ. Munich. Advisor: J. Schmidhuber\\'\\', 1991.</ref><ref name=\"HOCH2001\">{{cite book|url={{google books |plainurl=y |id=NWOcMVA64aAC}}|title=A Field Guide to Dynamical Recurrent Networks|last=Hochreiter|first=S.|display-authors=etal|date=15 January 2001|publisher=John Wiley & Sons|year=|isbn=978-0-7803-5369-5|location=|pages=|chapter=Gradient flow in recurrent nets: the difficulty of learning long-term dependencies|editor-last2=Kremer|editor-first2=Stefan C.|editor-first1=John F.|editor-last1=Kolen}}</ref>\\n\\nSimpler models that use task-specific handcrafted features such as [[Gabor filter]]s and [[support vector machine]]s (SVMs) were a popular choice in the 1990s and 2000s, because of ANNs\\' computational cost and a lack of understanding of how the brain wires its biological networks.\\n\\nBoth shallow and deep learning (e.g., recurrent nets) of ANNs have been explored for many years.<ref>{{Cite journal|last=Morgan|first=Nelson|last2=Bourlard |first2=Hervé |last3=Renals |first3=Steve |last4=Cohen |first4=Michael|last5=Franco |first5=Horacio |date=1993-08-01 |title=Hybrid neural network/hidden markov model systems for continuous speech recognition |url=http://www.worldscientific.com/doi/abs/10.1142/S0218001493000455|journal=International Journal of Pattern Recognition and Artificial Intelligence|volume=07|issue=04|pages=899–916|doi=10.1142/s0218001493000455|issn=0218-0014}}</ref><ref name=\"Robinson1992\">{{Cite journal|last=Robinson|first=T.|date=1992|title=A real-time recurrent error propagation network word recognition system|url=http://dl.acm.org/citation.cfm?id=1895720|journal=ICASSP|pages=|via=}}</ref><ref>{{Cite journal|last=Waibel|first=A.|last2=Hanazawa|first2=T.|last3=Hinton|first3=G.|last4=Shikano|first4=K.|last5=Lang|first5=K. J.|date=March 1989|title=Phoneme recognition using time-delay neural networks|url=http://ieeexplore.ieee.org/document/21701/|journal=IEEE Transactions on Acoustics, Speech, and Signal Processing|volume=37|issue=3|pages=328–339|doi=10.1109/29.21701|issn=0096-3518}}</ref> These methods never outperformed non-uniform internal-handcrafting Gaussian [[mixture model]]/[[Hidden Markov model]] (GMM-HMM) technology based on generative models of speech trained discriminatively.<ref name=\"Baker2009\">{{cite journal | last1 = Baker | first1 = J. | last2 = Deng | first2 = Li | last3 = Glass | first3 = Jim | last4 = Khudanpur | first4 = S. | last5 = Lee | first5 = C.-H. | last6 = Morgan | first6 = N. | last7 = O\\'Shaughnessy | first7 = D. | year = 2009 | title = Research Developments and Directions in Speech Recognition and Understanding, Part 1 | url= | journal = IEEE Signal Processing Magazine | volume = 26 | issue = 3| pages = 75–80 | doi=10.1109/msp.2009.932166}}</ref> Key difficulties have been analyzed, including gradient diminishing<ref name=\"HOCH1991\" /> and weak temporal correlation structure in neural predictive models.<ref name=\"Bengio1991\">{{Cite web|url=https://www.researchgate.net/publication/41229141_Artificial_neural_networks_and_their_application_to_sequence_recognition|title=Artificial Neural Networks and their Application to Speech/Sequence Recognition|last=Bengio|first=Y.|date=1991|website=|publisher=McGill University Ph.D. thesis|access-date=}}</ref><ref name=\"Deng1994\">{{cite journal | last1 = Deng | first1 = L. | last2 = Hassanein | first2 = K. | last3 = Elmasry | first3 = M. | year = 1994 | title = Analysis of correlation structure for a neural predictive model with applications to speech recognition | url= | journal = Neural Networks | volume = 7 | issue = 2| pages = 331–339 | doi=10.1016/0893-6080(94)90027-2}}</ref> Additional difficulties were the lack of training data and limited computing power.\\n\\nMost [[speech recognition]] researchers moved away from neural nets to pursue generative modeling. An exception was at [[SRI International]] in the late 1990s. Funded by the US government\\'s [[National Security Agency|NSA]] and [[DARPA]], SRI studied deep neural networks in speech and speaker recognition. Heck\\'s speaker recognition team achieved the first significant success with deep neural networks in speech processing in the 1998 [[National Institute of Standards and Technology]] Speaker Recognition evaluation.<ref name=\"Heck2000\">{{cite journal | last1 = Heck | first1 = L. | last2 = Konig | first2 = Y. | last3 = Sonmez | first3 = M. | last4 = Weintraub | first4 = M. | year = 2000 | title = Robustness to Telephone Handset Distortion in Speaker Recognition by Discriminative Feature Design | url= | journal = Speech Communication | volume = 31 | issue = 2| pages = 181–192 | doi=10.1016/s0167-6393(99)00077-1}}</ref> While SRI experienced success with deep neural networks in speaker recognition, they were unsuccessful in demonstrating similar success in speech recognition. One decade later, Hinton and Deng collaborated with each other and then with colleagues across groups at University of Toronto, Microsoft, Google and IBM, igniting a renaissance of deep feedforward neural networks in speech recognition.<ref name=\"HintonDengYu2012\" /><ref name=\"ReferenceICASSP2013\">{{cite journal|last2=Hinton|first2=G.|last3=Kingsbury|first3=B.|date=2013|title=New types of deep neural network learning for speech recognition and related applications: An overview (ICASSP)|url=https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/ICASSP-2013-DengHintonKingsbury-revised.pdf|journal=|pages=|via=|last1=Deng|first1=L.}}</ref><ref name=\"HintonKeynoteICASSP2013\">Keynote talk: Recent Developments in Deep Neural Networks. ICASSP, 2013 (by Geoff Hinton).</ref><ref name=\"interspeech2014Keynote\">{{Cite web|url=https://www.superlectures.com/interspeech2014/downloadFile?id=6&type=slides&filename=achievements-and-challenges-of-deep-learning-from-speech-analysis-and-recognition-to-language-and-multimodal-processing|title=Keynote talk: \\'Achievements and Challenges of Deep Learning - From Speech Analysis and Recognition To Language and Multimodal Processing\\'|last=Li|first=Deng|date=September 2014|website=Interspeech|access-date=}}</ref>\\n\\nThe principle of elevating \"raw\" features over hand-crafted optimization was first explored successfully in the architecture of deep autoencoder on the \"raw\" spectrogram or linear filter-bank features in the late 1990s,<ref name=\"Heck2000\" /> showing its superiority over the Mel-Cepstral features that contain stages of fixed transformation from spectrograms. The raw features of speech, [[waveform]]s, later produced excellent larger-scale results.<ref>{{Cite web|url=https://www.researchgate.net/publication/266030526_Acoustic_Modeling_with_Deep_Neural_Networks_Using_Raw_Time_Signal_for_LVCSR|title=Acoustic Modeling with Deep Neural Networks Using Raw Time Signal for LVCSR (PDF Download Available)|website=ResearchGate|language=en|access-date=2017-06-14}}</ref>\\n\\nMany aspects of speech recognition were taken over by a deep learning method called [[Long short-term memory]] (LSTM), a recurrent neural network published by Hochreiter and Schmidhuber in 1997.<ref name=\":0\">{{Cite journal|last=Hochreiter|first=Sepp|author-link=Sepp Hochreiter|last2=Schmidhuber|first2=Jürgen|author-link2=Jürgen Schmidhuber|date=1997-11-01|title=Long Short-Term Memory|url=http://www.mitpressjournals.org/doi/10.1162/neco.1997.9.8.1735|journal=Neural Computation|volume=9|issue=8|pages=1735–1780|doi=10.1162/neco.1997.9.8.1735|issn=0899-7667|via=|pmid=9377276}}</ref> LSTM RNNs avoid the vanishing gradient problem and can learn \"Very Deep Learning\" tasks<ref name=\"SCHIDHUB\" /> that require memories of events that happened thousands of discrete time steps before, which is important for speech. In 2003, LSTM started to become competitive with traditional speech recognizers on certain tasks.<ref name=\"graves2003\">{{Cite web|url=Ftp://ftp.idsia.ch/pub/juergen/bioadit2004.pdf|title=Biologically Plausible Speech Recognition with LSTM Neural Nets|last=Graves|first=Alex|last2=Eck|first2=Douglas|date=2003|website=1st Intl. Workshop on Biologically Inspired Approaches to Advanced Information Technology, Bio-ADIT 2004, Lausanne, Switzerland|pages=175–184|access-date=|last3=Beringer|first3=Nicole|last4=Schmidhuber|first4=Jürgen|authorlink4=Jürgen Schmidhuber}}</ref> Later it was combined with connectionist temporal classification (CTC)<ref name=\":1\">{{Cite journal|last=Graves|first=Alex|last2=Fernández|first2=Santiago|last3=Gomez|first3=Faustino|date=2006|title=Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks|url=http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.75.6306|journal=In Proceedings of the International Conference on Machine Learning, ICML 2006|pages=369–376}}</ref> in stacks of LSTM RNNs.<ref name=\"fernandez2007keyword\">Santiago Fernandez, Alex Graves, and Jürgen Schmidhuber (2007). An application of recurrent neural networks to discriminative keyword spotting. Proceedings of ICANN (2), pp. 220–229.</ref> In 2015, Google\\'s speech recognition reportedly experienced a dramatic performance jump of 49% through CTC-trained LSTM, which they made available through [[Google Voice Search]].<ref name=\"sak2015\">{{Cite web|url=http://googleresearch.blogspot.ch/2015/09/google-voice-search-faster-and-more.html|title=Google voice search: faster and more accurate|last=Sak|first=Haşim|last2=Senior|first2=Andrew|date=September 2015|website=|access-date=|last3=Rao|first3=Kanishka|last4=Beaufays|first4=Françoise|last5=Schalkwyk|first5=Johan}}</ref>\\n\\nIn the early 2000s, CNNs processed an estimated 10% to 20% of all the checks written in the US.<ref name=\"lecun2016slides\" />\\n\\nIn 2006, Hinton and Salakhutdinov showed how a many-layered feedforward neural network could be effectively pre-trained one layer at a time, treating each layer in turn as an unsupervised restricted Boltzmann machine, then fine-tuning it using supervised backpropagation.<ref>{{Cite journal|last=Hinton|first=Geoffrey E.|date=2007-10-01|title=Learning multiple layers of representation|url=http://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(07)00217-3|journal=Trends in Cognitive Sciences|language=English|volume=11|issue=10|pages=428–434|doi=10.1016/j.tics.2007.09.004|issn=1364-6613|pmid=17921042}}</ref>\\n\\nDeep learning is part of state-of-the-art systems in various disciplines, particularly computer vision and [[automatic speech recognition]] (ASR). Results on commonly used evaluation sets such as [[TIMIT]] (ASR) and [[MNIST database|MNIST]] ([[image classification]]), as well as a range of large-vocabulary speech recognition tasks have steadily improved.<ref name=\"HintonDengYu2012\" /><ref>{{cite journal|url=https://www.microsoft.com/en-us/research/publication/new-types-of-deep-neural-network-learning-for-speech-recognition-and-related-applications-an-overview/|title=New types of deep neural network learning for speech recognition and related applications: An overview|first1=Li|last1=Deng|first2=Geoffrey|last2=Hinton|first3=Brian|last3=Kingsbury|date=1 May 2013|publisher=|via=research.microsoft.com}}</ref><ref>{{Cite journal|last=Deng|first=L.|last2=Li|first2=J.|last3=Huang|first3=J. T.|last4=Yao|first4=K.|last5=Yu|first5=D.|last6=Seide|first6=F.|last7=Seltzer|first7=M.|last8=Zweig|first8=G.|last9=He|first9=X.|date=May 2013|title=Recent advances in deep learning for speech research at Microsoft|url=http://ieeexplore.ieee.org/document/6639345/|journal=2013 IEEE International Conference on Acoustics, Speech and Signal Processing|pages=8604–8608|doi=10.1109/icassp.2013.6639345}}</ref> [[Convolutional neural network]]s (CNNs) were superseded for ASR by CTC<ref name=\":1\" /> for LSTM.<ref name=\":0\" /><ref name=\"sak2015\" /><ref name=\"sak2014\">{{Cite web|url=https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43905.pdf|title=Long Short-Term Memory recurrent neural network architectures for large scale acoustic modeling|last=Sak|first=Hasim|last2=Senior|first2=Andrew|date=2014|website=|access-date=|last3=Beaufays|first3=Francoise}}</ref><ref name=\"liwu2015\">Xiangang Li, Xihong Wu (2015). Constructing Long Short-Term Memory based Deep Recurrent Neural Networks for Large Vocabulary Speech Recognition [[arxiv:1410.4281|arXiv:1410.4281]]</ref><ref name=\"zen2015\">{{Cite web|url=https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43266.pdf|title=Unidirectional Long Short-Term Memory Recurrent Neural Network with Recurrent Output Layer for Low-Latency Speech Synthesis|last=Zen|first=Heiga|last2=Sak|first2=Hasim|date=2015|website=Google.com|publisher=ICASSP|pages=4470–4474|access-date=}}</ref><ref name=\"CNNspeech2013\">{{Cite web|url=https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43266.pdf|title=A deep convolutional neural network using heterogeneous pooling for trading acoustic invariance with phonetic confusion|last=Deng|first=L.|last2=Abdel-Hamid|first2=O.|date=2013|website=Google.com|publisher=ICASSP|access-date=|last3=Yu|first3=D.}}</ref><ref name=\":2\">{{Cite journal|last=Sainath|first=T. N.|last2=Mohamed|first2=A. r|last3=Kingsbury|first3=B.|last4=Ramabhadran|first4=B.|date=May 2013|title=Deep convolutional neural networks for LVCSR|url=http://ieeexplore.ieee.org/document/6639347/|journal=2013 IEEE International Conference on Acoustics, Speech and Signal Processing|pages=8614–8618|doi=10.1109/icassp.2013.6639347}}</ref> but are more successful in computer vision.\\n\\nThe impact of deep learning in industry began in the early 2000s, when CNNs already processed an estimated 10% to 20% of all the checks written in the US.<ref name=\"lecun2016slides\">[[Yann LeCun]] (2016). Slides on Deep Learning [https://indico.cern.ch/event/510372/ Online]</ref> Industrial applications of deep learning to large-scale speech recognition started around 2010.\\n\\nIn late 2009, Li Deng invited Hinton to work with him and colleagues to apply deep learning to speech recognition. They co-organized the 2009 NIPS Workshop on Deep Learning for Speech Recognition.<ref name=\"NIPS2009\" /> The workshop was motivated by the limitations of deep generative models of speech, and the possibility that given more capable hardware and large-scale data sets that deep neural nets (DNN) might become practical. It was believed that pre-training DNNs using generative models of deep belief nets (DBN) would overcome the main difficulties of neural nets.<ref name=\"HintonKeynoteICASSP2013\" /> However, they discovered that replacing pre-training with large amounts of training data for straightforward backpropagation when using DNNs with large, context-dependent output layers produced error rates dramatically lower than then-state-of-the-art Gaussian mixture model (GMM)/Hidden Markov Model (HMM) and also than more-advanced generative model-based systems.<ref name=\"HintonDengYu2012\">{{cite journal | last1 = Hinton | first1 = G. | last2 = Deng | first2 = L. | last3 = Yu | first3 = D. | last4 = Dahl | first4 = G. | last5 = Mohamed | first5 = A. | last6 = Jaitly | first6 = N. | last7 = Senior | first7 = A. | last8 = Vanhoucke | first8 = V. | last9 = Nguyen | first9 = P. | last10 = Sainath | first10 = T. | last11 = Kingsbury | first11 = B. | year = 2012 | title = Deep Neural Networks for Acoustic Modeling in Speech Recognition --- The shared views of four research groups | url= | journal = IEEE Signal Processing Magazine | volume = 29 | issue = 6| pages = 82–97 | doi=10.1109/msp.2012.2205597}}</ref><ref name=\"patent2011\">D. Yu, L. Deng, G. Li, and F. Seide (2011). \"Discriminative pretraining of deep neural networks,\" U.S. Patent Filing.</ref> The nature of the recognition errors produced by the two types of systems was found to be characteristically different,<ref name=\"ReferenceICASSP2013\" /><ref name=\"NIPS2009\">NIPS Workshop: Deep Learning for Speech Recognition and Related Applications, Whistler, BC, Canada, Dec. 2009 (Organizers: Li Deng, Geoff Hinton, D. Yu).</ref> offering technical insights into how to integrate deep learning into the existing highly efficient, run-time speech decoding system deployed by all major speech recognition systems.<ref name=\"BOOK2014\" /><ref name=\"ReferenceA\">{{cite journal|last2=Deng|first2=L.|date=2014|title=Automatic Speech Recognition: A Deep Learning Approach (Publisher: Springer)|url={{google books |plainurl=y |id=rUBTBQAAQBAJ}}|journal=|pages=|isbn=978-1-4471-5779-3|via=|last1=Yu|first1=D.}}</ref><ref>{{cite web|title=IEEE (2015) |url=http://blogs.technet.com/b/inside_microsoft_research/archive/2015/12/03/deng-receives-prestigious-ieee-technical-achievement-award.aspx}}</ref> Analysis around 2009-2010, contrasted the GMM (and other generative speech models) vs. DNN models, stimulated early industrial investment in deep learning for speech recognition,<ref name=\"ReferenceICASSP2013\" /><ref name=\"NIPS2009\" /> eventually leading to pervasive and dominant use in that industry. That analysis was done with comparable performance (less than 1.5% in error rate) between discriminative DNNs and generative models.\\n\\nIn 2010, researchers extended deep learning from TIMIT to large vocabulary speech recognition, by adopting large output layers of the DNN based on context-dependent HMM states constructed by [[decision tree]]s.<ref name=\"Roles2010\">{{cite journal|last1=Yu|first1=D.|last2=Deng|first2=L.|date=2010|title=Roles of Pre-Training and Fine-Tuning in Context-Dependent DBN-HMMs for Real-World Speech Recognition|url=https://www.microsoft.com/en-us/research/publication/roles-of-pre-training-and-fine-tuning-in-context-dependent-dbn-hmms-for-real-world-speech-recognition/|journal=NIPS Workshop on Deep Learning and Unsupervised Feature Learning|pages=|via=}}</ref><ref>{{Cite journal|last=Seide|first=F.|last2=Li|first2=G.|last3=Yu|first3=D.|date=2011|title=Conversational speech transcription using context-dependent deep neural networks|url=https://www.microsoft.com/en-us/research/publication/conversational-speech-transcription-using-context-dependent-deep-neural-networks|journal=Interspeech|pages=|via=}}</ref><ref>{{Cite journal|last=Deng|first=Li|last2=Li|first2=Jinyu|last3=Huang|first3=Jui-Ting|last4=Yao|first4=Kaisheng|last5=Yu|first5=Dong|last6=Seide|first6=Frank|last7=Seltzer|first7=Mike|last8=Zweig|first8=Geoff|last9=He|first9=Xiaodong|date=2013-05-01|title=Recent Advances in Deep Learning for Speech Research at Microsoft|url=https://www.microsoft.com/en-us/research/publication/recent-advances-in-deep-learning-for-speech-research-at-microsoft/|journal=Microsoft Research|language=en-US}}</ref><ref name=\"ReferenceA\" />\\n\\nAdvances in hardware enabled the renewed interest. In 2009, [[Nvidia]] was involved in what was called the “big bang” of deep learning, “as deep-learning neural networks were trained with Nvidia [[graphics processing unit]]s (GPUs).”<ref>{{cite web|url=https://venturebeat.com/2016/04/05/nvidia-ceo-bets-big-on-deep-learning-and-vr/|title=Nvidia CEO bets big on deep learning and VR|date=April 5, 2016|publisher=\\'\\'[[Venture Beat]]\\'\\'}}</ref> That year, [[Google Brain]] used Nvidia GPUs to create capable DNNs. While there, [[Andrew Ng|Ng]] determined that GPUs could increase the speed of deep-learning systems by about 100 times.<ref>{{cite web|url=https://www.economist.com/news/special-report/21700756-artificial-intelligence-boom-based-old-idea-modern-twist-not|title=From not working to neural networking|publisher=\\'\\'[[The Economist]]\\'\\'}}</ref> In particular, GPUs are well-suited for the matrix/vector math involved in machine learning.<ref name=\"jung2004\">{{cite journal | last1 = Oh | first1 = K.-S. | last2 = Jung | first2 = K. | year = 2004 | title = GPU implementation of neural networks | url= | journal = Pattern Recognition | volume = 37 | issue = 6| pages = 1311–1314 | doi=10.1016/j.patcog.2004.01.013}}</ref><ref name=\"chellapilla2006\">Chellapilla, K., Puri, S., and Simard, P. (2006). High performance convolutional neural networks for document processing. International Workshop on Frontiers in Handwriting Recognition.</ref> GPUs speed up training algorithms by orders of magnitude, reducing running times from weeks to days.<ref name=\":3\">{{Cite journal|last=Cireşan|first=Dan Claudiu|last2=Meier|first2=Ueli|last3=Gambardella|first3=Luca Maria|last4=Schmidhuber|first4=Jürgen|date=2010-09-21|title=Deep, Big, Simple Neural Nets for Handwritten Digit Recognition|url=http://www.mitpressjournals.org/doi/10.1162/NECO_a_00052|journal=Neural Computation|volume=22|issue=12|pages=3207–3220|doi=10.1162/neco_a_00052|issn=0899-7667}}</ref><ref>{{Cite journal|last=Raina|first=Rajat|last2=Madhavan|first2=Anand|last3=Ng|first3=Andrew Y.|date=2009|title=Large-scale Deep Unsupervised Learning Using Graphics Processors|url=http://doi.acm.org/10.1145/1553374.1553486|journal=Proceedings of the 26th Annual International Conference on Machine Learning|series=ICML \\'09|location=New York, NY, USA|publisher=ACM|pages=873–880|doi=10.1145/1553374.1553486|isbn=9781605585161|citeseerx=10.1.1.154.372}}</ref> Specialized hardware and algorithm optimizations can be used for efficient processing.<ref name=\"sze2017\">{{cite arXiv\\n|title= Efficient Processing of Deep Neural Networks: A Tutorial and Survey\\n|last1=Sze |first1=Vivienne\\n|last2=Chen |first2=Yu-Hsin\\n|last3=Yang |first3=Tien-Ju\\n|last4=Emer |first4=Joel\\n|arxiv=1703.09039\\n|year=2017\\n}}</ref>\\n\\nIn 2012, a team led by Dahl won the \"Merck Molecular Activity Challenge\" using multi-task deep neural networks to predict the [[Biomolecule|biomolecular]] target of one drug.<ref name=\"MERCK2012\">{{cite web|url=https://www.kaggle.com/c/MerckActivity/details/winners|title=Announcement of the winners of the Merck Molecular Activity Challenge}}</ref><ref name=\":5\">{{Cite web|url=http://www.datascienceassn.org/content/multi-task-neural-networks-qsar-predictions|title=Multi-task Neural Networks for QSAR Predictions {{!}} Data Science Association|website=www.datascienceassn.org|access-date=2017-06-14}}</ref> In 2014, Hochreiter\\'s group used deep learning to detect off-target and toxic effects of environmental chemicals in nutrients, household products and drugs and won the \"Tox21 Data Challenge\" of [[NIH]], [[FDA]] and [[National Center for Advancing Translational Sciences|NCATS]].<ref name=\"TOX21\">\"Toxicology in the 21st century Data Challenge]</ref><ref name=\"TOX21Data\">{{cite web|url=https://tripod.nih.gov/tox21/challenge/leaderboard.jsp|title=NCATS Announces Tox21 Data Challenge Winners|publisher=}}</ref><ref name=\":11\">{{cite web|url=http://www.ncats.nih.gov/news-and-events/features/tox21-challenge-winners.html|title=Archived copy|archiveurl=https://web.archive.org/web/20150228225709/http://www.ncats.nih.gov/news-and-events/features/tox21-challenge-winners.html|archivedate=2015-02-28|deadurl=yes|accessdate=2015-03-05|df=}}</ref>\\n\\nSignificant additional impacts in image or object recognition were felt from 2011 to 2012. Although CNNs trained by backpropagation had been around for decades, and GPU implementations of NNs for years, including CNNs, fast implementations of CNNs with max-pooling on GPUs in the style of Ciresan and colleagues were needed to progress on computer vision.<ref name=\"jung2004\" /><ref name=\"chellapilla2006\" /><ref name=\"LECUN1989\" /><ref name=\":6\">{{Cite journal|last=Ciresan|first=D. C.|last2=Meier|first2=U.|last3=Masci|first3=J.|last4=Gambardella|first4=L. M.|last5=Schmidhuber|first5=J.|date=2011|title=Flexible, High Performance Convolutional Neural Networks for Image Classification|url=http://ijcai.org/papers11/Papers/IJCAI11-210.pdf|journal=International Joint Conference on Artificial Intelligence|pages=|doi=10.5591/978-1-57735-516-8/ijcai11-210|via=}}</ref><ref name=\"SCHIDHUB\" /> In 2011, this approach achieved for the first time superhuman performance in a visual pattern recognition contest. Also in 2011, it won the ICDAR Chinese handwriting contest, and in May 2012, it won the ISBI image segmentation contest.<ref name=\":8\">{{Cite book|url=http://papers.nips.cc/paper/4741-deep-neural-networks-segment-neuronal-membranes-in-electron-microscopy-images.pdf|title=Advances in Neural Information Processing Systems 25|last=Ciresan|first=Dan|last2=Giusti|first2=Alessandro|last3=Gambardella|first3=Luca M.|last4=Schmidhuber|first4=Juergen|date=2012|publisher=Curran Associates, Inc.|editor-last=Pereira|editor-first=F.|pages=2843–2851|editor-last2=Burges|editor-first2=C. J. C.|editor-last3=Bottou|editor-first3=L.|editor-last4=Weinberger|editor-first4=K. Q.}}</ref> Until 2011, CNNs did not play a major role at computer vision conferences, but in June 2012, a paper by Ciresan et al. at the leading conference CVPR<ref name=\":9\" /> showed how max-pooling CNNs on GPU can dramatically improve many vision benchmark records. In October 2012, a similar system by Krizhevsky and Hinton<ref name=\"krizhevsky2012\" /> won the large-scale [[ImageNet competition]] by a significant margin over shallow machine learning methods. In November 2012, Ciresan et al.\\'s system also won the ICPR contest on analysis of large medical images for cancer detection, and in the following year also the MICCAI Grand Challenge on the same topic.<ref name=\"ciresan2013miccai\">{{Cite journal|last=Ciresan|first=D.|last2=Giusti|first2=A.|last3=Gambardella|first3=L.M.|last4=Schmidhuber|first4=J.|date=2013|title=Mitosis Detection in Breast Cancer Histology Images using Deep Neural Networks|url=http://people.idsia.ch/~ciresan/data/cvpr2012.pdf|journal=Proceedings MICCAI|pages=|via=}}</ref> In 2013 and 2014, the error rate on the ImageNet task using deep learning was further reduced, following a similar trend in large-scale speech recognition. The [[Stephen Wolfram|Wolfram]] Image Identification project publicized these improvements.<ref>{{Cite web|url=https://www.imageidentify.com/|title=The Wolfram Language Image Identification Project|website=www.imageidentify.com|access-date=2017-03-22}}</ref>\\n\\nImage classification was then extended to the more challenging task of generating descriptions (captions) for images, often as a combination of CNNs and LSTMs.<ref name=\"1411.4555\">Vinyals et al. (2014).\"Show and Tell: A Neural Image Caption Generator,\" {{arxiv|1411.4555}}.</ref><ref name=\"1411.4952\">Fang et al. (2014).\"From Captions to Visual Concepts and Back,\" {{arxiv|1411.4952}}.</ref><ref name=\"1411.2539\">Kiros et al. (2014). \"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models,\" {{arxiv|1411.2539}}.</ref><ref>{{Cite journal|last=Zhong|first=Sheng-hua|last2=Liu|first2=Yan|last3=Liu|first3=Yang|date=2011|title=Bilinear Deep Learning for Image Classification|url=http://doi.acm.org/10.1145/2072298.2072344|journal=Proceedings of the 19th ACM International Conference on Multimedia|series=MM \\'11|location=New York, NY, USA|publisher=ACM|pages=343–352|doi=10.1145/2072298.2072344|isbn=9781450306164}}</ref>\\n\\n== Artificial neural networks ==\\n{{Main|Artificial neural network}}\\n\\'\\'\\'Artificial neural networks\\'\\'\\' (\\'\\'\\'ANNs\\'\\'\\') or \\'\\'\\'[[Connectionism|connectionist]] systems\\'\\'\\' are computing systems inspired by the [[biological neural network]]s that constitute animal brains. Such systems learn (progressively improve their ability) to do tasks by considering examples, generally without task-specific programming. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually [[Labeled data|labeled]] as \"cat\" or \"no cat\" and using the analytic results to identify cats in other images. They have found most use in applications difficult to express with a traditional computer algorithm using [[rule-based programming]].\\n\\nAn ANN is based on a collection of connected units called [[artificial neuron]]s, (analogous to [[axon]]s in a [[Brain|biological brain]]). Each connection ([[synapse]]) between neurons can transmit a signal to another neuron. The receiving (postsynaptic) neuron can process the signal(s) and then signal downstream neurons connected to it. Neurons may have state, generally represented by [[real numbers]], typically between 0 and 1. Neurons and synapses may also have a weight that varies as learning proceeds, which can increase or decrease the strength of the signal that it sends downstream.\\n\\nTypically, neurons are organized in layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first (input), to the last (output) layer, possibly after traversing the layers multiple times.\\n\\nThe original goal of the neural network approach was to solve problems in the same way that a human brain would. Over time, attention focused on matching specific mental abilities, leading to deviations from biology such as backpropagation, or passing information in the reverse direction and adjusting the network to reflect that information.\\n\\nNeural networks have been used on a variety of tasks, including computer vision, [[speech recognition]], [[machine translation]], [[social network]] filtering, playing board and video games and medical diagnosis.\\n\\nAs of 2017, neural networks typically have a few thousand to a few million units and millions of connections. Despite this number being several order of magnitude less than the number of neurons on a human brain, these networks can perform many tasks at a level beyond that of humans (e.g., recognizing faces, playing \"Go\").\\n\\n== Deep neural networks ==\\n{{technical|section|date=July 2016}}\\nA deep neural network (DNN) is an ANN with multiple hidden layers between the input and output layers.<ref name=\"BENGIODEEP\" /><ref name=\"SCHIDHUB\" /> Similar to shallow ANNs, DNNs can model complex non-linear relationships. DNN architectures generate compositional models where the object is expressed as a layered composition of [[Primitive data type|primitives]].<ref>{{Cite journal|last=Szegedy|first=Christian|last2=Toshev|first2=Alexander|last3=Erhan|first3=Dumitru|date=2013|title=Deep neural networks for object detection|url=https://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection|journal=Advances in Neural Information Processing Systems|pages=|via=}}</ref> The extra layers enable composition of features from lower layers, potentially modeling complex data with fewer units than a similarly performing shallow network.<ref name=\"BENGIODEEP\" />\\n\\nDeep architectures include many variants of a few basic approaches. Each architecture has found success in specific domains. It is not always possible to compare the performance of multiple architectures, unless they have been evaluated on the same data sets.\\n\\nDNNs are typically feedforward networks in which data flows from the input layer to the output layer without looping back.\\n\\nRecurrent neural networks (RNNs), in which data can flow in any direction, are used for applications such as [[language model]]ing.<ref name=\"gers2001\">{{cite journal|last2=Schmidhuber|first2=Jürgen|year=2001|title=LSTM Recurrent Networks Learn Simple Context Free and Context Sensitive Languages|url=|journal=IEEE TNN|volume=12|issue=6|pages=1333–1340|doi=10.1109/72.963769|last1=Gers|first1=Felix A.|authorlink2=Jürgen Schmidhuber}}</ref><ref name=\"NIPS2014\"/><ref name=\"vinyals2016\">Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, Yonghui Wu (2016). Exploring the Limits of Language Modeling. [http://arxiv.org/abs/1602.02410 arXiv]</ref><ref name=\"gillick2015\">Dan Gillick, Cliff Brunk, Oriol Vinyals, Amarnag Subramanya (2015). Multilingual Language Processing From Bytes. [http://arxiv.org/abs/1512.00103 arXiv]</ref><ref name=\"MIKO2010\">{{Cite journal|last=Mikolov|first=T.|display-authors=etal|date=2010|title=Recurrent neural network based language model|url=http://www.fit.vutbr.cz/research/groups/speech/servite/2010/rnnlm_mikolov.pdf|journal=Interspeech|pages=|via=}}</ref> Long short-term memory is particularly effective for this use.<ref name=\":0\" /><ref name=\":10\">{{Cite web|url=https://www.researchgate.net/publication/220320057_Learning_Precise_Timing_with_LSTM_Recurrent_Networks|title=Learning Precise Timing with LSTM Recurrent Networks (PDF Download Available)|website=ResearchGate|language=en|access-date=2017-06-13}}</ref>\\n\\nConvolutional deep neural networks (CNNs) are used in computer vision.<ref name=\"LECUN86\">{{cite journal |last1=LeCun |first1=Y. |display-authors=etal |year= |title=Gradient-based learning applied to document recognition |url= |journal=Proceedings of the IEEE |volume=86 |issue=11 |pages=2278–2324 |doi=10.1109/5.726791}}</ref> CNNs also have been applied to [[acoustic model]]ing for automatic speech recognition (ASR).<ref name=\":2\" />\\n\\n=== Challenges ===\\nAs with ANNs, many issues can arise with naively trained DNNs. Two common issues are [[overfitting]] and computation time.\\n\\nDNNs are prone to overfitting because of the added layers of abstraction, which allow them to model rare dependencies in the training data. [[Regularization (mathematics)|Regularization]] methods such as Ivakhnenko\\'s unit pruning<ref name=\"ivak1971\"/> or [[weight decay]] (<math> \\\\ell_2 </math>-regularization) or [[sparse matrix|sparsity]] (<math> \\\\ell_1 </math>-regularization) can be applied during training to combat overfitting.<ref>{{Cite journal|last=Bengio|first=Y.|last2=Boulanger-Lewandowski|first2=N.|last3=Pascanu|first3=R.|date=May 2013|title=Advances in optimizing recurrent networks|url=http://ieeexplore.ieee.org/document/6639349/|journal=2013 IEEE International Conference on Acoustics, Speech and Signal Processing|pages=8624–8628|doi=10.1109/icassp.2013.6639349}}</ref> Alternatively dropout regularization randomly omits units from the hidden layers during training. This helps to exclude rare dependencies.<ref name=\"DAHL2013\">{{Cite journal|last=Dahl|first=G.|display-authors=etal|date=2013|title=Improving DNNs for LVCSR using rectified linear units and dropout|url=http://www.cs.toronto.edu/~gdahl/papers/reluDropoutBN_icassp2013.pdf|journal=ICASSP|pages=|via=}}</ref>\\n\\nDNNs must consider many training parameters, such as the size (number of layers and number of units per layer), the learning rate and initial weights. [[Hyperparameter optimization#Grid search|Sweeping through the parameter space]] for optimal parameters may not be feasible due to the cost in time and computational resources. Various tricks such as batching (computing the gradient on several training examples at once rather than individual examples)<ref name=\"RBMTRAIN\">{{Cite journal|last=Hinton|first=G. E.|date=2010|title=A Practical Guide to Training Restricted Boltzmann Machines|url=https://www.researchgate.net/publication/221166159_A_brief_introduction_to_Weightless_Neural_Systems|journal=Tech. Rep. UTML TR 2010-003|pages=|via=}}</ref> speed up computation. The large processing throughput of GPUs has produced significant speedups in training, because the matrix and vector computations required are well-suited for GPUs.<ref name=\"SCHIDHUB\" /><nowiki/>\\n\\n== Applications ==\\n=== Automatic speech recognition ===\\n{{Main article|Speech recognition}}\\n\\nLarge-scale automatic speech recognition is the first and most convincing successful case of deep learning. LSTM RNNs can learn \"Very Deep Learning\" tasks<ref name=\"SCHIDHUB\"/> that involve multi-second intervals containing speech events separated by thousands of discrete time steps, where one time step corresponds to about 10 ms. LSTM with forget gates<ref name=\":10\" /> is competitive with traditional speech recognizers on certain tasks.<ref name=\"graves2003\"/>\\n\\nThe initial success in speech recognition was based on small-scale recognition tasks based on TIMIT. The data set contains 630 speakers from eight major [[dialect]]s of [[American English]], where each speaker reads 10 sentences.<ref name=\"LDCTIMIT\">\\'\\'TIMIT Acoustic-Phonetic Continuous Speech Corpus\\'\\' Linguistic Data Consortium, Philadelphia.</ref> Its small size allows many configurations to be tried. More importantly, the TIMIT task concerns phone-sequence recognition, which, unlike word-sequence recognition, allows weak language models (without a strong grammar).{{Clarify|reason=terminology|date=June 2017}} This allows the weaknesses in acoustic modeling aspects of speech recognition to be more easily analyzed. The error rates listed below, including these early results and measured as percent phone error rates (PER), have been summarized over the past 20 years:{{Clarify|reason=In what sense is this \"over 20 years\"?|date=October 2017}}\\n\\n{| class=\"wikitable\"\\n|-\\n! Method !! PER (%)\\n|-\\n| Randomly Initialized RNN || 26.1\\n|-\\n| Bayesian Triphone GMM-HMM || 25.6\\n|-\\n| Hidden Trajectory (Generative) Model|| 24.8\\n|-\\n| Monophone Randomly Initialized DNN|| 23.4\\n|-\\n| Monophone DBN-DNN|| 22.4\\n|-\\n| Triphone GMM-HMM with BMMI Training|| 21.7\\n|-\\n| Monophone DBN-DNN on fbank || 20.7\\n|-\\n| Convolutional DNN<ref name=\"CNN-2014\">{{cite journal|last1=Abdel-Hamid|first1=O.|title=Convolutional Neural Networks for Speech Recognition|journal=IEEE/ACM Transactions on Audio, Speech, and Language Processing|date=2014|volume=22|issue=10|pages=1533–1545|doi=10.1109/taslp.2014.2339736|display-authors=etal}}</ref>|| 20.0\\n|-\\n| Convolutional DNN w. Heterogeneous Pooling|| 18.7\\n|-\\n| Ensemble DNN/CNN/RNN<ref name=\"EnsembleDL\">{{cite journal|last2=Platt|first2=J.|date=2014|title=Ensemble Deep Learning for Speech Recognition|url=https://pdfs.semanticscholar.org/8201/55ecb57325503183253b8796de5f4535eb16.pdf|journal=Proc. Interspeech|pages=|via=|last1=Deng|first1=L.}}</ref>|| 18.2\\n|-\\n| Bidirectional LSTM|| 17.9\\n|}\\n\\nThe debut of DNNs for speaker recognition in the late 1990s and speech recognition around 2009-2011 and of LSTM around 2003-2007, accelerated progress in eight major areas:<ref name=\"BOOK2014\" /><ref name=\"interspeech2014Keynote\" /><ref name=\"ReferenceA\" />\\n* Scale-up/out and acclerated DNN training and decoding \\n* Sequence discriminative training \\n* Feature processing by deep models with solid understanding of the underlying mechanisms \\n* Adaptation of DNNs and related deep models \\n* [[Multi-task learning|Multi-task]] and [[Inductive transfer|transfer learning]] by DNNs and related deep models \\n* CNNs and how to design them to best exploit domain knowledge of speech \\n* RNN and its rich LSTM variants \\n* Other types of deep models including tensor-based models and integrated deep generative/discriminative models.\\n\\nAll major commercial speech recognition systems (e.g., Microsoft [[Cortana (software)|Cortana]], [[Xbox]], [[Skype Translator]], [[Amazon Alexa]], [[Google Now]], [[Siri|Apple Siri]], [[Baidu]] and [[IFlytek|iFlyTek]] voice search, and a range of [[Nuance Communications|Nuance]] speech products, etc.) are based on deep learning.<ref name=BOOK2014 /><ref>{{Cite web|url=https://www.wired.com/2014/12/skype-used-ai-build-amazing-new-language-translator/|title=How Skype Used AI to Build Its Amazing New Language Translator {{!}} WIRED|website=www.wired.com|access-date=2017-06-14}}</ref><ref name=\"Baidu\">Hannun et al. (2014) \"Deep Speech: Scaling up end-to-end speech recognition\", {{arxiv|1412.5567}}.</ref><ref>{{Cite web|url=http://research.microsoft.com/en-US/people/deng/ieee-icassp-plenary-2016-mar24-lideng-posted.pdf|title=Plenary presentation at ICASSP-2016|date=|website=|publisher=|access-date=}}</ref>\\n\\n=== Image recognition ===\\n{{Main|Computer vision}}\\n\\nA common evaluation set for image classification is the MNIST database data set. MNIST is composed of handwritten digits and includes 60,000 training examples and 10,000 test examples. As with TIMIT, its small size allows multiple configurations to be tested. A comprehensive list of results on this set is available.<ref name=\"YANNMNIST\">{{cite web|url=http://yann.lecun.com/exdb/mnist/.|title=MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges|website=yann.lecun.com}}</ref>\\n\\nDeep learning-based image recognition has become \"superhuman\", producing more accurate results than human contestants. This first occurred in 2011.<ref name=\":7\">{{Cite journal|last=Cireşan|first=Dan|last2=Meier|first2=Ueli|last3=Masci|first3=Jonathan|last4=Schmidhuber|first4=Jürgen|date=August 2012|title=Multi-column deep neural network for traffic sign classification|url=http://www.sciencedirect.com/science/article/pii/S0893608012000524|journal=Neural Networks|series=Selected Papers from IJCNN 2011|volume=32|pages=333–338|doi=10.1016/j.neunet.2012.02.023}}</ref>\\n\\nDeep learning-trained vehicles now interpret 360° camera views.<ref>[http://www.technologyreview.com/news/533936/nvidia-demos-a-car-computer-trained-with-deep-learning/ Nvidia Demos a Car Computer Trained with \"Deep Learning\"] (2015-01-06), David Talbot, \\'\\'[[MIT Technology Review]]\\'\\'</ref> Another example is Facial Dysmorphology Novel Analysis (FDNA) used to analyze cases of human malformation connected to a large database of genetic syndromes.\\n\\n=== Visual Art Processing ===\\n\\nClosely related to the progress that has been made in image recognition is the increasing application of deep learning techniques to various visual art tasks.  DNNs have proven themselves capable, for example, of a) identifying the style period of a given painting, b) \"capturing\" the style of a given painting and applying it in a visually pleasing manner to an arbitrary photograph, and c) generating striking imagery based on random visual input fields.<ref>{{cite web |url=http://www.mdpi.com/2076-0752/6/2/5|author1=G. W. Smith|author2=Frederic Fol Leymarie|date=10 April 2017|title=The Machine as Artist: An Introduction|publisher=Arts|accessdate=4 October 2017}}</ref><ref>{{cite web |url=http://www.mdpi.com/2076-0752/6/4/18|author=Blaise Agüera y Arcas|date=29 September 2017|title=Art in the Age of Machine Intelligence|publisher=Arts|accessdate=4 October 2017}}</ref>\\n\\n=== Natural language processing ===\\n{{Main|Natural language processing}}\\nNeural networks have been used for implementing language models since the early 2000s.<ref name=\"gers2001\" /><ref>{{Cite journal|last=Bengio|first=Yoshua|last2=Ducharme|first2=Réjean|last3=Vincent|first3=Pascal|last4=Janvin|first4=Christian|date=March 2003|title=A Neural Probabilistic Language Model|url=http://dl.acm.org/citation.cfm?id=944919.944966|journal=J. Mach. Learn. Res.|volume=3|pages=1137–1155|issn=1532-4435}}</ref> LSTM helped to improve machine translation and language modeling.<ref name=\"NIPS2014\" /><ref name=\"vinyals2016\" /><ref name=\"gillick2015\" />\\n\\nOther key techniques in this field are negative sampling<ref name=\"GoldbergLevy2014\">{{cite arXiv|last1=Goldberg|first1=Yoav|last2=Levy|first2=Omar|title=word2vec Explained: Deriving Mikolov et al.’s Negative-Sampling Word-Embedding Method|arxiv=1402.3722}}</ref> and [[word embedding]]. Word embedding, such as \\'\\'[[word2vec]]\\'\\', can be thought of as a representational layer in a deep learning architecture that transforms an atomic word into a positional representation of the word relative to other words in the dataset; the position is represented as a point in a [[vector space]]. Using word embedding as an RNN input layer allows the network to parse sentences and phrases using an effective compositional vector grammar. A compositional vector grammar can be thought of as [[probabilistic context free grammar]] (PCFG) implemented by an RNN.<ref name=\"SocherManning2014\">{{cite web|last1=Socher|first1=Richard|last2=Manning|first2=Christopher|title=Deep Learning for NLP|url=http://nlp.stanford.edu/courses/NAACL2013/NAACL2013-Socher-Manning-DeepLearning.pdf|accessdate=26 October 2014}}</ref> Recursive auto-encoders built atop word embeddings can assess sentence similarity and detect paraphrasing.<ref name=\"SocherManning2014\" /> Deep neural architectures provide the best results for [[Statistical parsing|constituency parsing]],<ref>{{Cite journal |url= http://aclweb.org/anthology/P/P13/P13-1045.pdf|title = Parsing With Compositional Vector Grammars|last = Socher|first = Richard|date = 2013|journal = Proceedings of the ACL 2013 conference|accessdate = |doi = |pmid = |last2 = Bauer|first2 = John|last3 = Manning|first3 = Christopher|last4 = Ng|first4 = Andrew}}</ref> [[sentiment analysis]],<ref>{{Cite journal |url= http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf|title = Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank|last = Socher|first = Richard|date = 2013|journal = EMNLP 2013|accessdate = |doi = |pmid =}}</ref> information retrieval,<ref>{{Cite journal|last=Shen|first=Yelong|last2=He|first2=Xiaodong|last3=Gao|first3=Jianfeng|last4=Deng|first4=Li|last5=Mesnil|first5=Gregoire|date=2014-11-01|title=A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval|url=https://www.microsoft.com/en-us/research/publication/a-latent-semantic-model-with-convolutional-pooling-structure-for-information-retrieval/|journal=Microsoft Research|language=en-US}}</ref><ref>{{Cite journal|last=Huang|first=Po-Sen|last2=He|first2=Xiaodong|last3=Gao|first3=Jianfeng|last4=Deng|first4=Li|last5=Acero|first5=Alex|last6=Heck|first6=Larry|date=2013-10-01|title=Learning Deep Structured Semantic Models for Web Search using Clickthrough Data|url=https://www.microsoft.com/en-us/research/publication/learning-deep-structured-semantic-models-for-web-search-using-clickthrough-data/|journal=Microsoft Research|language=en-US}}</ref> spoken language understanding,<ref name=\"IEEE-TASL2015\">{{cite journal | last1 = Mesnil | first1 = G. | last2 = Dauphin | first2 = Y. | last3 = Yao | first3 = K. | last4 = Bengio | first4 = Y. | last5 = Deng | first5 = L. | last6 = Hakkani-Tur | first6 = D. | last7 = He | first7 = X. | last8 = Heck | first8 = L. | last9 = Tur | first9 = G. | last10 = Yu | first10 = D. | last11 = Zweig | first11 = G. | year = 2015 | title = Using recurrent neural networks for slot filling in spoken language understanding | url= | journal = IEEE Transactions on Audio, Speech, and Language Processing | volume = 23 | issue = 3| pages = 530–539 | doi=10.1109/taslp.2014.2383614}}</ref> machine translation,<ref name=\"NIPS2014\">{{Cite journal|last=Sutskever|first=L.|last2=Vinyals|first2=O.|last3=Le|first3=Q.|date=2014|title=Sequence to Sequence Learning with Neural Networks|url=https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf|journal=Proc. NIPS|pages=|via=}}</ref><ref name=\"auto\">{{Cite journal|last=Gao|first=Jianfeng|last2=He|first2=Xiaodong|last3=Yih|first3=Scott Wen-tau|last4=Deng|first4=Li|date=2014-06-01|title=Learning Continuous Phrase Representations for Translation Modeling|url=https://www.microsoft.com/en-us/research/publication/learning-continuous-phrase-representations-for-translation-modeling/|journal=Microsoft Research|language=en-US}}</ref> contextual entity linking,<ref name=\"auto\"/> writing style recognition<ref name=\"BROC2017\">Brocardo ML, Traore I, Woungang I, Obaidat MS. \"[http://onlinelibrary.wiley.com/doi/10.1002/dac.3259/full Authorship verification using deep belief network systems]\". Int J Commun Syst. 2017. doi:10.1002/dac.3259</ref> and others.<ref>{{Cite news|url=https://www.microsoft.com/en-us/research/project/deep-learning-for-natural-language-processing-theory-and-practice-cikm2014-tutorial/|title=Deep Learning for Natural Language Processing: Theory and Practice (CIKM2014 Tutorial) - Microsoft Research|work=Microsoft Research|access-date=2017-06-14|language=en-US}}</ref>\\n\\n[[Google Translate]] (GT) uses a large [[End-to-end principle|end-to-end]] long short-term memory network.<ref name=\"GT_Turovsky_2016\">{{cite web|url=https://blog.google/products/translate/found-translation-more-accurate-fluent-sentences-google-translate/|title=Found in translation: More accurate, fluent sentences in Google Translate|last=Turovsky|first=Barak|date=November 15, 2016|website=The Keyword Google Blog|publisher=[[Google]]|accessdate=March 23, 2017}}</ref><ref name=\"googleblog_GNMT_2016\">{{cite web|url=https://research.googleblog.com/2016/11/zero-shot-translation-with-googles.html|title=Zero-Shot Translation with Google’s Multilingual Neural Machine Translation System|last1=Schuster|first1=Mike|last2=Johnson|first2=Melvin|date=November 22, 2016|website=Google Research Blog|publisher=[[Google]]|accessdate=March 23, 2017|last3=Thorat|first3=Nikhil}}</ref><ref name=\"lstm1997\">{{Cite journal|author=Sepp Hochreiter|author-link=Sepp Hochreiter|author2=Jürgen Schmidhuber|author2-link=Jürgen Schmidhuber|year=1997|title=Long short-term memory|url=https://www.researchgate.net/publication/13853244_Long_Short-term_Memory|journal=[[Neural Computation (journal)|Neural Computation]]|volume=9|issue=8|pages=1735–1780|doi=10.1162/neco.1997.9.8.1735|pmid=9377276}}</ref><ref name=\"lstm2000\">{{Cite journal|author=Felix A. Gers|author2=Jürgen Schmidhuber|author3=Fred Cummins|year=2000|title=Learning to Forget: Continual Prediction with LSTM|url=http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.55.5709|journal=[[Neural Computation (journal)|Neural Computation]]|volume=12|issue=10|pages=2451–2471|doi=10.1162/089976600300015015}}</ref><ref name=\"GoogleTranslate\">Google\\'s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation (26 Sep 2016): Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Łukasz Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian, Nishant Patil, Wei Wang, Cliff Young, Jason Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado, Macduff Hughes, Jeffrey Dean. https://arxiv.org/abs/1609.08144</ref><ref name=\"WiredGoogleTranslate\">\"An Infusion of AI Makes Google Translate More Powerful Than Ever.\" Cade Metz, WIRED, Date of Publication: 09.27.16. https://www.wired.com/2016/09/google-claims-ai-breakthrough-machine-translation/</ref> GNMT uses an [[example-based machine translation]] method in which the system \"learns from millions of examples.\"<ref name=\"googleblog_GNMT_2016\" /> It translates \"whole sentences at a time, rather than pieces. Google Translate supports over one hundred languages.<ref name=\"googleblog_GNMT_2016\" /> The network encodes the \"semantics of the sentence rather than simply memorizing phrase-to-phrase translations\".<ref name=\"googleblog_GNMT_2016\" /><ref name=\"Biotet\">{{cite web|url=http://www-clips.imag.fr/geta/herve.blanchon/Pdfs/NLP-KE-10.pdf|title=MT on and for the Web|last1=Boitet|first1=Christian|last2=Blanchon|first2=Hervé|date=2010|format=PDF|accessdate=December 1, 2016|last3=Seligman|first3=Mark|last4=Bellynck|first4=Valérie}}</ref> GT can translate directly from one language to another, rather than using English as an intermediate.<ref name=\"Biotet\" />\\n\\n=== Drug discovery and toxicology ===\\n{{For|more information|Drug discovery|Toxicology}}\\nA large percentage of candidate drugs fail to win regulatory approval. These failures are caused by insufficient efficacy (on-target effect), undesired interactions (off-target effects), or unanticipated [[cytotoxicity|toxic effects]].<ref name=\"ARROWSMITH2013\">{{Cite journal\\n| pmid = 23903212\\n| year = 2013\\n| author1 = Arrowsmith\\n| first1 = J\\n| title = Trial watch: Phase II and phase III attrition rates 2011-2012\\n| journal = Nature Reviews Drug Discovery\\n| volume = 12\\n| issue = 8\\n| pages = 569\\n| last2 = Miller\\n| first2 = P\\n| doi = 10.1038/nrd4090\\n}}</ref><ref name=\"VERBIEST2015\">{{Cite journal\\n| pmid = 25582842\\n| year = 2015\\n| author1 = Verbist\\n| first1 = B\\n| title = Using transcriptomics to guide lead optimization in drug discovery projects: Lessons learned from the QSTAR project\\n| journal = Drug Discovery Today\\n| last2 = Klambauer\\n| first2 = G\\n| last3 = Vervoort\\n| first3 = L\\n| last4 = Talloen\\n| first4 = W\\n| last5 = The Qstar\\n| first5 = Consortium\\n| last6 = Shkedy\\n| first6 = Z\\n| last7 = Thas\\n| first7 = O\\n| last8 = Bender\\n| first8 = A\\n| last9 = Göhlmann\\n| first9 = H. W.\\n| last10 = Hochreiter\\n| first10 = S\\n| doi = 10.1016/j.drudis.2014.12.014\\n| volume=20\\n| pages=505–513\\n}}</ref> Research has explored use of deep learning to predict [[Biomolecule|biomolecular]] target,<ref name=\"MERCK2012\" /><ref name=\":5\" /> off-target and toxic effects of environmental chemicals in nutrients, household products and drugs.<ref name=\"TOX21\" /><ref name=\"TOX21Data\" /><ref name=\":11\" />\\n\\nAtomNet is a deep learning system for structure-based [[Drug design|rational drug design]].<ref>{{cite arXiv|title = AtomNet: A Deep Convolutional Neural Network for Bioactivity Prediction in Structure-based Drug Discovery|arxiv= 1510.02855|date = 2015-10-09|first = Izhar|last = Wallach|first2 = Michael|last2 = Dzamba|first3 = Abraham|last3 = Heifets}}</ref> AtomNet was used to predict novel candidate biomolecules for disease targets such as the [[Ebola virus]]<ref>{{Cite web|title = Toronto startup has a faster way to discover effective medicines |url= https://www.theglobeandmail.com/report-on-business/small-business/starting-out/toronto-startup-has-a-faster-way-to-discover-effective-medicines/article25660419/|website = The Globe and Mail |accessdate= 2015-11-09}}</ref> and [[multiple sclerosis]].<ref>{{Cite web|title = Startup Harnesses Supercomputers to Seek Cures |url= http://ww2.kqed.org/futureofyou/2015/05/27/startup-harnesses-supercomputers-to-seek-cures/|website = KQED Future of You|accessdate = 2015-11-09}}</ref><ref>{{cite web|url=https://www.theglobeandmail.com/report-on-business/small-business/starting-out/toronto-startup-has-a-faster-way-to-discover-effective-medicines/article25660419/%5D%20and%20multiple%20sclerosis%20%5B/|title=Toronto startup has a faster way to discover effective medicines|publisher=}}</ref>\\n\\n=== Customer relationship management ===\\n{{Main|Customer relationship management}}\\nDeep reinforcement learning has been used to approximate the value of possible [[direct marketing]] actions, defined in terms of [[RFM (customer value)|RFM]] variables. The estimated value function was shown to have a natural interpretation as [[customer lifetime value]].<ref>{{cite journal|last=Tkachenko |first=Yegor |title=Autonomous CRM Control via CLV Approximation with Deep Reinforcement Learning in Discrete and Continuous Action Space |date=April 8, 2015 |url=http://arxiv.org/abs/1504.01840}}</ref>\\n\\n=== Recommendation systems ===\\n{{Main|Recommender system}}\\nRecommendation systems have used deep learning to extract meaningful features for a latent factor model for content-based music recommendations.<ref>{{Cite book|url=http://papers.nips.cc/paper/5004-deep-content-based-music-recommendation.pdf|title=Advances in Neural Information Processing Systems 26|last=van den Oord|first=Aaron|last2=Dieleman|first2=Sander|last3=Schrauwen|first3=Benjamin|date=2013|publisher=Curran Associates, Inc.|editor-last=Burges|editor-first=C. J. C.|pages=2643–2651|editor-last2=Bottou|editor-first2=L.|editor-last3=Welling|editor-first3=M.|editor-last4=Ghahramani|editor-first4=Z.|editor-last5=Weinberger|editor-first5=K. Q.}}</ref> Multiview deep learning has been applied for learning user preferences from multiple domains.<ref>{{Cite journal|last=Elkahky|first=Ali Mamdouh|last2=Song|first2=Yang|last3=He|first3=Xiaodong|date=2015-05-01|title=A Multi-View Deep Learning Approach for Cross Domain User Modeling in Recommendation Systems|url=https://www.microsoft.com/en-us/research/publication/a-multi-view-deep-learning-approach-for-cross-domain-user-modeling-in-recommendation-systems/|journal=Microsoft Research|language=en-US}}</ref> The model uses a hybrid collaborative and content-based approach and enhances recommendations in multiple tasks.\\n\\n=== Bioinformatics ===\\n{{Main|Bioinformatics}}\\nAn [[autoencoder]] ANN was used in [[bioinformatics]], to predict [[Gene Ontology|gene ontology]] annotations and gene-function relationships.<ref>{{cite journal|url=http://doi.acm.org/10.1145/2649387.2649442|title=Deep Autoencoder Neural Networks for Gene Ontology Annotation Predictions |first1=Davide |last1=Chicco|first2=Peter|last2=Sadowski|first3=Pierre |last3=Baldi |date=1 January 2014|publisher=ACM|pages=533–540|via=ACM Digital Library |doi=10.1145/2649387.2649442|journal=Proceedings of the 5th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics - BCB \\'14}}</ref>\\n\\nIn medical informatics, deep learning was used to predict sleep quality based on data from wearables<ref>{{Cite journal|last=Sathyanarayana|first=Aarti|date=2016-01-01|title=Sleep Quality Prediction From Wearable Data Using Deep Learning|url=http://doi.org/10.2196/mhealth.6562|journal=JMIR mHealth and uHealth|language=en|volume=4|issue=4|doi=10.2196/mhealth.6562|pages=e125}}</ref> and predictions of health complications from [[electronic health record]] data.<ref>{{Cite journal|last=Choi|first=Edward|last2=Schuetz|first2=Andy|last3=Stewart|first3=Walter F.|last4=Sun|first4=Jimeng|date=2016-08-13|title=Using recurrent neural network models for early detection of heart failure onset|url=http://jamia.oxfordjournals.org/content/early/2016/08/13/jamia.ocw112|journal=Journal of the American Medical Informatics Association|language=en|pages=ocw112|doi=10.1093/jamia/ocw112|issn=1067-5027|pmid=27521897}}</ref>\\n\\n=== Mobile Advertising ===\\nFinding the appropriate mobile audience for mobile advertising<ref>{{cite journal|url=http://www.ijstr.org/final-print/apr2016/Using-Deep-Learning-Neural-Networks-To-Find-Best-Performing-Audience-Segments.pdf|journal=IJSTR|volume=5|issue=04}}</ref> is always challenging since there are many data points that need to be considered and assimilated before a target segment can be created and used in ad serving by any ad server. Deep learning has been used to interpret large, many-dimensioned advertising datasets. Many data points are collected during the request/serve/click internet advertising cycle. This information can form the basis of machine learning to improve ad selection.\\n\\n== Relation to human development ==\\nDeep learning is closely related to a class of theories of [[brain development]] (specifically, neocortical development) proposed by [[cognitive neuroscientist]]s in the early 1990s.<ref name=\"UTGOFF\">{{cite journal | last1 = Utgoff | first1 = P. E. | last2 = Stracuzzi | first2 = D. J. | year = 2002 | title = Many-layered learning | url= | journal = Neural Computation | volume = 14 | issue = | pages = 2497–2529 | doi=10.1162/08997660260293319}}</ref><ref name=\"ELMAN\">{{cite book|url={{google books |plainurl=y |id=vELaRu_MrwoC}}|title=Rethinking Innateness: A Connectionist Perspective on Development|last=Elman|first=Jeffrey L.|publisher=MIT Press|year=1998|isbn=978-0-262-55030-7}}</ref><ref name=\"SHRAGER\">{{cite journal | last1 = Shrager | first1 = J. | last2 = Johnson | first2 = MH | year = 1996 | title = Dynamic plasticity influences the emergence of function in a simple cortical array | url= | journal = Neural Networks | volume = 9 | issue = 7| pages = 1119–1129 | doi=10.1016/0893-6080(96)00033-0}}</ref><ref name=\"QUARTZ\">{{cite journal | last1 = Quartz | first1 = SR | last2 = Sejnowski | first2 = TJ | year = 1997 | title = The neural basis of cognitive development: A constructivist manifesto | url= | journal = Behavioral and Brain Sciences | volume = 20 | issue = 4| pages = 537–556 | doi=10.1017/s0140525x97001581}}</ref> These developmental theories were instantiated in computational models, making them predecessors of deep learning systems. These developmental models share the property that various proposed learning dynamics in the brain (e.g., a wave of [[nerve growth factor]]) support the [[self-organization]] somewhat analogous to the neural networks utilized in deep learning models. Like the [[neocortex]], neural networks employ a hierarchy of layered filters in which each layer considers information from a prior layer (or the operating environment), and then passes its output (and possibly the original input), to other layers. This process yields a self-organizing stack of [[transducer]]s, well-tuned to their operating environment. A 1995 description stated, \"...the infant\\'s brain seems to organize itself under the influence of waves of so-called trophic-factors ... different regions of the brain become connected sequentially, with one layer of tissue maturing before another and so on until the whole brain is mature.\"<ref name=\"BLAKESLEE\">S. Blakeslee., \"In brain\\'s early growth, timetable may be critical,\" \\'\\'The New York Times, Science Section\\'\\', pp. B5–B6, 1995.</ref>\\n\\n== Commercial activity ==\\nMany organizations employ deep learning for particular applications. [[Facebook]]\\'s AI lab performs tasks such as [[Automatic image annotation|automatically tagging uploaded pictures]] with the names of the people in them.<ref name=\"METZ2013\">{{cite news|first=C. |last=Metz |title=Facebook\\'s \\'Deep Learning\\' Guru Reveals the Future of AI |url=https://www.wired.com/wiredenterprise/2013/12/facebook-yann-lecun-qa/ |publisher=Wired |date=12 December 2013}}</ref>\\n\\nGoogle\\'s [[DeepMind Technologies]] developed a system capable of learning how to play [[Atari]] video games using only pixels as data input. In 2015 they demonstrated their [[AlphaGo]] system, which learned the game of [[Go (game)|Go]] well enough to beat a professional Go player.<ref>{{Cite web|title = Google AI algorithm masters ancient game of Go |url= http://www.nature.com/news/google-ai-algorithm-masters-ancient-game-of-go-1.19234|website = Nature News & Comment|access-date = 2016-01-30}}</ref><ref>{{Cite journal|title = Mastering the game of Go with deep neural networks and tree search |url=http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html|journal = Nature |date = 2016-01-28|issn = 0028-0836|pages = 484–489|volume = 529|issue = 7587|doi = 10.1038/nature16961|first = David|last = Silver|first2 = Aja|last2 = Huang|first3 = Chris J.|last3 = Maddison|first4 = Arthur|last4 = Guez|first5 = Laurent|last5 = Sifre|first6 = George|last6 = van den Driessche|first7 = Julian|last7 = Schrittwieser|first8 = Ioannis|last8 = Antonoglou|first9 = Veda|last9 = Panneershelvam|pmid=26819042}}</ref><ref>{{Cite web|title = A Google DeepMind Algorithm Uses Deep Learning and More to Master the Game of Go {{!}} MIT Technology Review |url= http://www.technologyreview.com/news/546066/googles-ai-masters-the-game-of-go-a-decade-earlier-than-expected/|website = MIT Technology Review|access-date = 2016-01-30}}</ref> Google Translate uses an LSTM to translate between more than 100 languages.\\n\\nIn 2015, Blippar demonstrated a mobile [[augmented reality]] application that uses deep learning to recognize objects in real time.<ref>{{Cite web|title=Blippar Demonstrates New Real-Time Augmented Reality App|url=https://techcrunch.com/2015/12/08/blippar-demonstrates-new-real-time-augmented-reality-app/|website=TechCrunch}}</ref>\\n\\n== Criticism and comment ==\\nDeep learning has attracted both criticism and comment, in some cases from outside the field of computer science.\\n\\n=== Theory ===\\n{{see also|Explainable AI}}\\nA main criticism concerns the lack of theory surrounding the methods.{{citation needed|date=July 2016}} Learning in the most common deep architectures is implemented using well-understood gradient descent. However, the theory surrounding other algorithms, such as contrastive divergence is less clear.{{citation needed|date=July 2016}} (e.g., Does it converge? If so, how fast? What is it approximating?) Deep learning methods are often looked at as a [[black box]], with most confirmations done empirically, rather than theoretically.<ref name=\"Knight 2017\">{{cite web | last=Knight | first=Will | title=DARPA is funding projects that will try to open up AI’s black boxes | website=MIT Technology Review | date=2017-03-14 | url=https://www.technologyreview.com/s/603795/the-us-military-wants-its-autonomous-machines-to-explain-themselves/ | access-date=2017-11-02}}</ref>\\n\\nOthers point out that deep learning should be looked at as a step towards realizing strong AI, not as an all-encompassing solution. Despite the power of deep learning methods, they still lack much of the functionality needed for realizing this goal entirely. Research psychologist [[Gary Marcus]] noted:<blockquote>\"Realistically, deep learning is only part of the larger challenge of building intelligent machines. Such techniques lack ways of representing [[causality|causal relationships]] (...) have no obvious ways of performing [[inference|logical inferences]], and they are also still a long way from integrating abstract knowledge, such as information about what objects are, what they are for, and how they are typically used. The most powerful A.I. systems, like [[Watson (computer)|Watson]] (...) use techniques like deep learning as just one element in a very complicated ensemble of techniques, ranging from the statistical technique of [[Bayesian inference]] to [[deductive reasoning]].\"<ref>{{Cite web|url=http://www.newyorker.com/|title=Is \"Deep Learning\" a Revolution in Artificial Intelligence?|last=Marcus|first=Gary|date=November 25, 2012|website=|publisher=The New Yorker|access-date=2017-06-14}}</ref></blockquote>As an alternative to this emphasis on the limits of deep learning, one author speculated that it might be possible to train a machine vision stack to perform the sophisticated task of discriminating between \"old master\" and amateur figure drawings, and hypothesized that such a sensitivity might represent the rudiments of a non-trivial machine empathy.<ref>{{cite web|url=http://artent.net/2015/03/27/art-and-artificial-intelligence-by-g-w-smith/|title=Art and Artificial Intelligence|date=March 27, 2015|publisher=ArtEnt|author=Smith, G. W.|accessdate=March 27, 2015|deadurl=bot: unknown|archiveurl=https://web.archive.org/web/20170625075845/http://artent.net/2015/03/27/art-and-artificial-intelligence-by-g-w-smith/|archivedate=June 25, 2017|df=}}</ref> This same author proposed that this would be in line with anthropology, which identifies a concern with aesthetics as a key element of [[behavioral modernity]].<ref>{{cite web |url=http://repositriodeficheiros.yolasite.com/resources/Texto%2028.pdf |author=Mellars, Paul |date=February 1, 2005 |title=The Impossible Coincidence: A Single-Species Model for the Origins of Modern Human Behavior in Europe|publisher=Evolutionary Anthropology: Issues, News, and Reviews |accessdate=April 5, 2017}}</ref>\\n\\nIn further reference to the idea that artistic sensitivity might inhere within relatively low levels of the cognitive hierarchy, a published series of graphic representations of the internal states of deep (20-30 layers) neural networks attempting to discern within essentially random data the images on which they were trained<ref>{{cite web|url=http://googleresearch.blogspot.co.uk/2015/06/inceptionism-going-deeper-into-neural.html |author1=Alexander Mordvintsev |author2=Christopher Olah |author3=Mike Tyka |date=June 17, 2015 |title=Inceptionism: Going Deeper into Neural Networks |publisher=Google Research Blog |accessdate=June 20, 2015}}</ref> demonstrate a visual appeal: the original research notice received well over 1,000 comments, and was the subject of what was for a time the most frequently accessed article on \\'\\'[[The Guardian]]\\'s\\'\\'<ref>{{cite web|url=https://www.theguardian.com/technology/2015/jun/18/google-image-recognition-neural-network-androids-dream-electric-sheep|title=Yes, androids do dream of electric sheep|date=June 18, 2015|publisher=The Guardian|author=Alex Hern|accessdate=June 20, 2015}}</ref> web site.\\n\\n=== Errors ===\\nSome deep learning architectures display problematic behaviors,<ref name=goertzel>{{cite web|first=Ben |last=Goertzel |title=Are there Deep Reasons Underlying the Pathologies of Today\\'s Deep Learning Algorithms? |year=2015 |url=http://goertzel.org/DeepLearning_v1.pdf}}</ref> such as confidently classifying unrecognizable images as belonging to a familiar category of ordinary images<ref>Nguyen, Anh, Jason Yosinski, and Jeff Clune. \"Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images.\" {{arxiv|1412.1897}} (2014).</ref> and misclassifying minuscule perturbations of correctly classified images.<ref>Szegedy, Christian, et al. \"Intriguing properties of neural networks.\" {{arxiv|1312.6199}} (2013).</ref> [[Ben Goertzel|Goertzel]] hypothesized that these behaviors are due to limitations in their internal representations and that these limitations would inhibit integration into heterogeneous multi-component [[Artificial general intelligence|AGI]] architectures.<ref name=\"goertzel\" /> These issues may possibly be addressed by deep learning architectures that internally form states homologous to image-grammar<ref>{{cite journal | last1 = Zhu | first1 = S.C. | last2 = Mumford | first2 = D. | year = | title = A stochastic grammar of images | url= | journal = Found. Trends Comput. Graph. Vis. | volume = 2 | issue = 4| pages = 259–362 | doi = 10.1561/0600000018}}</ref> decompositions of observed entities and events.<ref name=\"goertzel\"/> [[Grammar induction|Learning a grammar]] (visual or linguistic) from training data would be equivalent to restricting the system to [[commonsense reasoning]] that operates on concepts in terms of grammatical [[Production (computer science)|production rules]] and is a basic goal of both human language acquisition<ref>Miller, G. A., and N. Chomsky. \"Pattern conception.\" Paper for Conference on pattern detection, University of Michigan. 1957.</ref> and AI.<ref>{{cite web|first=Jason |last=Eisner |title=Deep Learning of Recursive Structure: Grammar Induction |url=http://techtalks.tv/talks/deep-learning-of-recursive-structure-grammar-induction/58089/}}</ref>\\n\\n=== Cyberthreat ===\\nAs deep learning moves from the lab into the world, artificial neural networks have been shown to be vulnerable to hacks and deception. By identifying patterns that these systems use to function, attackers can modify inputs to ANNs in such a way that the ANN finds a match that human observers would not recognize. For example, an attacker can make subtle changes to an image such that the ANN finds a match even though the image looks to a human nothing like the search target. Such a manipulation is termed an “adversarial attack.” In 2016 researchers used one ANN to doctor images in trial and error fashion, identify another\\'s focal points and thereby generate images that deceived it. The modified images looked no different to human eyes. Another group showed that printouts of doctored images then photographed successfully tricked an image classification system.<ref name=\":4\">{{Cite news|url=https://singularityhub.com/2017/10/10/ai-is-easy-to-fool-why-that-needs-to-change|title=AI Is Easy to Fool—Why That Needs to Change|last=|first=|date=2017-10-10|work=Singularity Hub|access-date=2017-10-11|archive-url=|archive-date=|dead-url=|language=en-US}}</ref> One defense is reverse image search, in which a possible fake image is submitted to a site such as [[TinEye]] that can then find other instances of it. A refinement is to search using only parts of the image, to identify images from which that piece may have been taken\\'\\'\\'.\\'\\'\\'<ref>{{Cite journal|last=Gibney|first=Elizabeth|date=|title=The scientist who spots fake videos|url=https://www.nature.com/news/the-scientist-who-spots-fake-videos-1.22784|journal=Nature|language=en|pages=|doi=10.1038/nature.2017.22784|via=}}</ref>\\n\\nAnother group showed that certain [[Psychedelic art|psychedelic]] spectacles could fool a [[facial recognition system]] into thinking ordinary people were celebrities, potentially allowing one person to impersonate another. In 2017 researchers added stickers to [[stop sign]]s and caused an ANN to misclassify them.<ref name=\":4\" />\\n\\nANNs can however be further trained to detect attempts at deception, potentially leading attackers and defenders into an arms race similar to the kind that already defines the [[malware]] defense industry. ANNs have been trained to defeat ANN-based anti-malware software by repeatedly attacking a defense with malware that was continually altered by a genetic algorithm until it tricked the anti-malware while retaining its ability to damage the target.<ref name=\":4\" />\\n\\nAnother group demonstrated that certain sounds could make the [[Google Now]] voice command system open a particular web address that would download malware.<ref name=\":4\" />\\n\\nIn “data poisoning”, false data is continually smuggled into a machine learning system’s training set to prevent it from achieving mastery.<ref name=\":4\" />\\n\\n==See also==\\n* [[Applications of artificial intelligence]]\\n* [[Artificial neural networks]]\\n* [[Boltzmann machine]]\\n* [[Comparison of deep learning software]]\\n* [[Compressed Sensing]]\\n* [[Echo state network]]\\n* [[List of artificial intelligence projects]]\\n* [[Liquid state machine]]\\n* [[List of datasets for machine learning research]]\\n* [[Reservoir computing]]\\n* [[Sparse coding]]\\n\\n==References==\\n{{Reflist|30em}}\\n\\n==External links==\\n* [https://www.researchgate.net/publication/316471270_Decision_Stream_Cultivating_Deep_Decision_Trees Deep Decision Tree]\\n\\n{{Prone to spam|date=June 2015}}{{Z148}}<!-- {{No more links}}\\n\\nPlease be cautious adding more external links.\\n\\nWikipedia is not a collection of links and should not be used for advertising.\\n\\nExcessive or inappropriate links will be removed.\\n\\n See [[Wikipedia:External links]] and [[Wikipedia:Spam]] for details.\\n\\nIf there are already suitable links, propose additions or replacements on\\nthe article\\'s talk page, or submit your link to the relevant category at\\nDMOZ (dmoz.org) and link there using {{Dmoz}}.\\n\\n-->\\n\\n[[Category:Deep learning| ]]',\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '32472154'},\n",
       " {'article': 'AIVA',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': '{{Infobox artist\\n | name                 = Aiva\\n | nationality  = [[Luxembourgish]]\\n | style = [[Classical music]]\\n | website              = {{URL|www.aiva.ai}}\\n}}\\n\\'\\'\\'AIVA\\'\\'\\' (Artificial Intelligence Virtual Artist) is a [[deep learning]] algorithm applied to music composition. In June 2016, it became the first system of [[algorithmic composition]] to be registered, as a [[composer]], in an authors\\' right Society [[SACEM]].<ref>{{cite web|url=http://www.siliconluxembourg.lu/aiva-the-artificial-intelligence-composing-classical-music/ |title=AIVA the Artificial Intelligence composing Classical Music |date= |accessdate=2016-10-21}}</ref>\\n\\n==Description==\\nCreated in February 2016, AIVA specializes in [[Classical music|Classical]] and [[Symphonic music]] composition.<ref>{{cite web|url=http://www.siliconluxembourg.lu/aiva-the-artificial-intelligence-composing-classical-music/ |title=AIVA the Artificial Intelligence composing Classical Music |date= |accessdate=2016-10-21}}</ref><ref>{{cite web|url=https://iq.intel.fr/aiva-lia-qui-compose-de-la-musique-classique/ |title=AIVA : l’IA qui compose de la musique classique |date= |accessdate=2016-11-29}}</ref> It became the world’s first virtual composer to be recognized by a music society ([[SACEM]]).<ref>{{cite web|url=https://repertoire.sacem.fr/droit-auteur/AIVA%20SYMPHONIC%20FANTASY%20OPUS%207%20THE%20AWAKENING%20IN%20G%20SHARP%20MINOR/3552274701?query=aiva&filters=parties#searchBtn\\n |title=AIVA composer of Classical Music}}</ref><ref>{{cite web|url=https://www.tf1.fr/tf1/jt-we/videos/demain-l-intelligence-artificielle-entre-fascination-apprehension.html\\n |title=TF1 News, subject \"A.I. between fascination and apprehension\" 25th June, 2017}}</ref>\\nBy reading a large collection of existing works of classical music (written by human composers such as [[Bach]], [[Beethoven]], [[Mozart]]) AIVA is capable of understanding concepts of music theory and composing on its own.<ref>{{cite web|url=http://radio.rtl.lu/emissiounen/greis-valerius/1560993.html/1560993.html\\n |title=AIVA - RTL.lu Radio Luxembourg}}</ref><ref>{{cite web|url=https://www.youtube.com/watch?v=RYDyhYaSevU\\n |title=France 2, Stupéfiant ! Les robots vont-ils remplacer les Artistes, 16th May, 2017}}</ref> The algorithm AIVA is based on [[deep learning]] and [[reinforcement learning]] architectures<ref>{{cite web|url=http://www.wort.lu/de/kultur/aiva-une-jeune-start-up-qui-ne-manque-pas-d-ambitions-la-musique-classique-recomposee-57fbba6b5061e01abe83a1c2|title=La musique Classique recomposée |date= |accessdate=2016-10-11}}</ref>\\n\\n== Discography ==\\nAIVA is a published composer;<ref>SACEM Database, https://repertoire.sacem.fr/resultats?filters=parties&query=aiva&nbWorks=20</ref> its first studio album “Genesis” was released in November 2016 and counts 20 original and 4 orchestrated works composed by AIVA. The tracks were recorded by human musicians:\\nOlivier Hecho as the Conductor of the Aiva Sinfonietta Orchestra and [[Eric Breton]] as a Pianist.<ref>CD Aiva album \"Genesis\" released November 2016.</ref><ref>{{cite web|url=https://medium.com/@aivatech/composing-the-music-of-the-future-4af560603988#.t8d6dkxi8 |title=Composing the music of the future |date= |accessdate=2016-09-24}}</ref> \\n[[File:GENESIS_AIVA_CD.jpg|thumb|right|AIVA album \"Genesis\"]]\\n* 2016 CD album « Genesis » Hv-Com – LEPM 048427\\n\\nTrack listing:\\n{{Track listing\\n| headline        = AIVA, \"Genesis\". All compositions by AIVA. Produced by Pierre Barreau\\n| title1          = Celtic Dance, Op. 14, in A minor\\n| length1         = 02:23\\n| title2          = Symphonic Fantasy in G sharp minor, Op. 7, \\'\\'The Awakening\\'\\'\\n| length2         = 03:23\\n| title3          = Symphonic Fantasy in A minor, Op. 21, \\'\\'Genesis\\'\\'\\n| length3         = 02:50\\n| title4          = Octet No. 1 in D major, Op. 3, \"A little chamber music\"\\n| length4         = 01:40\\n| title5          = Aiva, Op. 1 for piano solo in D major\\n| length5         = 04:15\\n| title6          = Aiva Op. 2 for piano solo\\n| length6         = 01:48\\n| title7          = Aiva Op. 3 for piano solo\\n| length7         = 01:31\\n| title8          = Aiva Op. 4 for piano solo\\n| length8         = 01:43\\n| title9          = Aiva Op. 5 for piano solo [or harpsichord]\\n| length9         = 02:08\\n| title10         = Aiva Op. 6 for piano solo\\n| length10        = 01:08\\n| title11         = Aiva Op. 8 For piano solo\\n| length11        = 02:27\\n| title12         = Aiva Op. 9 for piano solo\\n| length12        = 01:51\\n| title13         = Aiva Op. 10 for piano solo\\n| length13        = 03:43\\n| title14         = Aiva Op. 11 for piano solo \"Rhapsody\"\\n| length14        = 03:55\\n| title15         = Variation Op. 12 for piano solo\\n| length15        = 03:00\\n| title16         = Aiva Op. 13 for piano solo\\n| length16        = 02:49\\n| title17         = Aiva Op. 15 for piano solo\\n| length17        = 02:30\\n| title18         = Aiva Op. 16 for piano solo\\n| length18        = 01:55\\n| title19         = Aiva Op. 17 for piano solo\\n| length19        = 03:00\\n| title20         = Aiva Op. 18 for piano solo\\n| length20        = 02:16\\n| title21         = Aiva Op. 19 for piano solo\\n| length21        = 01:45\\n| title22         = Aiva Op. 20 for piano solo\\n| length22        = 01:57\\n| title23         = Aiva Op. 21 for piano solo, \\'\\'Genesis\\'\\'\\n| length23        = 03:00\\n| title24 = Aiva Op. 22 for piano solo\\n| length24        = 03:32\\n}}\\n\\n\\nAvignon Symphonic Orchestra [ORAP] also performed Aiva\\'s compositions[http://www.ledauphine.com/search?q=orap+aiva+intelligence+artificielle&x=1&y=1] in April 2017.<ref>{{Cite news|url=|title=Europe 1 France, chronicle by Thierry Geffrotin, April 16th, 2017|last=|first=|date=|work=|access-date=|archive-url=|archive-date=|dead-url=}}</ref><ref>{{Cite news|url=|title=Le Dauphiné Libéré / Vaucluse Matin, April 17th, 2017, \"De la musique née d\\'un cerveau artificiel\"|last=|first=|date=|work=|access-date=|archive-url=|archive-date=|dead-url=}}</ref>\\n\\n==Example of scores composed by AIVA==\\nThis is the preview of the score Op. n°3 for piano solo \"A little chamber music\", composed by AIVA.\\n\\n[[File:Opus 3 for Piano Solo.pdf|This is the score for AIVA\\'s Opus 3 for Piano Solo, composed by the Artificial Intelligence]]\\n==See also==\\n{{Portal|music|artificial intelligence}}\\n*[[Music and Artificial Intelligence]]\\n*[[Applications of artificial intelligence|Applications of Artificial Intelligence]]\\n*[[Computer Music]]\\n\\n==References==\\n\\n<references />\\n\\n[[Category:Artificial intelligence]]\\n[[Category:Computer music software]]\\n[[Category:Artificial intelligence applications]]\\n[[Category:2016 software]]\\n[[Category:Machine learning]]\\n[[Category:Deep learning]]',\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '52642349'},\n",
       " {'article': 'AlexNet',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': '\\'\\'\\'AlexNet\\'\\'\\' is the name of a [[convolutional neural network]], originally written with [[CUDA]] to run with [[GPU]] support, which competed in the [[ImageNet Large Scale Visual Recognition Challenge]]<ref name=\":0\">{{cite web|url=http://vision.stanford.edu/teaching/cs231b_spring1415/slides/alexnet_tugce_kyunghee.pdf|title=AlexNet}}</ref> in 2012. The network achieved a top-5 error of 15.3%, more than 10.8 percentage points ahead of the runner up. AlexNet was designed by the SuperVision group, consisting of Alex Krizhevsky, Geoffrey Hinton, and Ilya Sutskever.  <ref name =\":1\">{{cite web|url=https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/|title=The data that transformed AI research—and possibly the world}}</ref> <ref name =\":2\">{{cite web|url=http://www.image-net.org/challenges/LSVRC/2012/results.html|title=ILSVRC2012 Results}}</ref> \\n\\n== Network design ==\\nAlexnet contained only 8 layers, first 5 were convolutional layers followed by fully connected layers.<ref>https://cs231n.github.io/convolutional-networks/#case</ref>\\n\\n==References==\\n{{reflist}}\\n\\n[[Category:Neural network software]]\\n[[Category:Deep learning]]\\n[[Category:Neural networks]]\\n[[Category:Object recognition and categorization]]\\n\\n{{software-stub}}',\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '52801963'},\n",
       " {'article': 'Apache SINGA',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': '{{Infobox Software|name=Apache SINGA|logo=Apache Singa Logo.png|caption=SINGA logo|developer=[[Apache Software Foundation]]|status=Active|released={{Start date and age|2015|10|08}}|latest release version={{URL|http://singa.incubator.apache.org/en/downloads.html|1.1.0}}|latest release date={{Start date and age|2017|02|12}}|latest preview version=|latest preview date=|size=|| operating system= [[Linux]], [[Mac OS]], [[Windows]]|programming language=[[C++]], [[Python (programming language)|Python]], [[Java (programming language)|Java]]|genre=|license=[[Apache License]] 2.0|website={{URL|http://singa.incubator.apache.org}}}}\\'\\'\\'SINGA\\'\\'\\' is an Apache Incubating project for developing an open source machine learning library. It provides a flexible architecture for scalable distributed training, is extensible to run over a wide range of hardware, and has a focus on health-care applications.\\n\\n== History ==\\nThe [http://www.comp.nus.edu.sg/~dbsystem/singa/ SINGA project] was initiated by the [http://www.comp.nus.edu.sg/~dbsystem/index.html DB System Group] at National University of Singapore in 2014, in collaboration with the database group of Zhejiang University. It focused on distributed deep learning by partitioning the model and data onto nodes in a cluster and parallelize the training.<ref name=\"singaopen-mm15\">{{cite journal|last2=Tan|first2=Kian-Lee|last3=Sheng|first3=Wang|last4=Wang|first4=Wei|last5=Cai|first5=Qingchao|last6=Chen|first6=Gang|last7=Gao|first7=Jinyang|last8=Luo|first8=Zhaojing|last9=Tung|first9=Anthony K. H.|date=2015|title=SINGA: A distributed deep learning platform|url=http://www.comp.nus.edu.sg/~ooibc/singaopen-mm15.pdf|journal=ACM Multimedia|doi=10.1145/2733373.2807410|last1=Ooi|first1=Beng Chin|last10=Wang|first10=Yuan|last11=Xie|first11=Zhongle|last12=Zhang|first12=Meihui|last13=Zheng|first13=Kaiping|accessdate=8 September 2016}}</ref><ref name=\"singa-mm15.pdf\">{{cite journal|last2=Chen|first2=Gang|last3=Anh Dinh|first3=Tien Tuan|last4=Gao|first4=Jinyang|last5=Ooi|first5=Beng Chin|last6=Tan|first6=Kian-Lee|last7=Sheng|first7=Wang|date=2015|title=SINGA: putting deep learning in the hands of multimedia users|url=http://www.comp.nus.edu.sg/~ooibc/singa-mm15.pdf|journal=ACM Multimedia|doi=10.1145/2733373.2806232|last1=Wei|first1=Wang|accessdate=8 September 2016}}</ref> The prototype was accepted by Apache Incubator in March 2015. Five versions have been released as shown in the following table. Since V1.0, SINGA is general to support traditional machine learning models such as logistic regression. Companies like [[NetEase]]<ref>{{Cite web|url=http://tech.163.com/17/0602/17/CLUL016I00098GJ5.html|title=网易携手Apache SINGA角逐人工智能新战场_网易科技|last=网易|website=tech.163.com|access-date=2017-06-03}}</ref>, [http://www.yzbigdata.com/en/index.html yzBigData] and [https://shentilium.com/ Shentilium] are using SINGA for their applications.\\n\\n{| class=\"wikitable\"\\n|-\\n! Version\\n! Original release date\\n! Latest version\\n! Release date\\n|-\\n|{{Version|c|1.1.0}}\\n|2017-02-12\\n|1.1.0\\n|2017-02-12\\n|-\\n| {{Version|co|1.0.0}}\\n| 2016-09-08\\n| 1.0.0\\n| 2016-09-08\\n|-\\n| {{Version|co|0.3.0}}\\n| 2016-04-20\\n| 0.1.0\\n| 2016-04-20\\n|-\\n| {{Version|o|0.2.0}}\\n| 2016-01-14\\n| 0.2.0\\n| 2016-01-14\\n|-\\n| {{Version|o|0.1.0}}\\n| 2015-10-08\\n| 0.1.0\\n| 2015-10-08\\n|-\\n| colspan=\"5\" | <small>{{Version |l |show=111110}}</small>\\n|}\\n\\n== Software Stack ==\\nSINGA\\'s software stack includes three major components, namely, core, IO and model. The following figure illustrates these components together with the hardware. The core component provides memory management and tensor operations; IO has classes for reading (and writing) data from (to) disk and network; The model component provides data structures and algorithms for machine learning models, e.g., layers for neural network models, optimizers/initializer/metric/loss for general machine learning models.\\n\\n[[File:Singav1-sw.png|Apache Singa software stack|center|frameless|400x400px]]\\n\\n== Using SINGA ==\\n\\nTo get started with SINGA, there are some [http://nbviewer.jupyter.org/github/apache/incubator-singa/blob/master/doc/en/docs/notebook/index.ipynb tutorials] available as [[Jupyter]] notebooks. The tutorials cover the following:\\n\\n* [http://nbviewer.jupyter.org/github/apache/incubator-singa/blob/master/doc/en/docs/notebook/core.ipynb Core classes]\\n* [http://nbviewer.jupyter.org/github/apache/incubator-singa/blob/master/doc/en/docs/notebook/model.ipynb Model classes]\\n* [http://nbviewer.jupyter.org/github/apache/incubator-singa/blob/master/doc/en/docs/notebook/regression.ipynb Linear Regression]\\n* [http://nbviewer.jupyter.org/github/apache/incubator-singa/blob/master/doc/en/docs/notebook/mlp.ipynb Multi-layer Perceptron]\\n* [http://nbviewer.jupyter.org/github/apache/incubator-singa/blob/master/doc/en/docs/notebook/cnn.ipynb Convolutional Neural Network (CNN)]\\n* [http://nbviewer.jupyter.org/github/apache/incubator-singa/blob/master/doc/en/docs/notebook/rnn.ipynb Recurrent Neural Networks (RNN)]\\n* [http://nbviewer.jupyter.org/github/apache/incubator-singa/blob/master/doc/en/docs/notebook/rbm.ipynb Restricted Boltzmann Machine (RBM)]\\n  \\n== See also ==\\n* [[List of Apache Software Foundation projects]]\\n* [[Comparison of deep learning software]]\\n\\n== References ==\\n{{reflist}}\\n\\n==External links==\\n* {{Official website|http://singa.incubator.apache.org/en/index.html}}\\n\\n{{Apache}}\\n{{Deep_Learning_Software}}\\n\\n[[Category:Apache Software Foundation projects]]\\n[[Category:Free software]]\\n[[Category:Deep learning]]',\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '51545339'},\n",
       " {'article': 'BigDL',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': \"{{Infobox software\\n| name                   = BigDL\\n| developer              = Intel\\n| genre                  = Library for [[deep learning]]\\n| license                = [[Apache 2.0]]<ref>{{cite web|title=BigDL LICENSE|url=https://github.com/intel-analytics/BigDL/blob/master/LICENSE|work=GitHub}}</ref>\\n| website                = {{url|title=BigDL: Distributed Deep Learning Library for Apache Spark|https://software.intel.com/en-us/ai-academy/training/frameworks/bigdl}}\\n}}\\n\\n{{machine learning bar}}\\n\\n'''BigDL''' is a deep learning framework, developed a.o. by Jason Dai and Sergey Ermolin<ref>{{url|title=BigDL: Distributed Deep Learning Library for Apache Spark|https://software.intel.com/en-us/ai-academy/training/frameworks/bigdl}}</ref> at [[Intel]].\\n== History ==\\nIt is hosted at [[GitHub]].<ref>{{cite web|title=BigDL: Distributed Deep Learning Library for Apache Spark|url=https://github.com/intel-analytics/BigDL|publisher=GitHub}}</ref>\\n\\n== Features ==\\n\\n== Applications ==\\n\\n==See also==\\n* [[Comparison of deep learning software]]\\n\\n==References==\\n{{Reflist}}\\n\\n==External links==\\n* \\n\\n{{Deep Learning Software}}\\n\\n{{DEFAULTSORT:BigDL}}\\n[[Category:Applied machine learning]]\\n[[Category:Artificial neural networks]]\\n[[Category:Data mining and machine learning software]]\\n[[Category:Deep learning]]\\n[[Category:Free science software]]\\n[[Category:Free statistical software]]\\n[[Category:Image processing]]\\n[[Category:Information technology companies of the United States]]\\n[[Category:Machine learning]]\",\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '55075082'},\n",
       " {'article': 'Caffe (software)',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': \"{{Infobox software\\n| name                   = Caffe\\n| logo                   = \\n| screenshot             =\\n| caption                =\\n| collapsible            =\\n| author                 = Yangqing Jia\\n| developer              = Berkeley Vision and Learning Center\\n| released               = \\n| latest release version = 1.0<ref>{{cite web|url=https://github.com/BVLC/caffe/releases/tag/1.0|title=Release 1.0}}</ref>\\n| latest release date    = {{Start date and age|2017|04|18|df=yes}}\\n| latest preview version = \\n| latest preview date    = \\n| frequently updated     = <!-- DO NOT include this parameter unless you know what it does -->\\n| programming language   = [[C++]]\\n| operating system       = [[Linux]], [[macOS]], [[Microsoft Windows|Windows]]<ref>{{cite web|url=https://github.com/Microsoft/caffe|title=Microsoft/caffe|work=GitHub}}</ref>\\n| platform               =\\n| size                   =\\n| language               =\\n| status                 =\\n| genre                  = Library for [[deep learning]]\\n| license                = [[BSD License|BSD]]<ref>{{cite web|url=https://github.com/BVLC/caffe/blob/master/LICENSE|title=caffe/LICENSE at master|work=GitHub}}</ref>\\n| website                = {{url|http://caffe.berkeleyvision.org/}}\\n}}\\n\\n{{machine learning bar}}\\n\\n'''Caffe''' is a deep learning framework, originally developed at UC Berkeley. It is [[open source]], under a [[BSD license]].<ref>{{cite web|url=https://github.com/BVLC/caffe/|title=BVLC/caffe|work=GitHub}}</ref> It is written in [[C++]], with a [[Python (programming language)|Python]] interface.<ref>{{cite web|url=https://deeplearning4j.org/compare-dl4j-torch7-pylearn#caffe|title=Comparing Frameworks: Deeplearning4j, Torch, Theano, TensorFlow, Caffe, Paddle, MxNet, Keras & CNTK}}</ref>\\n\\n== History ==\\nYangqing Jia created the caffe project during his PhD at UC Berkeley.<ref>{{cite web|title=The Caffe Deep Learning Framework: An Interview with the Core Developers|url=http://www.embedded-vision.com/industry-analysis/technical-articles/caffe-deep-learning-framework-interview-core-developers|publisher=Embedded Vision}}</ref> Now there are many contributors to the project, and it is hosted at [[GitHub]].<ref>{{cite web|title=Caffe: a fast open framework for deep learning.|url=https://github.com/BVLC/caffe|publisher=GitHub}}</ref>\\n\\n== Features ==\\nCaffe supports many different types of deep learning architectures geared towards [[image classification]] and [[image segmentation]]. It supports [[Convolutional neural network|CNN]], RCNN, [[LSTM]] and fully connected neural network designs.<ref>{{cite web|title=Caffe tutorial - vision.princeton.edu|url=https://vision.princeton.edu/courses/COS598/2015sp/slides/Caffe/caffe_tutorial.pdf|archiveurl=https://web.archive.org/web/20170405073658/https://vision.princeton.edu/courses/COS598/2015sp/slides/Caffe/caffe_tutorial.pdf|archivedate=April 5, 2017}}</ref> Caffe supports GPU based accleration using CuDNN of Nvidia.<ref>{{cite web|title=Deep Learning for Computer Vision with Caffe and cuDNN|url=https://devblogs.nvidia.com/parallelforall/deep-learning-computer-vision-caffe-cudnn/}}</ref>\\n\\n== Applications ==\\nCaffe is being used in academic research projects, startup prototypes, and even large-scale industrial applications in vision, speech, and multimedia. [[Yahoo!]] has also integrated caffe with [[Apache Spark]] to create CaffeOnSpark, a distributed deep learning framework.<ref>{{cite news|title=Yahoo enters artificial intelligence race with CaffeOnSpark|url=https://jaxenter.com/yahoo-enters-artificial-intelligence-race-with-caffeonspark-124324.html}}</ref>\\n\\nIn April 2017, Facebook announced [[Caffe2]],<ref>{{cite web|url=http://caffe2.ai/blog/2017/04/18/caffe2-open-source-announcement.html|title=Caffe2 Open Source Brings Cross Platform Machine Learning Tools to Developers}}</ref> which includes new features such as [[Recurrent neural network|Recurrent Neural Networks]].\\n\\n==See also==\\n* [[Comparison of deep learning software]]\\n\\n==References==\\n{{Reflist}}\\n\\n==External links==\\n* {{Official website|http://caffe.berkeleyvision.org/}} (GitHub)\\n\\n{{Deep Learning Software}}\\n\\n{{DEFAULTSORT:Caffe}}\\n[[Category:Applied machine learning]]\\n[[Category:Artificial neural networks]]\\n[[Category:Data mining and machine learning software]]\\n[[Category:Deep learning]]\\n[[Category:Free science software]]\\n[[Category:Free statistical software]]\\n[[Category:Image processing]]\\n[[Category:Information technology companies of the United States]]\\n[[Category:Machine learning]]\",\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '53631046'},\n",
       " {'article': 'Comparison of deep learning software',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': 'The following table compares some of the most popular [[software framework]]s, [[software library|libraries]] and [[computer program]]s for [[deep learning]].\\n\\n<!-- This is a list of software with a corresponding Wikipedia article -->\\n\\n==Deep learning software by name==\\n\\n{| class=\"wikitable sortable\" style=\"text-align: center; font-size: 85%; width: auto; table-layout: fixed;\"\\n|-\\n! style=\"width: 12em\" | Software\\n! Creator\\n! Software license{{efn|name=\"license\"|Licenses here are a summary, and are not taken to be complete statements of the licenses. Some libraries may use other libraries internally under different licenses}}\\n! Open source\\n! Platform\\n! Written in\\n! Interface\\n! [[OpenMP]] support\\n! [[OpenCL]] support\\n! [[CUDA]] support\\n! [[Automatic differentiation]]<ref>{{cite arXiv |author1=Atilim Gunes Baydin |author2=Barak A. Pearlmutter |author3=Alexey Andreyevich Radul |author4=Jeffrey Mark Siskind |eprint=1502.05767 |title=Automatic differentiation in machine learning: a survey |class=cs.LG |date=20 February 2015}}</ref>\\n! Has pretrained models\\n! [[Recurrent neural network|Recurrent net]]s\\n! [[Convolutional neural network|Convolutional nets]]\\n! [[Restricted Boltzmann machine|RBM]]/[[deep belief network|DBNs]]\\n! Parallel execution (multi node)\\n|-\\n| [[Caffe (software)|Caffe]]\\n| Berkeley Vision and Learning Center\\n| {{Free|[[BSD license]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Microsoft Windows|Windows]]<ref>{{cite web|url=https://github.com/Microsoft/caffe|title=Microsoft/caffe|work=GitHub}}</ref>\\n| [[C++]]\\n| [[Python (programming language)|Python]], [[MATLAB]]\\n| {{Yes}}\\n| {{Depends|Under development<ref>{{cite web|url=https://github.com/BVLC/caffe/tree/opencl|title=OpenCL Caffe}}</ref>}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>{{cite web|url=http://caffe.berkeleyvision.org/model_zoo.html|title=Caffe Model Zoo}}</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{No}}\\n| {{Dunno}}\\n|-\\n| [[Caffe2 (software)|Caffe2]]\\n| Facebook\\n| {{Free|[[Apache 2.0]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Microsoft Windows|Windows]]<ref>{{cite web|url=https://github.com/caffe2/caffe2|title=Caffe2 Github Repo}}</ref>\\n| [[C++]], [[Python (programming language)|Python]]\\n| [[Python (programming language)|Python]], [[MATLAB]]\\n| {{Yes}}\\n| {{Depends|Under development<ref>{{cite web|url=https://github.com/BVLC/caffe/tree/opencl|title=OpenCL Caffe}}</ref>}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>{{cite web|url=http://caffe.berkeleyvision.org/model_zoo.html|title=Caffe Model Zoo}}</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{No}}\\n| {{Yes}}\\n|-\\n| [[Deeplearning4j]] \\n| Skymind engineering team; Deeplearning4j community; originally [[Adam Gibson (computer scientist)|Adam Gibson]]\\n| {{Free|[[Apache 2.0]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Windows]], [[Android (operating system)|Android]] ([[Cross-platform]])\\n| [[C++]], [[Java (programming language)|Java]]\\n| [[Java (programming language)|Java]], [[Scala (programming language)|Scala]], [[Clojure (programming language)|Clojure]], [[Python (programming language)|Python]] ([[Keras]]), [[Kotlin (programming language)|Kotlin]]\\n| {{Yes}}\\n| {{No|On roadmap}}<ref>{{cite web|url=https://github.com/deeplearning4j/nd4j/issues/27|title=Support for Open CL · Issue #27 · deeplearning4j/nd4j|work=GitHub}}</ref>\\n| {{Yes}}<ref>{{cite web|url=http://nd4j.org/gpu_native_backends.html|title=N-Dimensional Scientific Computing for Java|publisher=}}</ref><ref>{{cite web|url=https://deeplearning4j.org/compare-dl4j-tensorflow-pytorch|title=Comparing Top Deep Learning Frameworks|publisher=Deeplearning4j}}</ref>\\n| {{Yes|Computational Graph}}\\n| {{Yes}}<ref>{{cite web|url=http://deeplearning4j.org/model-zoo|title=Deeplearning4j Models|author1=Chris Nicholson|author2= Adam Gibson|publisher=}}</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>{{cite web|url=http://deeplearning4j.org/spark|title=Deeplearning4j on Spark|author=Deeplearning4j|publisher=Deeplearning4j}}</ref>\\n|-\\n|[[Dlib]]\\n|Davis King\\n| {{Free|[[Boost Software License]]}}\\n| {{Yes}}\\n|[[Cross-platform|Cross-Platform]]\\n|[[C++]]\\n|[[C++]]\\n| {{Yes}}\\n| {{No}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{No}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n|-\\n|[[Gensim]]\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|-\\n| [[Keras]]\\n| François Chollet\\n| {{Free|[[MIT license]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Windows]]\\n| [[Python (programming language)|Python]]\\n| [[Python (programming language)|Python]], [[R (programming language)|R]]\\n| {{Depends|Only if using Theano or MXNet as backend}}\\n| {{Depends|Under development for the Theano backend (and on roadmap for the TensorFlow backend)}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>https://keras.io/applications/</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>[https://github.com/fchollet/keras/issues/2436 Does Keras support using multiple GPUs? · Issue #2436 · fchollet/keras]</ref>\\n|-\\n| [[MatConvNet]] \\n| [[Andrea Vedaldi]], [[Karel Lenc]]\\n| {{Free|[[BSD license]]}}\\n| {{Yes}}\\n| [[Microsoft Windows|Windows]], [[Linux]]<ref name=\"Setup CNTK on your machine\">{{cite web|url=https://github.com/Microsoft/CNTK/wiki/Setup-CNTK-on-your-machine|title=Setup CNTK on your machine|work=GitHub}}</ref> ([[macOS]] via Docker on roadmap)\\n| [[C++]]\\n| [[MATLAB]], [[C++]],\\n| {{No}}\\n| {{No}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{No}}\\n| {{Yes}}\\n|-\\n| [[Microsoft Cognitive Toolkit]] \\n| [[Microsoft Research]]\\n| {{Free|[[MIT license]]}}<ref>{{cite web|url=https://github.com/Microsoft/CNTK/blob/master/LICENSE.md|title=CNTK/LICENSE.md at master · Microsoft/CNTK · GitHub|work=GitHub}}</ref>\\n| {{Yes}}\\n| [[Microsoft Windows|Windows]], [[Linux]]<ref name=\"Setup CNTK on your machine\"/> ([[macOS]] via Docker on roadmap)\\n| [[C++]]\\n| [[Python (programming language)|Python (]][[Keras]]), [[C++]],  [[Command line]],<ref>{{cite web|url=https://github.com/Microsoft/CNTK/wiki/CNTK-usage-overview|title=CNTK usage overview|work=GitHub}}</ref> BrainScript<ref>{{cite web|url=https://github.com/Microsoft/CNTK/wiki/BrainScript-Network-Builder|title=BrainScript Network Builder|work=GitHub}}</ref> ([[.NET Framework|.NET]] on roadmap<ref>{{cite web|url=https://github.com/Microsoft/CNTK/issues/960|title=.NET Support · Issue #960 · Microsoft/CNTK|work=GitHub}}</ref>)\\n| {{Yes}}<ref>{{cite web|url=https://github.com/Microsoft/CNTK/issues/59#issuecomment-178104505|title=How to train a model using multiple machines? · Issue #59 · Microsoft/CNTK|work=GitHub}}</ref>\\n| {{No}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>https://github.com/Microsoft/CNTK/issues/140#issuecomment-186466820</ref>\\n| {{Yes}}<ref name=\"cntk.ai\">{{cite web|url=http://www.cntk.ai/|title=CNTK - Computational Network Toolkit|publisher=Microsoft Corporation}}</ref>\\n| {{Yes}}<ref name=\"cntk.ai\" />\\n| {{No}}<ref>url=https://github.com/Microsoft/CNTK/issues/534</ref>\\n| {{Yes}}<ref>{{cite web|url=https://github.com/Microsoft/CNTK/wiki/Multiple-GPUs-and-machines|title=Multiple GPUs and machines|publisher=Microsoft Corporation}}</ref>\\n|-\\n| [[MXNet]]\\n| Distributed (Deep) Machine Learning Community\\n| {{Free|[[Apache 2.0]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Windows]],<ref>{{cite web|url=https://github.com/dmlc/mxnet/releases|title=Releases · dmlc/mxnet|work=Github}}</ref><ref>{{cite web|url=http://mxnet.readthedocs.io/en/latest/how_to/build.html#building-on-windows|title=Installation Guide — mxnet documentation|work=Readthdocs}}</ref> [[Amazon Web Services|AWS]], [[Android (operating system)|Android]],<ref>{{cite web|url=https://mxnet.readthedocs.io/en/latest/how_to/smart_device.html|title=MXNet Smart Device|work=ReadTheDocs}}</ref> [[iOS]], [[File manager|JavaScript]]<ref>{{cite web|url=https://github.com/dmlc/mxnet.js|title=MXNet.js|work=Github}}</ref>\\n| Small [[C++]] core library\\n| [[C++]], [[Python (programming language)|Python]], [[Julia (programming language)|Julia]], [[Matlab]], [[JavaScript]], [[Go (programming language)|Go]], [[R (programming language)|R]], [[Scala (programming language)|Scala]], [[Perl (programming language)|Perl]]\\n| {{Yes}}\\n| {{No|On roadmap}}<ref>{{cite web|url=https://github.com/dmlc/mxnet/issues/621|title=Support for other Device Types, OpenCL AMD GPU · Issue #621 · dmlc/mxnet|work=GitHub}}</ref>\\n| {{Yes}}\\n| {{Yes}}<ref>http://mxnet.readthedocs.io/</ref>\\n| {{Yes}}<ref>{{cite web|url=https://github.com/dmlc/mxnet-model-gallery|title=Model Gallery|work=GitHub}}</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>{{cite web|url=http://mxnet.readthedocs.io/en/latest/how_to/multi_devices.html|title=Run MXNet on Multiple CPU/GPUs with Data Parallel|work=GitHub}}</ref>\\n|-\\n| [[Neural Designer]]\\n| Artelnics\\n| {{Proprietary}}\\n| {{No}}\\n| [[Linux]], [[macOS]], [[Microsoft Windows|Windows]]\\n| [[C++]]\\n| [[Graphical user interface]]\\n| {{Yes}}\\n| {{No}}\\n| {{No}}\\n| {{Dunno}}\\n| {{Dunno}}\\n| {{No}}\\n| {{No}}\\n| {{No}}\\n| {{Dunno}}\\n|-\\n| [[OpenNN]]\\n| Artelnics\\n| {{Free|[[GNU Lesser General Public License|GNU LGPL]]}}\\n| {{Yes}}\\n| [[Cross-platform]]\\n| [[C++]]\\n| [[C++]]\\n| {{Yes}}\\n| {{No}}\\n| {{No}}\\n| {{Dunno}}\\n| {{Dunno}}\\n| {{No}}\\n| {{No}}\\n| {{No}}\\n| {{Dunno}}\\n|-\\n|Paddle\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|-\\n|Pytorch\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|\\n|-\\n| [[Apache SINGA]]\\n| [[Apache Incubator]]\\n| {{Free|[[Apache 2.0]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Windows]]\\n| [[C++]]\\n| [[Python (programming language)|Python]], [[C++]], [[Java (programming language)|Java]]\\n| {{No}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Dunno}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n|-\\n| [[TensorFlow]]\\n| [[Google Brain]] team\\n| {{Free|[[Apache 2.0]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Microsoft Windows|Windows]]<ref>https://developers.googleblog.com/2016/11/tensorflow-0-12-adds-support-for-windows.html</ref>\\n| [[C++]], [[Python (programming language)|Python]]\\n| [[Python (programming language)|Python]] ([[Keras]]), [[C (programming language)|C]]/[[C++]], [[Java (programming language)|Java]], [[Go (programming language)|Go]], [[R (programming language)|R]]<ref>{{Citation|last=interface)|first=JJ Allaire (R|title=tensorflow: R Interface to TensorFlow|date=2017-05-26|url=https://cran.r-project.org/web/packages/tensorflow/index.html|last2=RStudio|last3=Eddelbuettel|last4=Golding|last5=Tang|last6=Tutorials)|first3=Dirk|first4=Nick|first5=Yuan|first6=Google Inc (Examples and|accessdate=2017-06-14}}</ref>\\n| {{No}}\\n| {{Depends|On roadmap}}<ref name=\"tensorflow-roadmap\">{{cite web|url=https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/about/roadmap.md|title=tensorflow/roadmap.md at master · tensorflow/tensorflow · GitHub | work=GitHub | date=January 23, 2017 | access-date=May 21, 2017}}</ref> but already with [[SYCL]]<ref name=\"GitHub\">{{cite web|url=https://github.com/tensorflow/tensorflow/issues/22|title=OpenCL support · Issue #22 · tensorflow/tensorflow|work=GitHub}}</ref> support\\n| {{Yes}}\\n| {{Yes}}<ref>https://www.tensorflow.org/</ref>\\n| {{Yes}}<ref>https://github.com/tensorflow/models</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n|-\\n| [[Theano (software)|Theano]]\\n| [[Université de Montréal]]\\n| {{Free|[[BSD Licenses|BSD license]]}}\\n| {{Yes}}\\n| [[Cross-platform]]\\n| [[Python (programming language)|Python]]\\n| [[Python (programming language)|Python]] ([[Keras]])\\n| {{Yes}}\\n| {{Depends|Under development<ref>{{cite web|url=http://deeplearning.net/software/theano/tutorial/using_gpu.html|title=Using the GPU — Theano 0.8.2 documentation|publisher=}}</ref>}}\\n| {{Yes}}\\n| {{Yes}}<ref>http://deeplearning.net/software/theano/library/gradient.html</ref><ref>https://groups.google.com/d/msg/theano-users/mln5g2IuBSU/gespG36Lf_QJ</ref>\\n| {{Depends|Through Lasagne\\'s model zoo<ref>{{cite web|url=https://github.com/Lasagne/Recipes/tree/master/modelzoo|title=Recipes/modelzoo at master · Lasagne/Recipes · GitHub|work=GitHub}}</ref>}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>[http://deeplearning.net/software/theano/tutorial/using_multi_gpu.html Using multiple GPUs — Theano 0.8.2 documentation]</ref>\\n|-\\n| [[Torch (machine learning)|Torch]]\\n| Ronan Collobert, Koray Kavukcuoglu, Clement Farabet\\n| {{Free|[[BSD Licenses|BSD license]]}}\\n| {{Yes}}\\n| [[Linux]], [[macOS]], [[Microsoft Windows|Windows]],<ref>https://github.com/torch/torch7/wiki/Windows</ref> [[Android (operating system)|Android]],<ref>{{cite web|url=https://github.com/soumith/torch-android|title=GitHub - soumith/torch-android: Torch-7 for Android|work=GitHub}}</ref> [[iOS]]\\n| [[C (programming language)|C]], [[Lua (programming language)|Lua]]\\n| [[Lua (programming language)|Lua]], [[Lua (programming language)|LuaJIT]],<ref>{{cite web|url=http://ronan.collobert.com/pub/matos/2011_torch7_nipsw.pdf|title=Torch7: A Matlab-like Environment for Machine Learning}}</ref> [[C (programming language)|C]], utility library for [[C++]]/[[OpenCL]]<ref name=jtorch>{{cite web|url=https://github.com/jonathantompson/jtorch|title=GitHub - jonathantompson/jtorch: An OpenCL Torch Utility Library|work=GitHub}}</ref>\\n| {{Yes}}\\n| {{Depends|Third party implementations<ref>{{cite web|url=https://github.com/torch/torch7/wiki/Cheatsheet#opencl|title=Cheatsheet|work=GitHub}}</ref><ref>{{cite web|url=https://github.com/hughperkins/distro-cl|title=cltorch|work=GitHub}}</ref>}}\\n| {{Yes}}<ref>{{cite web|url=https://github.com/torch/cutorch|title=Torch CUDA backend|work=GitHub}}</ref><ref>{{cite web|url=https://github.com/torch/cunn|title=Torch CUDA backend for nn|work=GitHub}}</ref>\\n| {{Yes|Through [[Twitter]]\\'s Autograd<ref>https://github.com/twitter/torch-autograd</ref>}}\\n| {{Yes}}<ref>{{cite web|url=https://github.com/torch/torch7/wiki/ModelZoo|title=ModelZoo|work=GitHub}}</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>https://github.com/torch/torch7/wiki/Cheatsheet#distributed-computing--parallel-processing</ref>\\n|-\\n| [[Wolfram Mathematica]]\\n| [[Wolfram Research]]\\n| {{Proprietary}}\\n| {{No}}\\n| [[Microsoft Windows|Windows]], [[macOS]], [[Linux]], [[Cloud computing]]\\n| [[C++]]\\n| [[Wolfram Language]]\\n| {{No}}\\n| {{No}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}<ref>http://blog.stephenwolfram.com/2017/03/the-rd-pipeline-continues-launching-version-11-1/</ref>\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n| {{Yes}}\\n|}\\n\\n{{See also|Comparison of deep learning software/Resources}}\\n\\n{{notelist}}\\n\\n==Related software==\\n* [[Neural Engineering Object]] (NENGO) – A graphical and scripting software for simulating large-scale neural systems\\n* [[Numenta Platform for Intelligent Computing]] – Numenta\\'s open source implementation of their [[hierarchical temporal memory]] model\\n\\n==See also==\\n*[[Comparison of numerical analysis software]]\\n*[[Comparison of statistical packages]]\\n*[[List of datasets for machine learning research]]\\n*[[List of numerical analysis software]]\\n\\n==References==\\n{{reflist|33em}}\\n\\n[[Category:Applied machine learning]]\\n[[Category:Comparisons of mathematical software|Deep learning frameworks]]\\n[[Category:Data mining and machine learning software]]\\n[[Category:Deep learning]]',\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '49119569'},\n",
       " {'article': 'Deeplearning4j',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': '{{news release|1=article|date=November 2017}}\\n{{Infobox software\\n| name                   = Deeplearning4j\\n| logo                   = \\n| screenshot             = \\n| caption                =\\n| collapsible            =\\n| author                 = [[Adam Gibson (computer scientist)|Adam Gibson]], [[Chris Nicholson (entrepreneur)|Chris Nicholson]], Josh Patterson\\n| developer              = [https://github.com/SkymindIO/deeplearning4j/graphs/contributors Various]\\n| released               = <!-- {{Start date and age|YYYY|MM|DD|df=yes}} -->\\n| latest release version = 0.9.1\\n| latest release date    = {{Start date and age|2017|8|13|df=yes}}\\n| latest preview version = \\n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD|df=yes}} -->\\n| frequently updated     = <!-- DO NOT include this parameter unless you know what it does -->\\n| programming language   = [[Java (programming language)|Java]], [[Scala (programming language)|Scala]], [[CUDA]], [[C (programming language)|C]], [[C++]], [[Python (programming language)|Python]], [[Clojure]]\\n| operating system       = [[Linux]], [[macOS]], [[Microsoft Windows|Windows]], [[Android (operating system)|Android]]\\n| platform               = [[Cross-platform]]\\n| size                   =\\n| language               = English\\n| status                 = Active\\n| genre                  = [[Natural language processing]], [[deep learning]], [[machine vision]], [[artificial intelligence]]\\n| license                = [[Apache License|Apache]] 2.0\\n| website                = {{URL|deeplearning4j.org}}\\n}}\\n\\n{{machine learning bar}}\\nEclipse \\'\\'\\'Deeplearning4j\\'\\'\\' is a [[deep learning]] programming [[Library (computing)|library]] written for [[Java (programming language)|Java]] and the [[Java virtual machine]] (JVM)<ref name=\"wired\">{{cite web|first=Cade|last=Metz|title=The Mission to Bring Google\\'s AI to the Rest of the World|work=[[Wired.com]]|date=2014-06-02|url=https://www.wired.com/2014/06/skymind-deep-learning/|accessdate=2014-06-28}}</ref><ref>{{cite web|url=http://www.businessweek.com/articles/2014-06-03/teaching-smaller-companies-how-to-probe-deep-learning-on-their-own|title=Deep Learning for (Some of) the People|last=Vance|first=Ashlee|work=[[Bloomberg Businessweek]]|date=2014-06-03|accessdate=2014-06-28}}</ref> and a [[computing]] framework with wide support for [[deep learning]] algorithms.<ref>{{cite web|url=https://venturebeat.com/2015/11/14/deep-learning-frameworks/|title=Want an open-source deep learning framework? Take your pick|last=Novet|first=Jordan|work=[[VentureBeat]]|date=2015-11-14|accessdate=2015-11-24}}</ref> Deeplearning4j includes implementations of the [[restricted Boltzmann machine]], [[deep belief net]], deep autoencoder, stacked denoising autoencoder and [[Recursive neural network#Tensor|recursive neural tensor network]], [[word2vec]], doc2vec, and [[GloVe (machine learning)|GloVe]]. These algorithms all include [[Distributed computing|distributed]] [[Parallel computing|parallel]] versions that integrate with [[Apache Hadoop]] and [[Apache Spark|Spark]].<ref>{{cite web|url=https://www.youtube.com/watch?v=LCsc1hFuNac&feature=youtu.be|title=Adam Gibson, DeepLearning4j on Spark and Data Science on JVM with nd4j, SF Spark @Galvanize 20150212 |last=TV|first=Functional|work=SF Spark Meetup|date=2015-02-12|accessdate=2015-03-01}}</ref>\\n\\nDeeplearning4j is [[open-source software]] released under [[Apache License]] 2.0,<ref>{{cite web|title=Github Repository|url=https://github.com/agibsonccc/java-deeplearning}}</ref> developed mainly by a [[machine learning]] group headquartered in [[San Francisco]] and [[Tokyo]] and led by Adam Gibson.<ref name=\"deeplearning4j.org\">{{cite web|url=http://deeplearning4j.org/|title=deeplearning4j.org}}</ref><ref>{{cite web|title=Crunchbase Profile|url=http://www.crunchbase.com/person/adam-gibson}}</ref> It is supported commercially by the startup [[Skymind]], which bundles DL4J, [[Tensorflow]], [[Keras]] and other deep learning libraries in an enterprise distribution called the Skymind Intelligence Layer.<ref>{{cite web|title=Skymind Intelligence Layer Community Edition|url=https://skymind.ai/quickstart}}</ref> Deeplearning4j was contributed to the [[Eclipse Foundation]] in October 2017.<ref>{{cite web|title=Eclipse Deeplearning4j Project Page|url=https://projects.eclipse.org/proposals/deeplearning4j}}</ref><ref>{{cite web|title=Skymind’s Deeplearning4j, the Eclipse Foundation, and scientific computing in the JVM|url=https://jaxenter.com/skymind-deeplearning4j-eclipse-138872.html|work=Jaxenter|accessdate=2017-11-15}}</ref>\\n\\n==Introduction==\\nDeeplearning4j relies on the widely used programming language, [[Java (programming language)|Java]], though it is compatible with [[Clojure]] and includes a [[Scala (programming language)|Scala]] [[application programming interface]] (API). It is powered by its own open-source numerical computing library, [[ND4J (software)|ND4J]], and works with both [[central processing unit]]s (CPUs) and [[graphics processing unit]]s (GPUs).<ref name=\"om\">{{cite web|first=Derrick|last=Harris|title=A startup called Skymind launches, pushing open source deep learning|work=[[GigaOM.com]]|date=2014-06-02|url=http://gigaom.com/2014/06/02/a-startup-called-skymind-launches-pushing-open-source-deep-learning/|accessdate=2014-06-29}}</ref><ref name=\"vb\">{{cite web|first=Jordan|last=Novet|title=Skymind launches with open-source, plug-and-play deep learning features for your app|date=2014-06-02|url=https://venturebeat.com/2014/06/02/skymind-launches-with-open-source-plug-and-play-deep-learning-features-for-your-app//|accessdate=2014-06-29}}</ref>\\n\\nDeeplearning4j has been used in several commercial and academic applications. The code is hosted on [[GitHub]].<ref>[https://github.com/deeplearning4j/deeplearning4j Deeplearning4j source code]</ref> A support forum is maintained on [[Gitter]].<ref>[https://gitter.im/deeplearning4j/deeplearning4j Deeplearning4j Gitter Support Channel]</ref>\\n\\nThe framework is composable, meaning shallow neural nets such as restricted Boltzmann machines, convolutional nets, autoencoders, and recurrent nets can be added to one another to create deep nets of varying types. It also has extensive visualization tools,<ref>[http://deeplearning4j.org/visualization Deeplearning4j Visualization Tools]</ref> and a computation graph.<ref>[http://deeplearning4j.org/compgraph Deeplearning4j Computation Graph]</ref>\\n\\n==Distributed==\\nTraining with Deeplearning4j occurs in a cluster. Neural nets are trained in parallel via iterative reduce, which works on [[Hadoop]]-YARN and on [[Apache Spark|Spark]].<ref name=\"deeplearning4j.org\"/><ref>{{cite web|url=https://github.com/emsixteeen/IterativeReduce|title=Iterative reduce}}</ref> Deeplearning4j also integrates with CUDA kernels to conduct pure GPU operations, and works with distributed GPUs.\\n\\n==Scientific computing for the JVM==\\nDeeplearning4j includes an n-dimensional array class using [[ND4J (software)|ND4J]] that allows scientific computing in Java and Scala, similar to the functions that [[NumPy]] provides to [[Python (programming language)|Python]]. It\\'s effectively based on a library for [[linear algebra]] and [[Matrix (mathematics)|matrix]] manipulation in a production environment.\\n\\n==DataVec vectorization library for machine-learning==\\nDataVec vectorizes various file formats and data types using an [[input/output]] format system similar to Hadoop\\'s use of MapReduce; that is, it turns various data types into columns of scalars termed [[Vector (mathematics and physics)|vectors]]. DataVec is designed to vectorize CSVs, images, sound, text, video, and time series.<ref>[http://deeplearning4j.org/datavec DataVec ETL for Machine Learning]</ref><ref>[https://www.infoq.com/articles/deep-learning-time-series-anomaly-detection Anomaly Detection for Time Series Data with Deep Learning]</ref>\\n\\n==Text and NLP==\\nDeeplearning4j includes a [[vector space model]]ing and [[topic model]]ing toolkit, implemented in Java and integrating with parallel GPUs for performance. It is designed to handle large text sets.\\n\\nDeeplearning4j includes implementations of term frequency–inverse document frequency ([[tf–idf]]), [[deep learning]], and Mikolov\\'s word2vec algorithm,<ref>[https://code.google.com/p/word2vec/ word2vec]</ref> doc2vec, and GloVe, reimplemented and optimized in Java. It relies on [[t-distributed stochastic neighbor embedding]] (t-SNE) for word-cloud visualizations.\\n\\n==Real-world use cases and integrations==\\nReal-world use cases for Deeplearning4j include network intrusion detection and cybersecurity, fraud detection for the financial sector,<ref>http://www.skymind.io/finance/</ref><ref>https://skymind.ai/bsa-aml</ref> anomaly detection in industries such as manufacturing, recommender systems in e-commerce and advertising,<ref>{{cite web |url=http://www.skymind.io/commerce/ |title=Archived copy |accessdate=2016-02-22 |deadurl=yes |archiveurl=https://web.archive.org/web/20160310082156/http://www.skymind.io/commerce/ |archivedate=2016-03-10 |df= }}</ref> and image recognition.<ref>https://skymind.ai/image</ref> Deeplearning4j has integrated with other machine-learning platforms such as RapidMiner, Prediction.io,<ref>https://www.rapidminerchina.com/en/products/shop/product/deeplearning4j/</ref> and [[Weka (machine learning)|Weka]].<ref>https://deeplearning.cms.waikato.ac.nz/</ref>\\n\\n==Machine Learning Model Server==\\n\\nDeeplearning4j serves machine-learning models for inference in production using the free developer edition of SKIL, the Skymind Intelligence Layer.<ref>https://skymind.ai/products</ref><ref>https://deeplearning4j.org/modelserver</ref> A model server serves the parametric machine-learning models that makes decisions about data. It is used for the inference stage of a machine-learning workflow, after data pipelines and model training. A model server is the tool that allows data science research to be deployed in a real-world production environment. \\n\\nWhat a Web server is to the Internet, a model server is to AI. Where a Web server receives an HTTP request and returns data about a Web site, a model server receives data, and returns a decision or prediction about that data: e.g. sent an image, a model server might return a label for that image, identifying faces or animals in photographs.\\n\\nThe SKIL model server is able to import models from Python frameworks such as Tensorflow, Keras, Theano and CNTK, overcoming a major barrier in deploying deep learning models.\\n\\n==Benchmarks==\\nDeeplearning4j is as fast as Caffe for non-trivial image recognition tasks using multiple GPUs.<ref>https://github.com/deeplearning4j/dl4j-benchmark</ref> For programmers unfamiliar with HPC on the JVM, there are several parameters that must be adjusted to optimize neural network training time. These include setting the heap space, the garbage collection algorithm, employing off-heap memory and pre-saving data (pickling) for faster ETL.<ref>https://deeplearning4j.org/benchmark</ref> Together, these optimizations can lead to a 10x acceleration in performance with Deeplearning4j.\\n\\n==API Languages: Java, Scala, Python & Clojure==\\nDeeplearning4j can be used via multiple API languages including Java, Scala, Python and Clojure. Its Scala API is called ScalNet.<ref>https://deeplearning4j.org/scala</ref>  Keras serves as its Python API.<ref>https://deeplearning4j.org/keras</ref>  And its Clojure wrapper is known as DL4CLJ.<ref>https://deeplearning4j.org/clojure</ref> The core languages performing the large-scale mathematical operations necessary for deep learning are C, C++ and CUDA C.\\n\\n==Tensorflow, Keras & Deeplearning4j==\\n\\nTensorflow, Keras and Deeplearning4j work together. Deeplearning4j can import models from Tensorflow and other Python frameworks if they have been created with Keras.<ref>https://deeplearning4j.org/tensorflow</ref>  \\n\\n==See also==\\n{{Portal|Free software|Java}}\\n* [[Comparison of deep learning software]]\\n* [[Artificial intelligence]]\\n* [[Machine learning]]\\n* [[Deep learning]]\\n\\n==References==\\n{{Reflist|30em}}\\n\\n==External links==\\n* {{official website|www.deeplearning4j.org}}\\n\\n\\n{{Computer vision footer}}\\n{{Deep Learning Software}}\\n\\n[[Category:Applied machine learning]]\\n[[Category:Artificial neural networks]]\\n[[Category:Cluster computing]]\\n[[Category:Data mining and machine learning software]]\\n[[Category:Deep learning]]\\n[[Category:Neural network software]]\\n[[Category:Data mining and machine learning software]]\\n[[Category:Free data analysis software]]\\n[[Category:Free science software]]\\n[[Category:Free software programmed in Java (programming language)]]\\n[[Category:Software programmed in Java (programming language)]]\\n[[Category:Free software programmed in Scala]]\\n[[Category:Free statistical software]]\\n[[Category:Hadoop]]\\n[[Category:Image processing]]\\n[[Category:Information technology companies of the United States]]\\n[[Category:Java (programming language) libraries]]\\n[[Category:Java platform]]\\n[[Category:Java programming language family]]\\n[[Category:JVM programming languages]]\\n[[Category:Machine learning]]\\n[[Category:Natural language processing]]\\n[[Category:Numerical programming languages]]\\n[[Category:Open-source artificial intelligence]]\\n[[Category:Scala (programming language)]]\\n[[Category:Software using the Apache license]]\\n[[Category:Technology companies based in the San Francisco Bay Area]]',\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '43169442'},\n",
       " {'article': 'DeepMind',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': '{{Use British English|date=September 2016}}\\n{{Infobox dot-com company\\n| name = DeepMind Technologies Limited\\n| logo = DeepMind logo.png\\n| founded = {{start date and age|df=y|2010|9|23}} <ref>{{cite web|url=https://beta.companieshouse.gov.uk/company/07386350|title=DEEPMIND TECHNOLOGIES LIMITED – Overview (free company information from Companies House)|work=[[Companies House]]|date= |accessdate=2016-03-13}}</ref>\\n| location = {{plain list|\\n6 Pancras Square,<ref name=\"nature2015\" /><br />London N1C 4AG, UK  }}\\n| founder = {{plain list|\\n*[[Demis Hassabis]],\\n*[[Shane Legg]],\\n*[[Mustafa Suleyman]]}}\\n| CEO = [[Demis Hassabis]]\\n| industry = [[Artificial Intelligence]]\\n| parent = Independent (2010–2014) <br /> [[Google]] Inc. (2014–present) <br /> [[Alphabet Inc.]] (2015–present)\\n| company_type = [[Subsidiary]]\\n| num_employees = 400 <ref>{{cite web|title=Alphabet\\'s DeepMind unit could be expanded to 1,000 people|url=http://www.businessinsider.com/alphabet-deepmind-could-be-expanded-1000-people-google-london-report-2016-12}}</ref>\\n| website = [https://www.deepmind.com/ www.deepmind.com]\\n}}\\n\\n\\'\\'\\'DeepMind Technologies Limited\\'\\'\\' is a British [[artificial intelligence]] company founded in September 2010.\\n\\n[[List of mergers and acquisitions by Google|Acquired]] by [[Google]] in 2014, the company has created a [[neural network]] that learns how to play [[video games]] in a fashion similar to that of humans,<ref name=\"arxiv medium\">{{cite web|title=The Last AI Breakthrough DeepMind Made Before Google Bought It|publisher=The Physics [[arXiv]] Blog|url=https://medium.com/the-physics-arxiv-blog/the-last-ai-breakthrough-deepmind-made-before-google-bought-it-for-400m-7952031ee5e1|accessdate=12 October 2014}}</ref> as well as a [[Neural Turing machine]],<ref name=\"arxiv\">{{cite arXiv |eprint=1410.5401|title= Neural Turing Machines |newspaper= |date=  |author= |last1= [[Alex Graves (computer scientist)|Graves]]  |first1= Alex |last2= Wayne |first2= Greg |last3= Danihelka |first3= Ivo |class= cs.NE |year= 2014 }}</ref> or a neural network that may be able to access an external memory like a conventional [[Turing machine]], resulting in a computer that mimics the [[short-term memory]] of the human brain.<ref>[http://www.technologyreview.com/view/533741/best-of-2014-googles-secretive-deepmind-startup-unveils-a-neural-turing-machine/ Best of 2014: Google\\'s Secretive DeepMind Startup Unveils a \"Neural Turing Machine\"], \\'\\'[[MIT Technology Review]]\\'\\'</ref><ref name=\"DNCnature2016\">{{Cite journal|last= [[Alex Graves (computer scientist)|Graves]]|first=Alex|last2=Wayne|first2=Greg|last3=Reynolds|first3=Malcolm|last4=Harley|first4=Tim|last5=Danihelka|first5=Ivo|last6=Grabska-Barwińska|first6=Agnieszka|last7=Colmenarejo|first7=Sergio Gómez|last8=Grefenstette|first8=Edward|last9=Ramalho|first9=Tiago|date=2016-10-12|title=Hybrid computing using a neural network with dynamic external memory|url=http://www.nature.com/articles/nature20101.epdf?author_access_token=ImTXBI8aWbYxYQ51Plys8NRgN0jAjWel9jnR3ZoTv0MggmpDmwljGswxVdeocYSurJ3hxupzWuRNeGvvXnoO8o4jTJcnAyhGuZzXJ1GEaD-Z7E6X_a9R-xqJ9TfJWBqz|journal=Nature|language=en|volume=538|doi=10.1038/nature20101|issn=1476-4687|pages=471–476|pmid=27732574}}</ref>\\n\\nThe company made headlines in 2016 in nature after its [[AlphaGo]] program beat a human professional [[Go (game)|Go]] player for the first time in October 2015.<ref name=\"lemondego\">{{cite web|url=http://www.lemonde.fr/pixels/article/2016/01/27/premiere-defaite-d-un-professionnel-du-go-contre-une-intelligence-artificielle_4854886_4408996.html|title=Première défaite d’un professionnel du go contre une intelligence artificielle|language=French|date=27 January 2016|work=Le Monde}}</ref> and again when AlphaGo beat [[Lee Sedol]] the world champion in a five-game tournament, which was the subject of a documentary film.\\n{{toclimit|3}}\\n\\n== History ==\\nThe [[Startup company|start-up]] was founded by [[Demis Hassabis]], [[Shane Legg]] and [[Mustafa Suleyman]] in 2010.<ref>{{cite news| url=https://www.bloomberg.com/news/2014-01-27/google-buys-u-k-artificial-intelligence-company-deepmind.html | work=Bloomberg | title=Google Buys U.K. Artificial Intelligence Company DeepMind | date=27 January 2014 | accessdate=13 November 2014}}</ref><ref>{{cite news|url=http://www.ft.com/cms/s/0/dfedc62e-874e-11e3-9c5c-00144feab7de.html | title=Google makes £400m move in quest for artificial intelligence | newspaper=Financial Times | date=27 January 2014 | accessdate=13 November 2014}}</ref> Hassabis and Legg first met at [[University College London]]\\'s [[UCL Faculty of Life Sciences|Gatsby Computational Neuroscience Unit]].<ref>{{cite news|title=Demis Hassabis: 15 facts about the DeepMind Technologies founder|url=https://www.theguardian.com/technology/shortcuts/2014/jan/28/demis-hassabis-15-facts-deepmind-technologies-founder-google|newspaper=The Guardian|accessdate=12 October 2014}}</ref> On 26 January 2014, Google announced the company had acquired DeepMind for $500 million,<ref>{{cite web|url=https://www.reuters.com/article/2014/01/27/google-deepmind-idUSL2N0L102A20140127|title=Google to buy artificial intelligence company DeepMind|date=26 January 2014|publisher=Reuters|accessdate=12 October 2014}}</ref><ref>{{cite news|url=https://www.theguardian.com/technology/2014/jan/27/google-acquires-uk-artificial-intelligence-startup-deepmind|title=Google Acquires UK AI startup Deepmind|newspaper=The Guardian|accessdate=27 January 2014}}</ref><ref>{{cite web|url=https://techcrunch.com/2014/01/26/google-deepmind/|title=Report of Acquisition, TechCrunch|publisher=TechCrunch|accessdate=27 January 2014}}</ref><ref>{{cite web|url=https://www.reuters.com/article/2014/01/27/us-google-deepmind-idUSBREA0Q03220140127|title=Reuters Report|last=Oreskovic|first=Alexei|publisher=Reuters|accessdate=27 January 2014}}</ref><ref>{{cite news|url=https://www.theverge.com/2014/1/26/5348640/google-deepmind-acquisition-robotics-ai|title=Google Acquires Artificial Intelligence Start-Up DeepMind|work=The Verge|accessdate=27 January 2014}}</ref><ref>{{cite web|url=https://arstechnica.com/business/2014/01/google-acquires-ai-pioneer-deepmind-technologies/|title=Google acquires AI pioneer DeepMind Technologies|work=Ars Technica|accessdate=27 January 2014}}</ref> and that it had agreed to take over DeepMind Technologies.\\n\\nSince then major venture capital firms [[Horizons Ventures]] and [[Founders Fund]] have invested in the company,<ref>{{cite web|title=DeepMind buy heralds rise of the machines|url=http://www.ft.com/cms/s/0/b09dbd40-876a-11e3-9c5c-00144feab7de.html#axzz3G6ykG7uq|newspaper=Financial Times|accessdate=14 October 2014}}</ref> as well as entrepreneurs [[Scott Banister]]<ref>{{cite web|title=DeepMind Technologies Investors|url=https://angel.co/deepmind-technologies-limited|accessdate=12 October 2014}}</ref> and [[Elon Musk]].<ref>{{cite web|url=http://www.ibtimes.co.uk/elon-musk-artificial-intelligence-potentially-more-dangerous-nukes-1459710|title=Elon Musk: Artificial Intelligence \\'Potentially More Dangerous Than Nukes\\'|first=Anthony |last=Cuthbertson|date=|work=International Business Times UK}}</ref> [[Jaan Tallinn]] was an early investor and an adviser to the company.<ref>{{cite web|title=Recode.net – DeepMind Technologies Acquisition|url=http://recode.net/2014/01/26/exclusive-google-to-buy-artificial-intelligence-startup-deepmind-for-400m/|accessdate=27 January 2014}}</ref> The sale to Google took place after [[Facebook]] reportedly ended negotiations with DeepMind Technologies in 2013.<ref>{{cite web|url=https://www.theinformation.com/Google-beat-Facebook-For-DeepMind-Creates-Ethics-Board|title=Google beats Facebook for Acquisition of DeepMind Technologies|accessdate=27 January 2014}}</ref> The company was afterwards renamed Google DeepMind and kept that name for about two years.<ref name=\"nature2015\" />\\n\\nIn 2014, DeepMind received the \"Company of the Year\" award by [[Cambridge Computer Laboratory]].<ref>{{cite web|title=Hall of Fame Awards: To celebrate the success of companies founded by Computer Laboratory graduates.|url=https://www.cl.cam.ac.uk/ring/awards.html|publisher=University of Cambridge|accessdate=12 October 2014}}</ref>\\n\\nIn September 2015, DeepMind and the Royal Free NHS Trust signed their initial Information Sharing Agreement(ISA) to co-develop a clinical task management app, Streams.<ref>{{Cite news|url=https://techcrunch.com/2017/08/31/documents-detail-deepminds-plan-to-apply-ai-to-nhs-data-in-2015/|title=Documents detail DeepMind’s plan to apply AI to NHS data in 2015|last=Lomas|first=Natasha|work=TechCrunch|access-date=2017-09-26|language=en}}</ref>\\n\\nAfter Google\\'s acquisition the company established an [[Ethics of artificial intelligence|artificial intelligence ethics]] board.<ref>{{cite magazine |title=Inside Google\\'s Mysterious Ethics Board|url=https://www.forbes.com/sites/privacynotice/2014/02/03/inside-googles-mysterious-ethics-board/|magazine=Forbes|accessdate=12 October 2014|date=3 February 2014}}</ref> The ethics board for AI research remains a mystery, with both Google and DeepMind declining to reveal who sits on the board.<ref name=\"theguardian.com 2016-05-04\">{{cite web|last1=Ramesh|first1=Randeep|title=Google\\'s DeepMind shouldn\\'t suck up our NHS records in secret|url=https://www.theguardian.com/commentisfree/2016/may/04/googles-deepmind-shouldnt-be-sucking-up-our-nhs-records-in-secret|website=TheGuardian.com|publisher=The Guardian|accessdate=19 October 2016|archiveurl=https://web.archive.org/web/20161013145134/https://www.theguardian.com/commentisfree/2016/may/04/googles-deepmind-shouldnt-be-sucking-up-our-nhs-records-in-secret|archivedate=2016-10-13|date=2016-05-04}}</ref>  DeepMind, together with Amazon, Google, Facebook, IBM, and Microsoft, is a founding member of \\'\\'Partnership on AI\\'\\', an organization devoted to the society-AI interface.<ref>{{cite web |url=https://www.partnershiponai.org/#s-partners |title=Home/ Partnership on Artificial Intelligence to Benefit People and Society |year=2016 |author=<!--Staff writer(s); no by-line.--> |access-date=15 October 2016}}</ref> DeepMind has opened a new unit called DeepMind Ethics and Society and focused on the ethical and societal questions raised by artificial intelligence featuring prominent [[transhumanism|transhumanist]] Nick Bostrom as advisor.<ref>{{cite web|url=http://www.theguardian.com/technology/2017/oct/04/google-deepmind-ai-artificial-intelligence-ethics-group-problems|title=DeepMind announces ethics group to focus on problems of AI|first=Alex|last=Hern|date=4 October 2017|publisher=|via=www.theguardian.com}}</ref> In October 2017, Deepmind launched new \\'ethics and society\\' research team to investigate AI ethics.<ref>{{Cite news|url=http://www.businessinsider.com/deepmind-has-launched-a-new-ethics-and-society-research-team-2017-10|title=DeepMind has launched a new \\'ethics and society\\' research team|work=Business Insider|access-date=2017-10-25|language=en}}</ref><ref>{{Cite news|url=https://www.theverge.com/2017/10/4/16417978/deepmind-ai-ethics-society-research-group|title=DeepMind launches new research team to investigate AI ethics|work=The Verge|access-date=2017-10-25}}</ref>\\n\\n== Machine learning ==\\nDeepMind Technologies\\' goal is to \"solve intelligence\",<ref name=\"DeepMind Website\" /> which they are trying to achieve by combining \"the best techniques from [[machine learning]] and [[systems neuroscience]] to build powerful general-purpose [[learning algorithms]]\".<ref name=\"DeepMind Website\">{{cite web|title=DeepMind Technologies Website|url=https://www.deepmind.com/|publisher=DeepMind Technologies|accessdate=11 October 2014}}</ref>\\nThey are trying to formalize intelligence<ref>{{cite arXiv|title=An Approximation of the Universal Intelligence Measure |date=29 September 2011|first1=Shane |last1=Legg|first2=Joel |last2=Veness|eprint=1109.5951|class=cs.AI}}</ref> in order to not only implement it into machines, but also understand the human brain, as Demis Hassabis explains:\\n{{Quote|[...] attempting to distil intelligence into an algorithmic construct may prove to be the best path to understanding some of the enduring mysteries of our minds.<ref>{{cite journal|title=Model the brain\\'s algorithms |journal=Nature |date=23 February 2012|first=Demis |last=Hassabis|url=http://www.gatsby.ucl.ac.uk/~demis/TuringSpecialIssue(Nature2012).pdf|accessdate=12 October 2014}}</ref>}}\\nGoogle Research has released a paper in 2016 regarding [[AI safety|AI Safety]] and avoiding undesirable behaviour during the AI learning process.<ref>{{Cite arXiv|last=Amodei|first=Dario|last2=Olah|first2=Chris|last3=Steinhardt|first3=Jacob|last4=Christiano|first4=Paul|last5=Schulman|first5=John|last6=Mané|first6=Dan|date=2016-06-21|title=Concrete Problems in AI Safety |eprint=1606.06565 |class=cs.AI}}</ref> Deepmind has also released several publications via their website.<ref>{{Cite web|url=https://deepmind.com/research/publications/|title=Publications {{!}} DeepMind|website=DeepMind|access-date=2016-09-11}}</ref>\\n\\nTo date, the company has published research on computer systems that are able to play games, and developing these systems, ranging from strategy games such as [[Go (game)|Go]]<ref>{{cite journal|title=Investigating the Limits of Monte-Carlo Tree Search Methods in Computer Go|date=12 July 2014|first1=Shih-Chieh |last1=Huang|first2=Martin |last2=Müller|url=https://link.springer.com/chapter/10.1007%2F978-3-319-09165-5_4|publisher=Springer|doi=10.1007/978-3-319-09165-5_4|journal=Lecture Notes in Computer Science|volume=8427|pages=39–48|series=Lecture Notes in Computer Science|isbn=978-3-319-09164-8}}</ref> to [[arcade games]]. According to Shane Legg human-level machine intelligence can be achieved \"when a machine can learn to play a really wide range of games from perceptual stream input and output, and transfer understanding across games[...].\"<ref>{{cite web|title=Q&A with Shane Legg on risks from AI|url=http://lesswrong.com/lw/691/qa_with_shane_legg_on_risks_from_ai/|accessdate=12 October 2014|date= 17 June 2011}}</ref>\\nResearch describing an AI playing seven different [[Atari 2600]] video games (the \\'\\'[[Pong]]\\'\\' game in \\'\\'[[Video Olympics]]\\'\\', \\'\\'[[Breakout (video game)|Breakout]]\\'\\', \\'\\'[[Space Invaders]]\\'\\', \\'\\'[[Seaquest (video game)|Seaquest]]\\'\\', \\'\\'[[Beamrider]]\\'\\', \\'\\'[[Enduro (video game)|Enduro]]\\'\\', and \\'\\'[[Q*bert]]\\'\\') reportedly led to their acquisition by Google.<ref name=\"arxiv medium\" /> Hassabis has mentioned the popular e-sport game \\'\\'[[StarCraft]]\\'\\' as a possible future challenge, since it requires a high level of strategic thinking and handling imperfect information.<ref>{{cite web|url=https://www.theverge.com/2016/3/10/11192774/demis-hassabis-interview-alphago-google-deepmind-ai|title=DeepMind founder Demis Hassabis on how AI will shape the future|date=10 March 2016|website=The Verge}}</ref>\\n\\n=== Deep reinforcement learning ===\\nAs opposed to other AIs, such as [[IBM]]\\'s [[Deep Blue (chess computer)|Deep Blue]] or [[Watson (computer)|Watson]], which were developed for a pre-defined purpose and only function within its scope, DeepMind claims that their system is not pre-programmed: it learns from experience, using only raw pixels as data input. Technically it uses [[deep learning]] on a [[convolutional neural network]], with a novel form of [[Q-learning]], a form of model-free [[reinforcement learning]].<ref name=\"nature2015\" /><ref name=\"Atari Paper\">{{cite arXiv|title=Playing Atari with Deep Reinforcement Learning |date=12 December 2013 |first1=Volodymyr |last1=Mnih |first2=Koray |last2=Kavukcuoglu |first3=David |last3=Silver |first4=Alex |last4=Graves |first5=Ioannis |last5=Antonoglou |first6=Daan |last6=Wierstra |first7=Martin |last7=Riedmiller |eprint=1312.5602|class=cs.LG }}</ref>  They test the system on video games, notably early [[Arcade Games#Golden Age|arcade games]], such as \\'\\'[[Space Invaders]]\\'\\' or \\'\\'[[Breakout (video game)|Breakout]]\\'\\'.<ref name=\"Atari Paper\" /><ref name=\"hassabis talk\" /> Without altering the code, the AI begins to understand how to play the game, and after some time plays, for a few games (most notably \\'\\'Breakout\\'\\'), a more efficient game than any human ever could.<ref name=\"hassabis talk\">{{cite AV media|title=Deepmind artificial intelligence @ FDOT14|url=https://www.youtube.com/watch?v=EfGD2qveGdQ|date=19 April 2014}}</ref>\\n\\nFor most games (\\'\\'Space Invaders\\'\\', \\'\\'Ms Pac-Man\\'\\', \\'\\'Q*Bert\\'\\' for example), DeepMind plays below the current{{when|date=December 2016}} World Record. The application of DeepMind\\'s AI to video games is currently{{when|date=December 2016}} for games made in the 1970s and [[History of video games#1980s|1980s]], with work being done on more complex 3D games such as \\'\\'[[Doom (series)|Doom]]\\'\\', which first appeared in the early 1990s.<ref name=\"hassabis talk\" />\\n\\n=== AlphaGo ===\\n{{Main|AlphaGo}}\\nIn October 2015, a [[computer Go]] program called AlphaGo, developed by DeepMind, beat the European [[Go (game)|Go]] champion [[Fan Hui]], a [[Go ranks and ratings|2 dan]] (out of 9 dan possible) professional, five to zero.<ref name=\"bbcgo\">{{cite web|url=http://www.bbc.com/news/technology-35420579|title=Google achieves AI \\'breakthrough\\' by beating Go champion|date=27 January 2016|author=|work=BBC News}}</ref> This is the first time an artificial intelligence (AI) defeated a professional Go player.<ref name=\"lemondego\" /> Previously, computers were only known to have played Go at \"amateur\" level.<ref name=\"bbcgo\" /><ref name=\"googlego\">{{cite web|url=http://googleresearch.blogspot.com/2016/01/alphago-mastering-ancient-game-of-go.html|title=Research Blog: AlphaGo: Mastering the ancient game of Go with Machine Learning|date=27 January 2016|author=|work=Google Research Blog}}</ref> Go is considered much more difficult for computers to win compared to other games like [[chess]], due to the much larger number of possibilities, making it prohibitively difficult for traditional AI methods such as [[Brute-force search|brute-force]].<ref name=\"bbcgo\" /><ref name=\"googlego\" /> In March 2016 it beat [[Lee Sedol]]—a 9th dan Go player and one of the highest ranked players in the world—with 4-1 in a [[AlphaGo versus Lee Sedol|five-game match]]. In the 2017 [[Future of Go Summit]], AlphaGo won a [[AlphaGo versus Ke Jie|three-game match with Ke Jie]], who at the time continuously held the world No. 1 ranking for two years.<ref>{{Cite web|url=http://www.goratings.org/|title=World\\'s Go Player Ratings|date=May 2017}}</ref><ref>{{Cite web|title=柯洁迎19岁生日 雄踞人类世界排名第一已两年|url=http://sports.sina.com.cn/go/2016-08-02/doc-ifxunyya3020238.shtml|language=Chinese|date=May 2017}}</ref> It used a [[supervised learning]] protocol, studying large numbers of games played by humans against each other.<ref>{{Cite news|url=https://www.economist.com/news/science-and-technology/21730391-learning-play-go-only-start-latest-ai-can-work-things-out-without|title=The latest AI can work things out without being taught|work=The Economist|access-date=2017-10-19|language=en}}</ref>\\n\\nIn 2017 an improved version, AlphaGo Zero, defeated AlphaGo 100 games to 0. Zero discovered on its own many of the moves of human Go players and added new ones.\\n\\n==== Technology ====\\nAlphaGo used two deep neural networks: a policy network to evaluate move probabilities and a value network to assess positions. The policy network trained via supervised learning, and was subsequently refined by policy-gradient [[reinforcement learning]]. The value network learned to predict winners of games played by the policy network against itself. After training these networks employed a lookahead [[Monte Carlo tree search]] (MCTS), using the policy network to identify candidate high-probability moves, while the value network (in conjunction with Monte Carlo rollouts using a fast rollout policy) evaluated tree positions.<ref name=\":0\">{{Cite journal|last=Silver|first=David|last2=Schrittwieser|first2=Julian|last3=Simonyan|first3=Karen|last4=Antonoglou|first4=Ioannis|last5=Huang|first5=Aja|last6=Guez|first6=Arthur|last7=Hubert|first7=Thomas|last8=Baker|first8=Lucas|last9=Lai|first9=Matthew|date=2017-10-18|title=Mastering the game of Go without human knowledge|url=https://www.nature.com/articles/nature24270.epdf|journal=Nature|language=en|volume=550|issue=7676|pages=354–359|doi=10.1038/nature24270|issn=1476-4687|via=}}</ref>\\n\\nZero trained using reinforcement learning in which the system played millions of games against itself. Its only guide was to increase its win rate. It did so without learning from games played by humans. Its only input features are the black and white stones from the board. It uses a single neural network, rather than separate policy and value networks. Its simplified tree search relies upon this neural network to evaluate positions and sample moves, without Monte Carlo rollouts. A new reinforcement learning algorithm incorporates lookahead search inside the training loop.<ref name=\":0\" /> AlphaGo Zero employed around 15 people and millions in computing resources.<ref>{{Cite news|url=https://www.technologyreview.com/s/609141/alphago-zero-shows-machines-can-become-superhuman-without-any-help/|title=The world’s smartest game-playing AI—DeepMind’s AlphaGo—just got way smarter|last=Knight|first=Will|work=MIT Technology Review|access-date=2017-10-19|language=en}}</ref> Ultimately, it needed much less computing power than AlphaGo, running on four specialized AI processors (Google [[Tensor processing unit|TPUs]]), instead of AlphaGo\\'s 48.<ref>{{Cite news|url=https://www.theverge.com/2017/10/18/16495548/deepmind-ai-go-alphago-zero-self-taught|title=DeepMind’s Go-playing AI doesn’t need human help to beat us anymore|last=Vincent|first=James|date=October 18, 2017|work=The Verge|access-date=2017-10-19|archive-url=|archive-date=|dead-url=}}</ref>\\n\\n== Healthcare ==\\nIn July 2016, a collaboration between DeepMind and [[Moorfields Eye Hospital]] was announced.<ref>{{cite news|url=http://www.bbc.com/news/technology-36713308|title=Google\\'s DeepMind to peek at NHS eye scans for disease analysis|date=6 July 2016|publisher=BBC|last1=Baraniuk|first1=Chris|accessdate=6 July 2016}}</ref> DeepMind would be applied to the analysis of [[Data anonymization|anonymised]] eye scans, searching for early signs of diseases leading to [[blindness]].\\n\\nIn August 2016, a research programme with University College London Hospital was announced with the aim of developing an algorithm that can automatically differentiate between healthy and cancerous tissues in head and neck areas.<ref>{{cite news|url=http://www.bbc.co.uk/news/technology-37230806|title=Google DeepMind targets NHS head and neck cancer treatment|date=31 August 2016|publisher=BBC|last1=Baraniuk|first1=Chris|accessdate=5 September 2016}}</ref>\\n\\nThere are also projects with the [[Royal Free London NHS Foundation Trust]] and [[Imperial College Healthcare NHS Trust]] to develop new clinical mobile apps linked to [[electronic patient record]]s.<ref>{{cite news|title=DeepMind announces second NHS partnership|url=http://www.itpro.co.uk/public-sector/27833/deepmind-announces-second-nhs-partnership|accessdate=23 December 2016|publisher=IR Pro|date=23 December 2016}}</ref>\\n\\n=== Controversies ===\\nIn April 2016 \\'\\'[[New Scientist]]\\'\\' obtained a copy of a data-sharing agreement between DeepMind and the [[Royal Free London NHS Foundation Trust]].  The latter operates the three London hospitals where an estimated 1.6 million patients are treated annually. The revelation has exposed the ease with which private companies can obtain highly sensitive medical information without [[informed consent|patient consent]]. The agreement shows DeepMind Health had access to admissions, discharge and transfer data, accident and emergency, pathology and radiology, and critical care at these hospitals. This included personal details such as whether patients had been diagnosed with [[HIV/AIDS|HIV]], suffered from [[major depressive disorder|depression]] or had ever undergone an [[abortion]] in order to conduct research to seek better outcomes in various health conditions.<ref>{{cite news |url=https://www.newscientist.com/article/2086454-revealed-google-ai-has-access-to-huge-haul-of-nhs-patient-data |title=Revealed: Google AI has access to huge haul of NHS patient data |first=Hal |last=Hodson |work=[[New Scientist]] |date=29 April 2016 |accessdate= }}</ref><ref>{{cite news |url=https://www.newscientist.com/article/mg23030722-900-big-data-if-theres-nothing-to-hide-why-be-secretive/ |title=Leader: If Google has nothing to hide about NHS data, why so secretive? |work=[[New Scientist]] |date=4 May 2016 |accessdate= }}</ref> The agreement is seen as controversial and its legality has been questioned.<ref name=\"theguardian.com 2016-05-04\" />\\n\\nThe concerns were widely reported and have led to a complaint to the [[Information Commissioner\\'s Office]] (ICO), arguing that the data should be pseudonymised and encrypted.<ref>{{cite news |url=http://www.computerweekly.com/news/450296175/ICO-probes-Google-DeepMind-patient-data-sharing-deal-with-NHS-Hospital-Trust |title=ICO probes Google DeepMind patient data-sharing deal with NHS Hospital Trust |first=Caroline |last=Donnelly |work=[[Computer Weekly]] |date=12 May 2016 |accessdate= }}</ref>\\n\\nIn May 2016, \\'\\'New Scientist\\'\\' published a further article claiming that the project had failed to secure approval from the Confidentiality Advisory Group of the [[Medicines and Healthcare Products Regulatory Agency]].<ref>{{cite news |url=https://www.newscientist.com/article/2088056-exclusive-googles-nhs-deal/ |title=Did Google’s NHS patient data deal need ethical approval? |first=Hal |last=Hodson |work=[[New Scientist]] |date=25 May 2016 |accessdate=28 May 2016 }}</ref>\\n\\nIn May 2017, \\'\\'Sky News\\'\\' published a leaked letter from the National Data Guardian, Dame [[Fiona Caldicott]], revealing that in her \"considered opinion\" the data sharing agreement between DeepMind and the Royal Free took place on an \"inappropriate legal basis\".<ref>{{cite news |url=http://news.sky.com/story/google-received-16-million-nhs-patients-data-on-an-inappropriate-legal-basis-10879142/ |title=Google received 1.6 million NHS patients\\' data on an \\'inappropriate legal basis\\' |first=Alexander J |last=Martin |work=[[Sky News]] |date=15 May 2017 |accessdate=16 May 2017 }}</ref>\\n\\nThe Information Commissioner’s Office ruled that London’s Royal Free hospital failed to comply with the Data Protection Act when it handed over personal data of 1.6 million patients to DeepMind.\\n<ref>{{cite web|url=http://www.theguardian.com/technology/2017/jul/03/google-deepmind-16m-patient-royal-free-deal-data-protection-act|title=Royal Free breached UK data law in 1.6m patient deal with Google\\'s DeepMind|first=Alex|last=Hern|date=3 July 2017|publisher=|via=www.theguardian.com}}</ref>\\n\\n==See also==\\n* [[Artificial intelligence]]\\n* [[Glossary of artificial intelligence]]\\n\\n== References ==\\n{{reflist|29em|refs=\\n<ref name=\"nature2015\">{{cite journal |last= Mnih|first= Volodymyr |last2= Kavukcuoglu|first2= Koray |last3= Silver|first3= David |date= 26 February 2015 |title= Human-level control through deep reinforcement learning|url= http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html|journal=Nature|volume= 518|issue= 7540|pages= 529–33|doi= 10.1038/nature14236 |access-date=25 February 2015 |pmid=25719670|bibcode= 2015Natur.518..529M }}</ref>\\n}}\\n\\n== External links ==\\n* {{Official website}}\\n\\n{{Alphabet Inc.}}\\n\\n[[Category:2010 establishments in England]]\\n[[Category:Artificial intelligence laboratories]]\\n[[Category:Companies established in 2010]]\\n[[Category:Deep learning]]\\n[[Category:Game artificial intelligence]]\\n[[Category:Google acquisitions]]\\n[[Category:Machine learning]]',\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '41755648'},\n",
       " {'article': 'Hierarchical temporal memory',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': '{{Refimprove|date=July 2011}}\\n\\'\\'\\'Hierarchical temporal memory\\'\\'\\' (\\'\\'\\'HTM\\'\\'\\') is a biologically constrained theory of machine intelligence originally described in the 2004 book \\'\\'[[On Intelligence]]\\'\\'<ref>{{Cite journal|date=2016-12-04|title=On Intelligence|url=https://en.wikipedia.org/w/index.php?title=On_Intelligence&oldid=752902753|journal=Wikipedia|language=en}}</ref> by [[Jeff Hawkins]] with [[Sandra Blakeslee]]. HTM is based on [[neuroscience]] and the physiology and interaction of [[Pyramidal cell|pyramidal neurons]] in the [[neocortex]] of the human brain. The technology has been tested and implemented in software through example applications from [[Numenta]] and commercial applications from Numenta’s partners.\\n\\nAt the core of HTM are learning algorithms that can store, learn, infer and recall high-order sequences. Unlike most other machine learning methods, HTM learns time-based patterns in unlabeled data on a continuous basis. HTM is robust to noise and high capacity, meaning that it can learn multiple patterns simultaneously. When applied to computers, HTM is well suited for prediction, anomaly detection, classification and ultimately sensorimotor applications.<ref>{{Cite web|url=https://discourse.numenta.org/t/preliminary-details-about-new-theory-work-on-sensory-motor-inference/697|title=Preliminary details about new theory work on sensory-motor inference|website=HTM Forum|language=en|access-date=2017-03-14}}</ref>\\n\\n== HTM structure and algorithms ==\\nA typical HTM network is a [[Tree (data structure)|tree]]-shaped hierarchy of \\'\\'levels\\'\\' that are composed of smaller elements called \\'\\'nodes\\'\\' or \\'\\'columns\\'\\'. A single level in the hierarchy is also called a \\'\\'region\\'\\'. Higher hierarchy levels often have fewer nodes and therefore less spatial resolvability. Higher hierarchy levels can reuse patterns learned at the lower levels by combining them to memorize more complex patterns.\\n\\nEach HTM node has the same basic functionality. In learning and inference modes, sensory data comes into the bottom level nodes. In generation mode, the bottom level nodes output the generated pattern of a given category. The top level usually has a single node that stores the most general categories (concepts) which determine, or are determined by, smaller concepts in the lower levels which are more restricted in time and space. When in inference mode, a node in each level interprets information coming in from its child nodes in the lower level as probabilities of the categories it has in memory.\\n\\nEach HTM region learns by identifying and memorizing spatial patterns - combinations of input bits that often occur at the same time. It then identifies temporal sequences of spatial patterns that are likely to occur one after another.\\n\\n[[File:Neuron comparison.png|thumb|center|upright=1.7|500px|Comparing the artificial neural network (A), the biological neuron (B), and the HTM neuron (C).]]\\n:      {|class=\"wikitable\" border=\"1\" cellpadding=\"4\"  cellspacing=\"4\"\\n        |+ Comparison of Neuron Models\\n        ! Artificial Neural Network (ANN)\\n        ! Neocortical Pyramidal Neuron (Biological Neuron)\\n        ! HTM Model Neuron<ref>{{cite journal|last1=Hawkins|first1=Jeff|last2=Ahmad|first2=Subutai|title=Why Neurons Have Thousands of Synapses, a Theory of Sequence Memory in Neocortex|journal=Frontiers in Neural Circuits|date=30 March 2016|volume=10|doi=10.3389/fncir.2016.00023}} [[File:CC-BY icon.svg|50px]] This article contains quotations from this source, which is available under the [https://creativecommons.org/licenses/by/4.0/  Creative Commons Attribution 4.0 International (CC BY 4.0)] license.</ref></center>\\n        |- style=\"vertical-align:top\"\\n        | {{bulleted list | Few synapses| No dendrites| Sum input x weights| Learns by modifying weights of synapses}}\\n        | {{bulleted list | Thousands of synapses on the dendrites| Active dendrites: cell recognizes hundreds of unique patterns\\n| Co-activation of a set of synapses on a dendritic segment causes an NMDA spike and depolarization at the soma \\n| Sources of input to the cell:\\n# Feedforward inputs which form synapses proximal to the soma and directly lead to action potentials\\n# NMDA spikes generated in the more distal basal\\n# Apical dendrites that depolarize the soma (usually not sufficient enough to generate a somatic action potential)\\n| Learns by growing new synapses}}\\n        | {{bulleted list | Inspired by the pyramidal cells in neocortex layers 2/3 and 5| Thousands of synapses| Active dendrites: cell recognizes hundreds of unique patterns| Models dendrites and NMDA spikes with each array of coincident detectors having a set of synapses| Learns by modeling growth of new synapses}}\\n        |}\\n\\n=== Zeta 1: first generation node algorithms ===\\nDuring \\'\\'\\'training\\'\\'\\', a node receives a temporal sequence of spatial patterns as its input. The learning process consists of two stages: \\n# \\'\\'Spatial pooling\\'\\' identifies frequently observed patterns and memorizes them as coincidences. Patterns that are significantly similar to each other are treated as the same coincidence. A large number of possible input patterns are reduced to a manageable number of known coincidences.\\n# \\'\\'Temporal pooling\\'\\' partitions coincidences that are likely to follow each other in the training sequence into temporal groups. Each group of patterns represents a \"cause\" of the input pattern (or \"name\" in \\'\\'On Intelligence\\'\\').\\n\\nDuring \\'\\'\\'inference\\'\\'\\' (recognition), the node calculates the set of probabilities that a pattern belongs to each known coincidence. Then it calculates the probabilities that the input represents each temporal group. The set of probabilities assigned to the groups is called a node\\'s \"belief\" about the input pattern. (In a simplified implementation, node\\'s belief consists of only one winning group). This belief is the result of the inference that is passed to one or more \"parent\" nodes in the next higher level of the hierarchy.\\n\\n\"Unexpected\" patterns to the node do not have a dominant probability of belonging to any one temporal group, but have nearly equal probabilities of belonging to several of the groups. If sequences of patterns are similar to the training sequences, then the assigned probabilities to the groups will not change as often as patterns are received.  The output of the node will not change as much, and a resolution in time is lost.\\n\\nIn a more general scheme, the node\\'s belief can be sent to the input of any node(s) in any level(s), but the connections between the nodes are still fixed. The higher-level node combines this output with the output from other child nodes thus forming its own input pattern.\\n\\nSince resolution in space and time is lost in each node as described above, beliefs formed by higher-level nodes represent an even larger range of space and time. This is meant to reflect the organization of the physical world as it is perceived by human brain. Larger concepts (e.g. causes, actions and objects) are perceived to change more slowly and consist of smaller concepts that change more quickly. Jeff Hawkins postulates that brains evolved this type of hierarchy to match, predict, and affect the organization of the external world.\\n\\nMore details about the functioning of Zeta 1 HTM can be found in Numenta\\'s old documentation.<ref>[https://web.archive.org/web/20090527174304/http://numenta.com/for-developers/education/general-overview-htm.php Numenta old documentation]</ref>\\n\\n=== Cortical learning algorithms ===\\nThe new generation of HTM learning algorithms relies on fixed-[[Sparse coding|sparsity]] distributed representations.<ref>[https://www.youtube.com/watch?v=48r-IeYOvG4 Jeff Hawkins lecture describing cortical learning algorithms]</ref><ref name=SDR>{{cite web|title=New Insights from Neuroscience|url=https://www.numenta.com/htm-overview/ISCA-06-11-2012.pdf|accessdate=26 November 2012}}</ref>  It models cortical columns that tend to inhibit neighboring columns in the neocortex thus creating a sparse activation of columns. A region creates a sparse representation from its input, so that a fixed percentage of columns are active at any one time.\\n\\nEach HTM region consists of a number of highly interconnected [[cortical column]]s. A region is similar to layer III of the [[neocortex]]. A cortical column is understood as a group of cells that have the same receptive field. Each column has a number of cells that are able to remember several previous states. A cell can be in one of three states: active, inactive and predictive state.\\n\\n\\'\\'\\'Spatial pooling:\\'\\'\\' The receptive field of each column is a fixed number of inputs that are randomly selected from a much larger number of node inputs. Based on the input pattern, some columns will receive more active input values. Spatial pooling selects a relatively constant number of the most active columns and inactivates (inhibits) other columns in the vicinity of the active ones. Similar input patterns tend to activate a stable set of columns. The amount of memory used by each region can be increased to learn more complex spatial patterns or decreased to learn simpler patterns.\\n\\n\\'\\'\\'Representing the input in the context of previous inputs:\\'\\'\\' If one or more cells in the active column are in the predictive state (see below), they will be the only cells to become active in the current time step. If none of the cells in the active column are in the predictive state (during the initial time step or when the activation of this column was not expected), all cells are made active.\\n\\n\\'\\'\\'Predicting future inputs and temporal pooling:\\'\\'\\' When a cell becomes active, it gradually forms connections to nearby cells that tend to be active during several previous time steps. Thus a cell learns to recognize a known sequence by checking whether the connected cells are active. If a large number of connected cells are active, this cell switches to the predictive state in anticipation of one of the few next inputs of the sequence. The output of a region includes columns in both active and predictive states. Thus columns are active over longer periods of time, which leads to greater temporal stability seen by the parent region.\\n\\nCortical learning algorithms are able to learn continuously from each new input pattern, therefore no separate inference mode is necessary. During inference, HTM tries to match the stream of inputs to fragments of previously learned sequences. This allows each HTM region to be constantly predicting the likely continuation of the recognized sequences. The index of the predicted sequence is the output of the region. Since predictions tend to change less frequently than the input patterns, this leads to increasing temporal stability of the output in higher hierarchy levels. Prediction also helps to fill in missing patterns in the sequence and to interpret ambiguous data by biasing the system to infer what it predicted.\\n\\nCortical learning algorithms are currently being offered as commercial [[SaaS]] by Numenta (such as Grok<ref>[http://grokstream.com/product/ Grok Product Page]</ref>).\\n\\nThe following question was posed to Jeff Hawkins September 2011 with regard to Cortical learning algorithms: \"How do you know if the changes you are making to the model are good or not?\" To which Jeff\\'s response was \"There are two categories for the answer:  one is to look at neuroscience, and the other is methods for machine intelligence. In the neuroscience realm there are many predictions that we can make, and those can be tested. If our theories explain a vast array of neuroscience observations then it tells us that we’re on the right track. In the machine learning world they don’t care about that, only how well it works on practical problems. In our case that remains to be seen. To the extent you can solve a problem that no one was able to solve before, people will take notice.\"<ref name=\"ai.stanford.edu\">[http://ai.stanford.edu/~joni/papers/LasersonXRDS2011.pdf From Neural Networks to Deep Learning: Zeroing in on the Human Brain]</ref>\\n\\n==Comparing HTM and neocortex==\\nComparing high-level structures and functionality of neocortex with HTM is most appropriate. HTM attempts to implement the functionality that is characteristic of a hierarchically related group of cortical regions in the neocortex. A \\'\\'region\\'\\' of the neocortex corresponds to one or more \\'\\'levels\\'\\' in the HTM hierarchy, while the [[hippocampus]] is remotely similar to the highest HTM level. A single HTM node may represent a group of [[cortical column]]s within a certain region.\\n\\nAlthough it is primarily a functional model, several attempts have been made to relate the algorithms of the HTM with the structure of neuronal connections in the layers of neocortex.<ref>[[Jeff Hawkins]], [[Sandra Blakeslee]] \\'\\'[[On Intelligence]]\\'\\'</ref><ref>Towards a Mathematical Theory of Cortical Micro-circuits. Dileep George and Jeff Hawkins. PLoS Computational Biology 5(10)</ref> The neocortex is organized in vertical columns of 6 horizontal layers.  The 6 layers of cells in the neocortex should not be confused with levels in an HTM hierarchy.\\n\\nHTM nodes attempt to model a portion of cortical columns (80 to 100 neurons) with approximately 20 HTM \"cells\" per column.  HTMs model only layers 2 and 3 to detect spatial and temporal features of the input with 1 cell per column in layer 2 for spatial \"pooling\", and 1 to 2 dozen per column in layer 3 for temporal pooling. A key to HTMs and the cortex\\'s is their ability to deal with noise and variation in the input which is a result of using a \"sparse distributive representation\" where only about 2% of the columns are active at any given time.\\n\\nAn HTM attempts to model a portion of the cortex\\'s learning and plasticity as described above. Differences between HTMs and neurons include:<ref>https://www.groksolutions.com/htm-overview/education/HTM_CorticalLearningAlgorithms.pdf</ref>\\n* strictly binary signals and synapses\\n* no direct inhibition of synapses or dendrites (but simulated indirectly)\\n* currently only models layers 2/3 and 4 (no 5 or 6)\\n* no \"motor\" control (layer 5)\\n* no feed-back between regions (layer 6 of high to layer 1 of low)\\n\\n==Sparse distributed representations==\\nIntegrating memory component with neural networks has a long history dating back to early research in [[distributed representations]]<ref>Hinton, Geoffrey E. \"Distributed representations.\" (1984).</ref><ref>Plate, Tony. \"Holographic Reduced Representations: Convolution Algebra for Compositional Distributed Representations.\" IJCAI. 1991.</ref> and [[self-organizing map]]s. For example, in [[sparse distributed memory]] (SDM), the patterns encoded by neural networks are used as memory addresses for [[content-addressable memory]], with \"neurons\" essentially serving as address [[encoder]]s and decoders.<ref name=kanerva1988>Kanerva, Pentti. Sparse distributed memory. MIT press, 1988.</ref><ref>Snaider, Javier, and Stan Franklin. \"Integer sparse distributed memory.\" Twenty-fifth international flairs conference. 2012.</ref>\\n\\nComputers store information in \"dense\" representations such as a 32 bit word where all combinations of 1s and 0s are possible.\\nBy contrast, brains use sparse distributed representations (SDR).<ref>Olshausen, B.A., Field, D.J., 1997, Sparse coding with an overcomplete basis set: A strategy employed by V1?, Vision Research, 37:3311-3325</ref> The human neocortex has roughly 100 billion neurons, but at any given time only a small percent are active. The activity of neurons are like bits in a computer, and therefore the representation is sparse. Similarly to [[Sparse distributed memory|SDM]] developed by [[NASA]] in the 80s<ref name=\"kanerva1988\"/> and [[vector space]] models used in [[Latent semantic analysis]], HTM also uses Sparse Distributed Representations.<ref name=\"nupicSDRs\">Numenta NUPIC  - Sparse Distributed representations. URL: https://github.com/numenta/nupic/wiki/Sparse-Distributed-Representations</ref>\\n\\nThe SDRs used in HTM are binary representations of data consisting of many bits with a small percentage of the bits active (1s); a typical implementation might have 2048 columns and 64K artificial neurons where as few as 40 might be active at once.  Although it may seem less efficient for the majority of bits to go \"unused\" in any given representation, SDRs have two major advantages over traditional dense representations.  First, SDRs are tolerant of corruption and ambiguity due to the meaning of the representation being shared (\\'\\'distributed\\'\\') across a small percentage (\\'\\'sparse\\'\\') of active bits.  In a dense representation, flipping a single bit completely changes the meaning, while in an SDR a single bit may not affect the overall meaning much.  This leads to the second advantage of SDRs: because the meaning of a representation is distributed across all active bits, similarity between two representations can be used as a measure of [[semantic]] similarity in the objects they represent.  That is, if two vectors in an SDR have 1s in the same position, then they are semantically similar in that attribute.  The bits in SDRs have semantic meaning, and that meaning is distributed across the bits.<ref name=\"nupicSDRs\"/>\\n\\nThe [[semantic folding]] theory<ref>{{cite arXiv|eprint=1511.08855|title=Semantic Folding Theory And its Application in Semantic Fingerprinting|last=De Sousa Webber|first=Francisco|date=2015|publisher=|access-date=|class=cs.AI}}</ref> builds on these SDR properties to propose a new model for language semantics, where words are encoded into word-SDRs and the similarity between terms, sentences and texts can be calculated with simple distance measures.\\n\\n== Similarity to other models ==\\n\\n=== Bayesian networks ===\\nLikened to a [[Bayesian network]], an HTM comprises a collection of nodes that are arranged in a tree-shaped hierarchy. Each node in the hierarchy discovers an array of causes in the input patterns and temporal sequences it receives. A Bayesian [[belief revision]] algorithm is used to propagate feed-forward and feedback beliefs from child to parent nodes and vice versa. However, the analogy to Bayesian networks is limited, because HTMs can be self-trained (such that each node has an unambiguous family relationship), cope with time-sensitive data, and grant mechanisms for covert attention.<ref>[http://brains.wordpress.com/2006/05/25/everything-short-of-pseudocode/ Hawkins\\' Blog]</ref>\\n\\nA theory of hierarchical cortical computation based on Bayesian [[belief propagation]] was proposed earlier by Tai Sing Lee and [[David Mumford]].<ref>[http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.12.2565 Tai Sing Lee, David Mumford \"Hierarchical Bayesian Inference in the Visual Cortex\"], 2002</ref> While HTM is mostly consistent with these ideas, it adds details about handling invariant representations in the visual cortex.<ref>http://dileepgeorge.com/blog/?p=5</ref>\\n\\n=== Neural networks ===\\nLike any system that models details of the neocortex, HTM can be viewed as an [[artificial neural network]]. The tree-shaped hierarchy commonly used in HTMs resembles the usual topology of traditional neural networks. HTMs attempt to model cortical columns (80 to 100 neurons) and their interactions with fewer HTM \"neurons\". The goal of current HTMs is to capture as much of the functions of neurons and the network (as they are currently understood) within the capability of typical computers and in areas that can be made readily useful such as image processing.  For example, feedback from higher levels and motor control are not attempted because it is not yet understood how to incorporate them and binary instead of variable synapses are used because they were determined to be sufficient in the current HTM capabilities.\\n\\nLAMINART and similar neural networks researched by Stephen Grossberg attempt to model both the infrastructure of the cortex and the behavior of neurons in a temporal framework to explain neurophysiological and psychophysical data.  However, these networks are, at present, too complex for realistic application.<ref>Grossberg, S. (2007). Towards a unified theory of neocortex: Laminar cortical circuits for vision and cognition. Technical Report CAS/CNS-TR-2006-008. For Computational Neuroscience: From Neurons to Theory and Back Again, eds: Paul Cisek, Trevor Drew, John Kalaska; Elsevier, Amsterdam, pp. 79-104.  http://cns.bu.edu/Profiles/Grossberg/GroCisek2007.pdf</ref>\\n\\nHTM is also related to work by [[Tomaso Poggio]], including an approach for modeling the ventral stream of the visual cortex known as HMAX. Similarities of HTM to various AI ideas are described in the December 2005 issue of the Artificial Intelligence journal.<ref>[http://www.sciencedirect.com/science?_ob=PublicationURL&_tockey=%23TOC%235617%232005%23998309997%23611936%23FLP%23&_cdi=5617&_pubType=J&_auth=y&_acct=C000050221&_version=1&_urlVersion=0&_userid=10&md5=f615b2c83ddfc9cbdf503c1f05f173d8 ScienceDirect - Artificial Intelligence, Volume 169, Issue 2, Page 103-212 (December 2005)]</ref>\\n\\n=== Neocognitron ===\\n[[Neocognitron]], a hierarchical multilayered neural network proposed by Professor Kunihiko Fukushima in 1987, is one of the first Deep Learning Neural Networks models.<ref>[http://www.scholarpedia.org/article/Neocognitron Neocognitron at Scholarpedia]</ref>\\n\\n== NuPIC platform and development tools ==\\n\\nThe [https://github.com/numenta/nupic Numenta Platform for Intelligent Computer (NuPIC)] is one of several available [https://numenta.org/implementations/ HTM implementations]. Some are provided by [https://numenta.com/ Numenta], while some are developed and maintained by the [https://numenta.org/ HTM open source community].\\n\\nNuPIC includes implementations of Spatial Pooling and Temporal Memory in both C++ and Python. It also includes [http://nupic.docs.numenta.org/stable/api/ 3 APIs]. Users can construct HTM systems using direct implementations of the [http://nupic.docs.numenta.org/stable/quick-start/algorithms.html algorithms], or construct a Network using the [http://nupic.docs.numenta.org/stable/quick-start/network.html Network API], which is a flexible framework for constructing complicated associations between different Layers of cortex. \\n\\n[https://github.com/numenta/nupic/releases/tag/1.0.0 NuPIC 1.0] was released on July 2017, after which the codebase was put into maintenance mode. Current research continues in Numenta [https://github.com/numenta/htmresearch research codebases].\\n\\n==Applications==\\nThe following commercial applications are available using NuPIC: \\n* Grok - anomaly detection for IT servers, see [http://www.grokstream.com www.grokstream.com]\\n* Cortical.io - advanced natural language processing, see [http://www.cortical.io www.cortical.io]\\nThe following tools are available on NuPIC:\\n* HTM Studio - find anomalies in time series using your own data, see www.[http://www.Numenta.com/htm-studio/ numenta.com/htm-studio/]\\n* Numenta Anomaly Benchmark - compare HTM anomalies with other anomaly detection techniques, see https://numenta.com/numenta-anomaly-benchmark/\\nThe following example applications are available on NuPIC, see http://numenta.com/applications/:\\n* HTM for stocks - example of tracking anomalies in the stock market (sample code)\\n* Rogue behavior detection - example of finding anomalies in human behavior (white paper and sample code)\\n* Geospatial tracking - example of finding anomalies in objectives moving through space and time (white paper and sample code)\\n\\n== See also ==\\n*[[Neocognitron]]\\n*[[Deep learning]]\\n*[[Convolutional neural network]]\\n*[[Artificial general intelligence|Strong AI]]\\n*[[Artificial consciousness]]\\n*[[Cognitive architecture]]\\n*\\'\\'[[On Intelligence]]\\'\\'\\n*[[Memory-prediction framework]]\\n*[[Belief revision]]\\n*[[Belief propagation]]\\n*[[Bionics]]\\n*[[List of artificial intelligence projects]]\\n*[[Memory Network]]\\n*[[Neural Turing Machine]]\\n*[[Multiple trace theory]]\\n\\n=== Related models ===\\n*[[Hierarchical hidden Markov model]]\\n*[[Bayesian networks]]\\n*[[Neural networks]]\\n\\n== References ==\\n{{Reflist}}\\n*{{cite web|url= http://www.numenta.com/Numenta_HTM_Concepts.pdf |title=\"Hierarchical Temporal Memory - Concepts, Theory, and Terminology\" }}&nbsp;{{small|(804&nbsp;[[Kibibyte|KiB]])}} by Jeff Hawkins and Dileep George, \\'\\'Numenta Inc.\\'\\', 2006-05-17\\n*\\'\\'On Intelligence\\'\\'; Jeff Hawkins, Sandra Blakeslee; Henry Holt, 2004; {{ISBN|0-312-71234-0}}\\n*{{Citation\\n  | title = How HTMs differ from Neural networks\\n  | last = Shoemaker\\n  | first = Phillip B.\\n  | url = http://onintelligence.org/forum/viewtopic.php?t=255\\n  | accessdate = 2007-10-17 }}\\n\\n== External links ==\\n\\n=== Official ===\\n*[https://www.youtube.com/watch?v=nBYddmFg4nQ Cortical Learning Algorithm overview] (Accessed May 2013)\\n*[http://www.numenta.com/htm-overview/education/HTM_CorticalLearningAlgorithms.pdf HTM Cortical Learning Algorithms] (PDF Sept. 2011)\\n*[http://www.numenta.com Numenta, Inc.]\\n*[https://web.archive.org/web/20110714212402/http://www.numenta.com/htm-overview/education.php HTM Cortical Learning Algorithms Archive]\\n*[http://fora.tv/2009/09/09/Hierarchical_Temporal_Memory_Subutai_Ahmad#fullprogram Association for Computing Machinery talk from 2009 by Subutai Ahmad from Numenta]\\n*[http://www.onintelligence.org/forum OnIntelligence.org Forum], an [[Internet forum]] for the discussion of relevant topics, especially relevant being the [http://www.onintelligence.org/forum/viewforum.php?f=3 Models and Simulation Topics] forum.\\n*[http://www.almaden.ibm.com/institute/resources/2006/Almaden%20Institute%20Jeff%20Hawkins.ppt Hierarchical Temporal Memory] (Microsoft PowerPoint presentation)\\n*[https://www.youtube.com/watch?v=z6r3ekreRzY Cortical Learning Algorithm Tutorial: CLA Basics], talk about the cortical learning algorithm (CLA) used by the HTM model on [[YouTube]]\\n\\n=== Other ===\\n*[http://bias.csr.unibo.it/maltoni/HTM_TR_v1.0.pdf Pattern Recognition by Hierarchical Temporal Memory] by Davide Maltoni, April 13, 2011\\n*[http://vicarious.com/ Vicarious] Startup rooted in HTM by Dileep George\\n*[http://www.gartner.com/research/fellows/fellows_interview_jeff_hawkins_tom_austin.jsp The Gartner Fellows: Jeff Hawkins Interview] by Tom Austin, \\'\\'[[Gartner]]\\'\\', March 2, 2006\\n*[http://www.cioinsight.com/article2/0,1540,1955963,00.asp Emerging Tech: Jeff Hawkins reinvents artificial intelligence] by Debra D\\'Agostino and Edward H. Baker, \\'\\'CIO Insight\\'\\', May 1, 2006\\n*[http://insight.zdnet.co.uk/hardware/emergingtech/0,39020439,39268542,00.htm \"Putting your brain on a microchip\"] by Stefanie Olsen, \\'\\'[[CNET|CNET News.com]]\\'\\', May 12, 2006\\n*[https://www.wired.com/wired/archive/15.03/hawkins.html \"The Thinking Machine\"] by Evan Ratliff, [[Wired (magazine)|Wired]], March 2007\\n*[http://spectrum.ieee.org/apr07/4982 Think like a human] by Jeff Hawkins, [[IEEE Spectrum]], April 2007\\n*[http://sourceforge.net/projects/neocortex Neocortex - Memory-Prediction Framework] — [[Open Source]] Implementation with [[GNU General Public License]]\\n*[https://web.archive.org/web/20130820231210/http://blog.mohammadzadeh.info/index.php/hierarchical-temporal-memory-related-papers Hierarchical Temporal Memory related Papers and Books]\\n\\n[[Category:Belief revision]]\\n[[Category:Artificial neural networks]]\\n[[Category:Deep learning]]\\n[[Category:Unsupervised learning]]\\n[[Category:Semisupervised learning]]',\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '11273721'},\n",
       " {'article': 'Keras',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': \"{{Infobox software\\n| name                   = Keras\\n| logo                   = [[File:Keras Logo.jpg|180px]]\\n| screenshot             =\\n| caption                =\\n| collapsible            =\\n| author                 = François Chollet\\n| developer              = various\\n| released               = {{Start date and age|2015|03|27|df=yes}}\\n| latest release version = 2.0.8\\n| latest release date    = {{Start date and age|2017|08|24|df=yes}}\\n| latest preview version = \\n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD}} -->\\n| status                 = Active\\n| programming language   = [[Python (programming language)|Python]]\\n| operating system       =\\n| platform               = [[Cross-platform]]\\n| size                   =\\n| language               = \\n| genre                  = [[Artificial neural network|Neural Network]]s\\n| license                = [[MIT License|MIT]]\\n| website                = {{URL|https://keras.io/}}\\n| frequently updated     = <!-- DO NOT include this parameter unless you know what it does -->\\n}}\\n\\n'''Keras''' is an [[Open-source software|open source]] [[Artificial neural network|neural network]] library written in [[Python (programming language)|Python]]. It is capable of running on top of [[MXNet]], [[Deeplearning4j]], [[TensorFlow|Tensorflow]], [[CNTK]] or [[Theano (software)|Theano]].<ref>{{Cite web|url=https://www.forbes.com/sites/quora/2016/08/25/this-is-what-makes-keras-different-according-to-its-author/|title=This Is What Makes Keras Different, According To Its Author|website=forbes.com|access-date=2016-09-20}}</ref><ref>[https://github.com/crockpotveggies/dl4j-examples/tree/keras-examples/dl4j-keras-examples Deeplearning4j Keras Frontend]</ref> Designed to enable fast experimentation with [[Deep learning|deep neural networks]], it focuses on being minimal, modular and extensible. It was developed as part of the research effort of project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating System),<ref>{{Cite web|url=https://keras.io/#why-this-name-keras|title=Keras Documentation|website=keras.io|access-date=2016-09-18}}</ref> and its primary author and maintainer is François Chollet, a [[Google]] engineer.\\n\\nIn 2017, Google's TensorFlow team decided to support Keras in TensorFlow's core library.  Chollet explained that Keras was conceived to be an interface rather than an end-to-end machine-learning framework. It presents a higher-level, more intuitive set of abstractions that make it easy to configure neural networks regardless of the backend scientific computing library.<ref>[https://github.com/fchollet/keras/issues/5050 Chollet GitHub Comment]</ref> [[Microsoft]] has been working to add a [[CNTK]] backend to Keras as well and the functionality is currently in beta release with CNTK v2.0 .<ref>[https://github.com/Microsoft/CNTK/issues/797 CNTK Keras GitHub Issue]</ref><ref>{{Cite web|url=https://docs.microsoft.com/en-us/cognitive-toolkit/ReleaseNotes/CNTK_2_0_Release_Notes|title=CNTK_2_0_Release_Notes|last=alexeyo|website=docs.microsoft.com|language=en-us|access-date=2017-06-14}}</ref>\\n\\n==Features==\\nThe library contains numerous implementations of commonly used neural network building blocks such as layers, [[Objective function|objectives]], [[activation function]]s, [[Mathematical optimization|optimizers]], and a host of tools to make working with image and text data easier. The code is hosted on [[GitHub]], and community support forums include the GitHub issues page, a [[Gitter]] channel and a [[Slack (software)|Slack]] channel.\\n\\n==Traction==\\n{{As of|2016|09|16}}, Keras is the second-fastest growing deep learning framework after Google's TensorFlow, and the third largest after TensorFlow and [[Caffe (software)|Caffe]].<ref>{{Cite web|url=https://twitter.com/fchollet/status/776455778274250752|title=François Chollet on Twitter|access-date=2016-09-18}}</ref>\\n\\n==See also==\\n* [[Comparison of deep learning software]]\\n\\n==References==\\n{{Reflist}}\\n\\n==External links==\\n* {{Official website|https://keras.io/}}\\n\\n\\n{{Deep Learning Software}}\\n\\n[[Category:Applied machine learning]]\\n[[Category:Data mining and machine learning software]]\\n[[Category:Deep learning]]\\n[[Category:Free statistical software]]\\n[[Category:Python scientific libraries]]\",\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '51650259'},\n",
       " {'article': 'Microsoft Cognitive Toolkit',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': \"{{Infobox software\\n| name                   = Microsoft Cognitive Toolkit\\n| logo                   = \\n| screenshot             =\\n| caption                =\\n| collapsible            =\\n| author                 = \\n| developer              = [[Microsoft Research]]\\n| released               = {{Start date and age|2016|01|25|df=yes}}\\n| latest release version = 2.2\\n| latest release date    = {{Start date and age|2017|09|16|df=yes}}\\n| latest preview version = \\n| latest preview date    = \\n| frequently updated     = <!-- DO NOT include this parameter unless you know what it does -->\\n| programming language   = [[C++]]\\n| operating system       = [[Microsoft Windows|Windows]], [[Linux]]\\n| platform               =\\n| size                   =\\n| language               =\\n| status                 =\\n| genre                  = Library for [[machine learning]] and [[deep learning]]\\n| license                = [[MIT License|MIT]]<ref>[https://github.com/Microsoft/CNTK/blob/master/LICENSE.md CNTK/LICENSE.md at master · Microsoft/CNTK]</ref>\\n| website                = {{url|https://www.microsoft.com/en-us/cognitive-toolkit/}}\\n}}\\n\\n'''Microsoft Cognitive Toolkit''',<ref>\\n{{cite web|url=https://blogs.microsoft.com/next/2016/10/25/microsoft-releases-beta-microsoft-cognitive-toolkit-deep-learning-advances/ |title=Microsoft releases beta of Microsoft Cognitive Toolkit for deep learning advances |last1=Linn |first1=Allison |date=25 October 2016 |website=microsoft.com |publisher=Microsoft |accessdate=30 January 2017|quote=Title: Microsoft releases beta of [no 'The' here] Microsoft Cognitive Toolkit\\n}}</ref> previously known as '''CNTK''' and sometimes styled as '''The Microsoft Cognitive Toolkit''', is a [[deep learning]] [[Software framework|framework]] developed by [[Microsoft Research]]. Microsoft Cognitive Toolkit describes [[Artificial neural network|neural networks]] as a series of computational steps via a [[directed graph]].\\n\\n==See also==\\n* [[Comparison of deep learning software]]\\n\\n==References==\\n{{reflist}}\\n\\n{{Deep_Learning_Software}}\\n{{Microsoft Research Labs}}\\n\\n[[Category:Data mining and machine learning software]]\\n[[Category:Deep learning]]\\n[[Category:Free statistical software]]\\n\\n\\n{{ai-stub}}\",\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '49830146'},\n",
       " {'article': 'Msg.ai',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': '{{Lowercase title}}\\n{{Infobox dot-com company\\n| name = msg.ai\\n| logo = msgai logo.png\\n| logo_size = 180px\\n| type = [[Private company]]\\n| founded = {{start date and age|df=y|2015|5}}\\n| location = [[San Francisco, California]]\\n| founder = Puneet Mehta\\n| key_people = Puneet Mehta (CEO), Dan Greene (CRO)\\n| num_employees = 50+\\n| industry = [[Artificial Intelligence]]\\n| website = [http://msg.ai/ www.msg.ai]\\n}}\\n\\n\\'\\'\\'msg.ai\\'\\'\\' is an American [[artificial intelligence]] company and developer of [[human–computer interaction]] technologies founded in May 2015.<ref>{{cite web|url=https://www.crunchbase.com/organization/msg-ai|title= \"msg.ai\" Crunchbase |date= |accessdate=2017-10-13}}</ref>\\n\\n{{toclimit|3}}\\n\\n== History ==\\n\\nFounded in May 2015 by Puneet Mehta, msg.ai was recruited by the global media and advertising agency, [[Universal McCann]], to assist clients [[Heinz]] and [[BMW]]. \\n\\nmsg.ai worked with [[Sony Pictures]] to launch the first ever bot on Facebook Messenger for a $100M film, [[Goosebumps (film)|“Goosebumps”]] <ref>{{cite web|url=http://www.businessinsider.com/startup-msgai-wants-to-make-bots-big-2016-3|title= msg.ai wants to make bots big |date= |accessdate=2017-10-13}}</ref> and subsequently joined [[Y Combinator]] as a member of the Winter 2016 class.<ref>{{cite web|url=https://techcrunch.com/2016/03/23/y-combinator-winter-2016/|title= TechCrunch Y Combinator Winter 2016|date= |accessdate=2017-10-13}}</ref>\\n\\nIn 2016 the company received investments from several venture capital firms, including [[Index Ventures]], [[Y Combinator]], Bowery Capital, [[Salesforce Ventures]] and private entrepreneurs such as the founders of Google [[DeepMind]] and [[OpenAI]].<ref>{{cite web|url=https://www.crunchbase.com/organization/msg-ai/investors/investors_list|title= msg.ai Investors List |date= |accessdate=2017-10-13}}</ref>\\n\\nmsg.ai later partnered with [[Facebook]]’s Creative Shop and the [[Tommy Hilfiger]] fashion brand to develop a brand-specific bot with the goal of outperforming existing retail shopping bots.<ref>{{cite web|url=https://www.forbes.com/sites/rachelarthur/2016/09/11/tommy-hilfiger-launches-chatbot-on-facebook-messenger-to-tie-to-gigi-hadid-collection/#a329f0a2238b|title= Tommy Hilfiger Launches Chatbot On Facebook Messenger to Tie to Gigi Hadid Collection |date= |accessdate=2017-10-13}}</ref>\\n\\nIn 2016 there was an update to the platform to incorporate [[multivariate testing]]. This type of testing, unlike traditional A/B testing, permits the monitoring of user interaction with the bot, adjustments to the bot’s tone, and experiments with the use of media.<ref>{{cite web|url=https://venturebeat.com/2016/07/13/multivariate-testing-in-msg-ai-helps-you-measure-the-tone-of-your-chatbot/|title= Multivariate testing in Msg.ai helps you measure the tone of your chatbot |date= |accessdate=2017-10-13}}</ref>\\n\\n== Methodology ==\\nmsg.ai’s deep reinforcement learning platform allows for [[Chatbots|conversational AI and chatbots]] which engage through personalized interactions at scale and one-to-one relationships throughout the entire user experience.<ref>{{cite web|url=https://messenger.fb.com/blog/building-bots-for-messenger-tips-from-the-experts-msg-ai/|title=Building Bots for Messenger – Tips from the Experts|date=|accessdate=2017-10-31}}</ref>\\n\\nmsg.ai utilizes [[artificial intelligence]] to automate customized messages and engage in natural dialogues with deep reinforcement learning.<ref>{{cite web|url=https://venturebeat.com/2016/07/13/multivariate-testing-in-msg-ai-helps-you-measure-the-tone-of-your-chatbot/|title= Multivariate testing in Msg.ai helps you measure the tone of your chatbot |date= |accessdate=2017-10-13}}</ref> This allows the bot to interact in a conversational manner and in a number of ways, including offering product recommendations based on user preferences, answering questions regarding availability and pricing, guiding customers towards a purchase, and providing assistance to complex issues.\\n\\n== Partners & Customers ==\\nmsg.ai has collaborated with messaging platforms, creative agencies, and technology providers to build conversational AI for brands such as [[Heinz]]<ref>{{cite web|url=http://adage.com/article/digital/heinz-bmw-convos-facebook-messenger/299207/|title= Heinz BMW Convos Facebook Messenger |date= |accessdate=2017-10-13}}</ref>, [[BMW]]<ref>{{cite web|url=http://www.insiderhub.com/5-startups-that-are-gaining-way-in-2016/|title=5 Startups that are gaining way in 2016 |date= |accessdate=2017-10-13}}</ref>, [[Tommy Hilfiger]]<ref>{{cite web|url=https://techcrunch.com/2016/09/09/botty-hilfiger/|title=Botty-Hilfiger|date= |accessdate=2017-10-13}}</ref>, Signal<ref>{{cite web|url=http://www.thedrum.com/news/2016/11/11/anatomy-ad-how-unilevers-signal-used-chatbots-spread-the-word-brushing-teeth|title= Anatomy of an Ad: How Unilever\\'s Signal used chatbots to spread the word on brushing teeth| date= |accessdate=2017-10-13}}</ref>, and [[Anne Frank House|The Anne Frank House]].<ref>{{cite web|url=http://m.annefrank.org/key/aWQ9Mjc0NzEmbGM9ZW4=|title=Anne Frank House launches bot for Messenger|date= |accessdate=2017-11-02}}</ref>\\n\\n==See also==\\n* [[Artificial intelligence]]\\n* [[Chatbot]]\\n\\n== References==\\n\\n[[Category:Companies established in 2015]]\\n[[Category:Deep learning]]\\n[[Category:Artificial intelligence]]\\n[[Category:Deep learning]]',\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '55690224'},\n",
       " {'article': 'MXNet',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': \"{{Infobox software\\n| name                   = MXNet\\n| logo                   = \\n| screenshot             =\\n| caption                =\\n| collapsible            =\\n| author                 = \\n| developer              = [[Distributed (Deep) Machine Learning Community]]\\n| released               = \\n| latest release version = \\n| latest release date    = \\n| latest preview version = \\n| latest preview date    = \\n| programming language   = [[C++]], [[Python (programming language)|Python]], [[R (programming language)|R]], [[Julia (programming language)|Julia]], [[JavaScript]], [[Scala (programming language)|Scala]], [[Go (programming language)|Go]], [[Perl (programming language)|Perl]]\\n| operating system       = [[Microsoft Windows|Windows]], [[Linux]]\\n| platform               =\\n| size                   =\\n| language               =\\n| status                 =\\n| genre                  = Library for [[machine learning]] and [[deep learning]]\\n| license                = [[Apache 2.0]]\\n| website                = {{URL|http://mxnet.io}}\\n}}\\n\\n'''MXNet''' is a modern open-source [[deep learning]] framework used to train, and deploy deep neural networks. It is scalable, allowing for fast model training, and supports a flexible programming model and multiple languages ([[C++]], [[Python (programming language)|Python]], [[Julia (programming language)|Julia]], [[Matlab]], [[JavaScript]], [[Go (programming language)|Go]], [[R (programming language)|R]], [[Scala (programming language)|Scala]], [[Perl (programming language)|Perl]], [[Wolfram Language]])\\n\\nThe MXNet library is portable and can scale to multiple GPUs<ref>{{cite web|url=https://blogs.technet.microsoft.com/machinelearning/2016/09/15/building-deep-neural-networks-in-the-cloud-with-azure-gpu-vms-mxnet-and-microsoft-r-server/|title=Building Deep Neural Networks in the Cloud with Azure GPU VMs, MXNet and Microsoft R Server|publisher=|accessdate=13 May 2017}}</ref> and multiple machines. MXNet is supported by major Public Cloud providers including AWS<ref>{{cite web|url=https://aws.amazon.com/mxnet/|title=Apache MXNet on AWS - Deep Learning on the Cloud|website=Amazon Web Services, Inc.|accessdate=13 May 2017}}</ref> and Azure<ref>{{citeweb|url=https://blogs.technet.microsoft.com/machinelearning/2016/09/15/building-deep-neural-networks-in-the-cloud-with-azure-gpu-vms-mxnet-and-microsoft-r-server/|title=Building Deep Neural Networks in the Cloud with Azure GPU VMs, MXNet and Microsoft R Server.|website=Microsoft TechNet Blogs|accessdate=6 September 2017}}</ref>  Amazon has chosen MXNet as its deep learning framework of choice at AWS.<ref>{{cite web|url=http://www.allthingsdistributed.com/2016/11/mxnet-default-framework-deep-learning-aws.html|title=MXNet - Deep Learning Framework of Choice at AWS - All Things Distributed|website=www.allthingsdistributed.com|accessdate=13 May 2017}}</ref><ref>{{cite web|url=http://fortune.com/2016/11/22/amazon-deep-learning-mxnet/|title=Amazon Has Chosen This Framework to Guide Deep Learning Strategy|website=Fortune|accessdate=13 May 2017}}</ref> Currently, MXNet is supported by [[Intel]], Dato, [[Baidu]], [[Microsoft]], [[Wolfram Research]], and research institutions such as [[Carnegie Mellon University|Carnegie Mellon]], [[Massachusetts Institute of Technology|MIT]], the [[University of Washington]], and the [[Hong Kong University of Science and Technology]].<ref>{{Cite news|url=http://techgenix.com/mxnet-amazon-apache-incubator/|title=MXNet, Amazon’s deep learning framework, gets accepted into Apache Incubator|access-date=2017-03-08|language=en-US}}</ref>\\n\\n==Features==\\nApache MXNet is a lean, flexible, and ultra-scalable deep learning framework that supports state of the art in deep learning models, including convolutional neural networks (CNNs) and long short-term memory networks (LSTMs).\\n\\n===Scalable===\\nMXNet is designed to be distributed on dynamic Cloud infrastructure, using distributed parameter server (based on <ref>{{cite web|url=https://www.cs.cmu.edu/~muli/file/parameter_server_osdi14.pdf|title=Scaling Distributed Machine Learning with the Parameter Server|publisher=|accessdate=2014-10-08}}</ref>), and can achieve almost linear scale with multiple GPU/CPU.\\n\\n===Flexible===\\nMXNet supports both imperative and symbolic programming, which makes it easier for developers that are used to imperative programming to get started with deep learning. It also makes it easier to track, debug, save checkpoints, modify [[Hyperparameter_(machine_learning)|hyperparameters]], such as learning rate or perform [[early stopping]].\\n\\n===Multiple Languages===\\nSupports C++ for the optimized backend to get the most of the GPU or CPU available, and Python, R, Scala, Julia, Perl, Matlab and Javascript for the simple to use frontend for the developers.\\n\\n===Portable===\\nSupports an efficient deployment of a trained model to low-end devices for inference, such as mobile devices (using Amalgamation [[http://mxnet.io/how_to/smart_device.html|Amalgamation]]), IoT devices (using AWS Greengrass), Serverless (Using AWS Lambda) or [[Container (virtualization)|containers]]. These low-end environments can have only weaker CPU or limited memory (RAM), and should be able to use the models that were trained on a higher-level environment (GPU based cluster, for example).\\n\\n==See also==\\n* [[Comparison of deep learning software]]\\n\\n==References==\\n{{reflist}}\\n\\n{{Deep_Learning_Software}}\\n\\n[[Category:Data mining and machine learning software]]\\n[[Category:Deep learning]]\\n[[Category:Free statistical software]]\\n\\n\\n{{ai-stub}}\",\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '52513310'},\n",
       " {'article': 'ND4J (software)',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': \"{{Infobox software\\n| name                   = ND4J: N-Dimensional Arrays for Java\\n| logo                   = \\n| screenshot             = \\n| caption                =\\n| collapsible            =\\n| author                 = Adam Gibson\\n| developer              = Various<ref>[https://github.com/deeplearning4j/nd4j ND4J developers]</ref>\\n| released               = {{Start date and age|2014|09|15|df=yes}}\\n| latest release version = 0.9.1\\n| latest release date    = {{Start date and age|2017|08|03|df=yes}}\\n| latest preview version = \\n| latest preview date    = <!-- {{Start date and age|YYYY|MM|DD}} -->\\n| programming language   = [[Java (programming language)]], [[C++]]\\n| operating system       = [[Linux]], [[macOS]], [[Microsoft Windows|Windows]], [[Android (operating system)|Android]]\\n| platform               = [[Cross-platform]]\\n| size                   =\\n| language               = English\\n| status                 = Active\\n| genre                  = [[Natural language processing]], [[deep learning]], [[machine vision]]\\n| license                = [[Apache License|Apache]] 2.0\\n| website                = {{URL|nd4j.org}}\\n}}\\n\\n'''ND4J''' is a scientific computing [[Library (computing)|library]], written in the programming language [[C++]], operating on the [[Java virtual machine]] (JVM), and compatible with the languages [[Java (programming language)|Java]], [[Scala (programming language)|Scala]], and [[Clojure]].<ref>{{cite web|title=Official website|url=http://nd4j.org/}}</ref><ref>{{cite web|title=The Deeplearning4j Framework|url=http://gtts.ehu.es/WDW/biblio/JavaMagazine/javamagazine20150506-dl.pdf}}</ref> ND4J was contributed to the Eclipse Foundation in October 2017.<ref>{{cite web|title=Eclipse Deeplearning4j Project Page|url=https://projects.eclipse.org/proposals/deeplearning4j}}</ref>\\n\\nND4J is for performing [[linear algebra]] and [[Matrix (mathematics)|matrix]] manipulation in a production environment, integrating with [[Apache Hadoop]] and [[Apache Spark|Spark]] to work with distributed [[central processing unit]]s (CPUs) or [[graphics processing unit]]s (GPUs). It supports n-dimensional arrays for JVM-based languages.\\n\\nND4J is [[free and open-source software]], released under [[Apache License]] 2.0, and developed mostly by the group in [[San Francisco]] that built [[Deeplearning4j]], led by Adam Gibson.<ref>{{cite web|title=Github Repository|url=https://github.com/deeplearning4j/nd4s}}</ref> It was created under an [[Apache Software Foundation]] license.\\n\\n==Distributed==\\n\\nND4J's operations include [[Distributed computing|distributed]] [[Parallel computing|parallel]] versions. Operation can occur in a cluster and process massive amounts of data. Matrix manipulation occurs in parallel on CPUs or GPUs over [[cloud computing]], and can work in Spark or Hadoop clusters.\\n\\n==Other JVM Scientific Computing Libraries==\\n\\nA usability gap has separated Java, Scala, Kotlin and Clojure programmers from powerful tools in data analysis such as NumPy or Matlab. Libraries like Breeze don’t support n-dimensional arrays, or tensors, which are necessary for deep learning and other tasks. Libraries like Colt and Parallel Colt use or have dependencies with GPL in the license, making them unsuitable for commercial use. ND4J was built to address those functional and licenses issues. \\n\\n==See also==\\n{{Portal|Free software|Java}}\\n* [[NumPy]]\\n* [[SciPy]]\\n\\n==References==\\n{{Reflist}}\\n\\n==External links==\\n* {{Official website|nd4j.org}}\\n* [https://github.com/deeplearning4j/nd4j GitHub project pages]\\n\\n[[Category:Applied machine learning]]\\n[[Category:Array programming languages]]\\n[[Category:Numerical programming languages]]\\n[[Category:Data mining and machine learning software]]\\n[[Category:Free statistical software]]\\n[[Category:Java platform]]\\n[[Category:Java programming language family]]\\n[[Category:JVM programming languages]]\\n[[Category:Scala (programming language)]]\\n[[Category:Linear algebra]]\\n[[Category:Numerical analysis]]\\n[[Category:Computational statistics]]\\n[[Category:Artificial neural networks]]\\n[[Category:Free software programmed in Java (programming language)]]\\n[[Category:Free data analysis software]]\\n[[Category:Free science software]]\\n[[Category:Numerical analysis software for Linux]]\\n[[Category:Numerical analysis software for MacOS]]\\n[[Category:Numerical analysis software for Windows]]\\n[[Category:Free mathematics software]]\\n[[Category:Java (programming language) libraries]]\\n[[Category:Numerical software]]\\n[[Category:Cluster computing]]\\n[[Category:Hadoop]]\\n[[Category:Software using the Apache license]]\\n[[Category:Deep learning]]\\n[[Category:Neural network software]]\\n[[Category:Open-source artificial intelligence]]\\n[[Category:Scala (programming language)]]\\n\\n{{compu-stub}}\",\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '49594059'},\n",
       " {'article': 'Neural Designer',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': \"{{Infobox software\\n| name                   = Neural Designer\\n| logo                   = [[File:Neural Designer logo.png|256px]]\\n| screenshot             = \\n| caption                = Screenshot of Neural Designer\\n| developer              = [http://www.artelnics.com Artelnics]\\n| released               = \\n| latest release version = \\n| latest release date    = \\n| operating system       = [[Microsoft Windows]], [[OS X]], [[Linux]]\\n| programming language   = [[C++]]\\n| genre                  = [[Data mining]], [[machine learning]], [[predictive analytics]]\\n| license                = [[Proprietary software]]\\n| website                = [https://www.neuraldesigner.com www.neuraldesigner.com]\\n}}\\n\\n'''Neural Designer''' is a software tool for [[analytics|data analytics]] based on [[artificial neural network|neural networks]], a main area of [[artificial intelligence]] research.<ref>{{cite web\\n| url= http://www.predictiveanalyticstoday.com/neural-designer-data-mining-using-neural-networks/\\n| title= Neural Designer for data mining using neural networks \\n| publisher=  Predictive Analytics Today\\n| date= July 2014\\n}}</ref> It has been developed from the [[open source]] [[Library (computing)|library]] [[OpenNN]],<ref>{{cite web\\n| url= http://www.kdnuggets.com/2014/06/opennn-open-source-library-neural-networks.html\\n| title= OpenNN, An Open Source Library For Neural Networks\\n| publisher= Kdnuggets\\n| date= June 2014\\n}}</ref> and contains a [[graphical user interface]] which simplifies data entry and interpretation of results.\\n\\nIn 2014, this computer program was selected by the prestigious magazine ''Predictive Analytics Today'' among the top [[proprietary software]] for [[data mining]].<ref>{{cite web\\n| url= http://www.predictiveanalyticstoday.com/top-data-mining-software\\n| title= Top 26 data mining software\\n| publisher= Predictive Analytics Today\\n| date= November 2014\\n}}</ref> Also, during the same year, ''Big Data Analytics Today'' selected Neural Designer as one of the best brain inspired [[artificial intelligence]] projects.<ref>{{cite web\\n| url= http://www.bigdataanalyticstoday.com/top-brain-inspired-artificial-intelligence-projects\\n| title= Top 12 Brain Inspired Artificial Intelligence Projects\\n| publisher= Big Data Analytics Today\\n| date= December 2014\\n}}</ref>\\n\\nIn 2015, Neural Designer has been chosen by the [[European Commission]], within the [[Horizon 2020]] program, as a [[disruptive technology]] in the [[Information and communications technology|ICT]] field.<ref>{{cite web\\n|url= http://cordis.europa.eu/project/rcn/196466_en.html\\n|title= European Commission : CORDIS : Projects and Results : A high performance solution for predictive analytics\\n|publisher= European Commission\\n|date= May 2015 \\n}}</ref>\\n\\n==Features==\\n\\nNeural Designer performs [[descriptive statistics|descriptive]], diagnostic, [[predictive analytics|predictive]] and [[prescriptive analytics|prescriptive]] data analytics. It implements deep architectures with multiple non-linear layers and contains utilities to solve [[Regression analysis|function regression]], [[pattern recognition]], [[time series]] and [[Autoencoder | autoencoding]] problems.<ref>{{cite book \\n| url=https://books.google.es/books?id=q58OBwAAQBAJ&printsec=frontcover&dq=Deep+Learning+52+Success+Secrets+-+52+Most+Asked+Questions+On+Deep+Learning+-+What+You+Need+To+Know&hl=es&sa=X&ei=_rNZVdG-IYL_UpmGgIgL&redir_esc=y#v=onepage&q=Deep%20Learning%2052%20Success%20Secrets%20-%2052%20Most%20Asked%20Questions%20On%20Deep%20Learning%20-%20What%20You%20Need%20To%20Know&f=false\\n| title= Deep Learning, 52 Most Asked Questions - What You Need To Know \\n| author = Louis Lott \\n| year = 2014\\n}}</ref>\\n\\nThe input to Neural Designer is a data set, and the output from it is a [[Predictive modelling|predictive model]]. That result takes the form of an explicit [[mathematical expression]], which can be exported to any computer language or system.<ref>{{cite web\\n| url= http://edutechwiki.unige.ch/en/Neural_Designer\\n| title= Neural Designer, Data mining and learning analytics tools\\n| publisher= Edutech wiki\\n| date= May 2015\\n}}</ref>\\n\\n==Related tools==\\n\\n*[[Weka (machine learning)|Weka]]: free [[machine learning]] and [[data mining]] software.\\n*[[RapidMiner]]: free and commercial [[machine learning]] framework implemented in [[Java (programming language)|Java]].\\n*[[KNIME]]: free and commercial [[machine learning]] and [[data mining]] software.\\n\\n==See also==\\n\\n*[[Artificial intelligence]]\\n*[[Artificial neural network]]\\n*[[Comparison of deep learning software]]\\n*[[Data mining]]\\n*[[Deep learning]]\\n*[[Machine learning]]\\n*[[Predictive analytics]]\\n\\n==References==\\n{{Reflist}}\\n\\n{{Deep_Learning_Software}}\\n\\n[[Category:C++ software]]\\n[[Category:Data mining and machine learning software]]\\n[[Category:Deep learning]]\\n[[Category:Neural network software]]\\n[[Category:Proprietary software that uses Qt]]\",\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '47012074'},\n",
       " {'article': 'Numenta',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': '{{Infobox company\\n|name             = Numenta\\n|logo             = Numenta.png\\n|type             = [[Privately held company|Privately held]]\\n|industry         = [[Analytics]], [[Artificial Intelligence]] \\n|founder          = [[Jeff Hawkins]], [[Donna Dubinsky]], [[Dileep George]]\\n|foundation       = [[Redwood City, California]]<br />({{Start date|2005|02|4}})\\n|location_city    = [[Redwood City, California]]\\n|location_country = U.S.\\n|area_served      = Worldwide\\n|key_people       = [[Donna Dubinsky]] ({{small|CEO}}),<br />[[Jeff Hawkins]] ({{small|Co-founder}}),\\n|num_employees    = 11-50 <ref>https://www.crunchbase.com/organization/numenta</ref>\\n|homepage         = {{URL|http://numenta.com|numenta.com}}<br />{{URL|http://numenta.org|numenta.org}}\\n}}\\n\\n{{wikinews|New company to research artificial brain}}\\n\\n\\'\\'\\'Numenta\\'\\'\\' is a machine intelligence company that has developed a cohesive theory, core software, technology and applications based on the principles of the [[neocortex]]. The company was founded on February 4, 2005 by [[Palm (PDA)|Palm]] founder [[Jeff Hawkins]] with his longtime business partner [[Donna Dubinsky]] and [[Stanford]] graduate student [[Dileep George]]. Numenta is headquartered in [[Redwood City, California]] and is privately funded.\\n\\nNumenta has developed a number of example applications to demonstrate the applicability of its technology. Its first commercial product, Grok, offers [[anomaly detection]] for IT analytics, giving insight into IT systems to identify unusual behavior and reduce business downtime. Grok has since been licensed to their strategic partner, Avik Partners. Other applications include stock monitoring, geospatial tracking and rogue behavior.\\n\\nIn addition, Numenta has created [http://numenta.org/ NuPIC] (Numenta Platform for Intelligent Computing) as an open source project and maintains an open source community [http://discourse.numenta.org/ discussion forum].\\n\\nThe company name comes from the Latin \\'\\'[[wikt:mentis#Latin|mentis]]\\'\\' (“pertaining to the mind”) genitive of \\'\\'[[wikt:mens#Latin|mēns]]\\'\\' (“mind”).<ref>[http://www.numenta.com Numenta - numenta.com<!-- Bot generated title -->]</ref>\\n\\n==Technology==\\nNumenta\\'s machine intelligence technology is called [[hierarchical temporal memory]] (HTM), and is a computational theory of the neocortex.<ref>http://numenta.com/assets/pdf/whitepapers/hierarchical-temporal-memory-cortical-learning-algorithm-0.2.1-en.pdf</ref> This theory was first described in the book \\'\\'[[On Intelligence]]\\'\\', written in 2004 by [[Jeff Hawkins]] and co-author [[Sandra Blakeslee]]. At the core of HTM are time-based learning algorithms that store and recall temporal patterns. The HTM algorithms are documented and available through its open source project, [http://numenta.org/ NuPIC]. The HTM technology is suited to address a number of problems, particularly those with the following characteristics: streaming data, underlying patterns in data change over time, subtle patterns, time-based patterns.<ref>http://numenta.com/#technology</ref>\\n\\n==Neuroscience Research==\\nNumenta focuses on large-scale brain theory and simulation. Numenta researchers have written a number of [https://numenta.com/papers/ peer-reviewed journal papers and research reports].\\n\\n==Business Model==\\nNumenta is a technology provider and does not create go-to-market solutions for specific use cases. The company licenses their technology and application code to developers, organizations and companies who wish to build upon their technology.\".<ref>http://numenta.com/assets/pdf/apps/licensing-guide.pdf</ref> Numenta has several different types of licenses, including open source licenses, trial licenses and commercial licenses. Developers can use Numenta technology within NuPIC using the AGPL v3 open source license.\\n\\n==Applications==\\nThe following commercial applications are available using NuPIC: \\n* Grok - anomaly detection for IT servers, see [http://www.grokstream.com www.grokstream.com]\\n* Cortical.io - advanced natural language processing, see [http://www.cortical.io www.cortical.io]\\nThe following tools are available on NuPIC:\\n* HTM Studio - find anomalies in time series using your own data, see www.[http://www.Numenta.com/htm-studio/ numenta.com/htm-studio/]\\n* Numenta Anomaly Benchmark - compare HTM anomalies with other anomaly detection techniques, see https://numenta.com/numenta-anomaly-benchmark/\\nThe following example applications are available on NuPIC, see http://numenta.com/applications/:\\n* HTM for Stocks - example of tracking anomalies in the stock market (sample code)\\n* Rogue behavior detection - example of finding anomalies in human behavior (white paper and sample code)\\n* Geospatial tracking - example of finding anomalies in objectives moving through space and time (white paper and sample code)\\n\\n==Partnerships==\\nNumenta works with strategic partners, who license their technology and build products using HTM. [http://www.cortical.io/ Cortical.io] is using HTM for natural language processing, the partnership was announced in May 2015.<ref>http://numenta.com/press/numenta-and-cortical-io-form-strategic-partnership.html</ref> [http://grokstream.com/#home Avik Partners] has licensed their Grok for IT Analytics application to monitor IT servers.<ref>http://numenta.com/press/numenta-announces-licensing-of-grok-for-it-to-avik-partners.html</ref> The partnership was announced in August 2015. Numenta also partners with various research institutions and universities.\\n\\n==Open Source Community==\\nThe Numenta Platform for Intelligent Computing ([http://numenta.org/ NuPIC]) is an open source platform and community for machine intelligence based on HTM theory. NuPIC is an implementation of HTM and can be used to analyze streaming data. Numenta first announced in June 2013 that it would open-source its HTM technology, the core of its software and algorithms. This was accompanied by the new Numenta.org website<ref>[http://numenta.org Numenta.org website]</ref> and a mailing list for community members.\\n\\nCommunity members are contributors from around the world, and topics on the mailing list have included both discussions of the HTM theory as well as details of development of the software. The mission of NuPIC is to build and support a community, that is interested in machine learning and machine intelligence based on modeling the neocortex and its principles.<ref>https://discourse.numenta.org/</ref>\\n\\nNumenta has hosted a series of hackathons, the first one in 2013, to bring community members together to collaborate on NuPIC and its applications.\\n\\n==References==\\n<references/>\\n\\n==External links==\\n* {{Official website}}\\n* [http://gigaom.com/2014/09/24/the-gigaom-interview-jeff-hawkins-on-why-his-approach-to-ai-will-become-the-approach-to-ai/%20Gigaom%20Article%20with%20Jeff%20Hawkins%20on%20Why%20his%20Approach%20to%20AI%20will%20become%20the%20Approach%20to%20AI Gigaom Article on Numenta\\'s Approach to AI]\\n* [https://venturebeat.com/2014/07/09/numentas-brain-research-has-taken-a-long-nine-years-but-it-starting-to-pay-off-interview/ VentureBeat article \"After Nine Years of Research Numenta Finally has Apps that Mimic the Way the Brain Works\\']\\n* [http://www.gartner.com/research/fellows/fellows_interview_jeff_hawkins_tom_austin.jsp Gartner Fellows Interview with Jeff Hawkins Founder of Numenta on 2 March 2006]\\n* [https://www.wired.com/wired/archive/15.03/hawkins.html Wired magazine article underlying details and giving background information on Numenta.]\\n* [https://www.theguardian.com/technology/2008/apr/10/robot.brain Guardian Newspaper 10 April 2008 article providing a general introduction to Numenta.]\\n* [http://www.technologyreview.com/business/26811/page1/ \"The Brainy Learning Algorithms of Numenta\"] December 2010 article in \\'\\'[[Technology Review]]\\'\\'\\n* [https://av.tib.eu/series/91/2015+spring+nupic+hackathon Videos from 2015 Spring NuPIC Hackathon]. Available at the [https://av.tib.eu/ AV-Portal] of the [[German National Library of Science and Technology|German National Library of Science and Technology (TIB)]]\\n\\n\\n[[Category:Companies established in 2005]]\\n[[Category:2005 establishments in California]]\\n[[Category:Applied machine learning]]\\n[[Category:Companies based in Redwood City, California]]\\n[[Category:Technology companies based in the San Francisco Bay Area]]\\n[[Category:Information technology companies of the United States]]\\n[[Category:Deep learning]]\\n[[Category:Free artificial intelligence applications]]',\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '1643246'},\n",
       " {'article': 'OpenNN',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': \"{{Infobox software\\n| name                   = Open Neural Networks Library\\n| title                  = OpenNN\\n| logo                   =\\n| screenshot             = \\n| caption                = \\n| developer              = [http://www.artelnics.com Artelnics]\\n| frequently updated     = \\n| operating system       = [[Cross-platform]]\\n| platform               = \\n| genre                  = [[Neural networks]]\\n| license                = [[GNU Lesser General Public License|LGPL]]\\n| website                = {{URL|http://www.opennn.net}}\\n}}\\n\\n'''OpenNN''' (Open Neural Networks Library) is a [[software library]] written in the [[C++]] [[programming language]] which implements [[neural networks]],<ref>{{cite web|url=http://www.kdnuggets.com/2014/06/opennn-open-source-library-neural-networks.html|title=OpenNN, An Open Source Library For Neural Networks | publisher=KDNuggets | date= June 2014}}</ref> a main area of [[deep learning]] research. The library is [[open source]], licensed under the [[GNU Lesser General Public License]]. \\n\\n==Characteristics==\\n\\nThe software implements any number of layers of non-linear processing units for [[supervised learning]]. This deep architecture allows the design of neural networks with [[Universal approximation theorem | universal approximation]] properties. Additionally, it allows [[multiprocessing]] programming by means of [[OpenMP]], in order to increase [[computer performance]].   \\n\\nOpenNN contains [[data mining]] algorithms as a bundle of functions. These can be embedded in other software tools, using an [[application programming interface]], for the integration of the [[predictive analytics]] tasks. In this regard, a graphical user interface is missing but some functions can be supported by specific visualization tools.<ref>{{cite journal | url=https://www.academia.edu/6491835/Categorization_of_Data_Mining_Tools_Based_on_Their_Types_ | title=Categorization of Data Mining Tools Based on Their Types | author=J. Mary Dallfin Bruxella| journal = International Journal of Computer Science and Mobile Computing | volume = 3 | issue = 3 | pages = 445-452 | year = 2014 |display-authors=etal}}</ref>\\n\\n==History==\\n\\nThe development started in 2003 at the [[International Center for Numerical Methods in Engineering | International Center for Numerical Methods in Engineering (CIMNE)]], within the research project funded by the [[European Union]] called RAMFLOOD (Risk Assessment and Management of FLOODs).<ref>{{cite web|url=http://cordis.europa.eu/projects/rcn/67049_en.html |title=CORDIS - EU Research Project RAMFLOOD |publisher=European Commission | date=December 2004}}</ref> Then it continued as part of similar projects.\\nAt present, OpenNN is being developed by the [[startup company]] Artelnics.<ref>{{cite web | url=http://www.artelnics.com |title=Artelnics home page}}</ref>\\n\\nIn 2014, ''Big Data Analytics Today'' rated OpenNN as the #1 brain inspired [[artificial intelligence]] project.<ref>{{cite web | url=http://www.bigdataanalyticstoday.com/top-brain-inspired-artificial-intelligence-projects | title = Top 12 Brain Inspired Artificial Intelligence Projects | publisher= Big Data Analytics Today | date= October 2014}}</ref> \\nAlso, during the same year, ''ToppersWorld'' selected OpenNN among the top 5 open source [[data mining]] tools.<ref>{{cite web | url=http://toppersworld.com/top-5-open-source-data-mining-tools/|title=Top 5 Open Source Data Mining Tools|publisher=ToppersWorld | date = November 2014}}</ref> \\n\\n==Applications==\\n\\nOpenNN is a general purpose [[artificial intelligence]] software package.<ref>{{cite web|url= http://www.efytimes.com/e1/fullnews.asp?edid=142005|title=Here Are 7 Thought-Provoking AI Software Packages For Your Info|publisher=Saurabh Singh|accessdate=25 June 2014}}</ref> It uses [[machine learning]] techniques for solving [[data mining]] and [[predictive analytics]] tasks in different fields. For instance, the library has been applied in the engineering,<ref>{{cite journal|url= http://onlinelibrary.wiley.com/doi/10.1002/nme.2304/abstract|title= Neural Networks for Variational Problems in Engineering | author = R. Lopez| journal = International Journal for Numerical Methods in Engineering | volume = 75 | issue = 11 | pages =  1341–1360 | year = 2008 | doi=10.1002/nme.2304|display-authors=etal}}</ref> energy,<ref>{{cite journal | url=https://link.springer.com/chapter/10.1007/978-3-642-20282-7_20 | title=Optimisation of Concentrating Solar Thermal Power Plants with Neural Networks | journal = Lecture Notes in Computer Science | author = P. Richter| volume = 6593 | pages = 190–199 | year = 2011 | doi=10.1007/978-3-642-20282-7_20|display-authors=etal}}</ref> or chemistry<ref>{{cite journal | url= https://link.springer.com/article/10.1007/s00216-014-8317-3 | title = Artificial Neural Network Prediction of Multilinear Gradient Retention in Reversed-Phase HPLC | journal = Analytical and Bioanalytical Chemistry |  author= A.A. D’Archivio| pages = 1-10 | year= 2014 | doi=10.1007/s00216-014-8317-3 | volume=407|display-authors=etal}}</ref> sectors.\\n\\n==See also==\\n\\n{{Portal|Free software|Artificial intelligence}}\\n* [[Comparison of deep learning software]]\\n* [[Neural Designer]], also developed by Artelnics\\n* [[Artificial intelligence]]\\n* [[Machine learning]]\\n* [[Deep learning]]\\n* [[Artificial neural network]]\\n\\n==References==\\n{{Reflist}}\\n\\n==External links==\\n* [https://github.com/Artelnics/OpenNN OpenNN project at GitHub]\\n* [http://www.sourceforge.net/projects/opennn OpenNN project at SourceForge]\\n\\n{{Deep Learning Software}}\\n\\n[[Category:Applied machine learning]]\\n[[Category:Artificial intelligence applications]]\\n[[Category:Artificial neural networks]]\\n[[Category:C++ libraries]]\\n[[Category:Data mining and machine learning software]]\\n[[Category:Deep learning]]\\n[[Category:Free software programmed in C++]]\\n[[Category:Machine learning]]\\n[[Category:Neural network software]]\\n[[Category:Open-source artificial intelligence]]\\n[[Category:Software using the LGPL license]]\",\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '42129549'},\n",
       " {'article': 'Qloo',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': '{{Infobox dot-com company\\n| name     = Qloo\\n| logo     = [[File:Qloo-app-logo.png|160px]]\\n| caption          = \\n| type     = Private\\n| foundation       = 2012\\n| founder          = Alex Elias <br /> Jay Alger\\n| location         = [[New York City]]\\n| industry         = Internet <br /> [[Artificial Intelligence]] \\n| revenue          = \\n| operating_income = \\n| net_income       = \\n| num_employees    = <!-- two? -->\\n| url              = {{url|http://qloo.com}}\\n}}\\n\\n\\'\\'\\'Qloo\\'\\'\\' (pronounced \"clue\") is a company that uses [[artificial intelligence]] (AI). An [[application programming interface]] (API) provides cultural correlations.<ref name=culturalai>{{Cite web|url=https://techcrunch.com/2016/06/15/leonardo-dicaprio-barry-sternlicht-back-qloo-a-cultural-recommendation-engine/|title=Leonardo DiCaprio, Barry Sternlicht back Qloo, a cultural recommendation engine|last=Kolodny|first=Lora|website=TechCrunch|access-date=2016-06-15}}</ref> It was founded by [[Alex Elias]] and received funding from [[Leonardo DiCaprio]], [[Barry Sternlicht]] and [[Pierre Lagrange]].\\n\\nQloo establishes consumer preference correlations via [[machine learning]] across multiple proprietary, customer and open-source data across cultural domains including music, film, television, dining, nightlife, fashion, books and travel. The [[recommender system]] uses AI to predict correlations for further applications.<ref name=culturalai />\\n\\n==History==\\nQloo was founded in 2012 by chief executive officer Alex Elias and chief operating officer Jay Alger.<ref>Jon Swartz, [https://www.usatoday.com/story/tech/2012/11/08/qloo-amazon-pandora-netflix/1684053/ “Getting a Qloo on where to find similar tastes,”] \\'\\'[[USA Today]]\\'\\', November 8, 2012.</ref> Elias was formerly a [[hedge fund]] manager with APE Capital.<ref name=\"mflamm\">Matthew Flamm, [http://www.crainsnewyork.com/article/20131114/TECHNOLOGY/131119933 “Cedric the Entertainer gets a Qloo,”] \\'\\'[[Crain\\'s New York Business]]\\'\\', November 14, 2013.</ref><ref>Joao-Pierre S. Ruth, [http://www.xconomy.com/new-york/2013/11/14/qloo-now-beta-wants-learn-different-cultural-tastes/ “Qloo, Now Out of Beta, Wants to Learn Your Different Cultural Tastes,”] [[Xconomy]], November 14, 2013.</ref><ref>Jessica Naziri, [http://articles.latimes.com/2013/mar/17/business/la-fi-tn-qloo-inspiration-engine-20130317 “Start-up Sunday: Qloo, a ‘cultural discovery’ search engine,”] \\'\\'[[Los Angeles Times]]\\'\\', March 17, 2013.</ref>\\nHe graduated from the [[University of Southern California]], and then developed his idea at law school at [[New York University]].<ref name=\"sclayton\">Sara Clayton, [http://dailytrojan.com/2014/01/14/alumnus-creates-standout-recommendation-app/ “Alumnus creates standout recommendation app,”] \\'\\'[[Daily Trojan]]\\'\\', January 14, 2014.</ref>\\nAlger was formerly the CEO of the digital agency Deepend.<ref name=\"lkolodny\">Lora Kolodny, [https://blogs.wsj.com/venturecapital/2013/11/19/cedric-the-entertainer-building-an-audience-is-like-building-a-startup/ “Cedric The Entertainer: Building An Audience Is Like Building A Startup,”] \\'\\'[[Wall Street Journal]]\\'\\', November 19, 2013.</ref><ref name=\"pbond\">Paul Bond, [http://www.hollywoodreporter.com/news/new-digital-firm-qloo-raises-655512 “New Digital Firm Qloo Raises $3 Million From Hollywood Insiders,”] \\'\\'[[The Hollywood Reporter]]\\'\\', November 14, 2013.</ref>\\n\\nQloo was tested on a private website in April 2012. \\nIn 2012, Qloo raised $1.4 million in seed funding from investors including [[Cedric the Entertainer]], [[Danny Masterson]], and venture capital firm Kindler Capital.<ref name=\"lkolodny\"/><ref name=\"tspangler\"/><ref name=\"cshu\"/>\\nQloo had a public beta release in November 2012 after its initial funding.<ref name=\"bahernandez\">Brian Anthony Hernandez, [http://mashable.com/2012/11/29/qloo/ “Qloo Finds New Things For You To Watch, Read, Listen, Eat and Wear,”] [[Mashable]], November 29, 2012.</ref><ref>Ki Mae Heussner, [http://gigaom.com/2012/11/08/with-1-4m-qloo-finds-food-films-and-fashion-that-match-your-taste/ “With $1.4M, Qloo finds films, fashion, food and more that match your taste,”] [[GigaOm]], November 8, 2012.</ref> \\n\\nIn 2013, the company raised an additional $1.6 million from [[Cross Creek Pictures]] founding partner Tommy Thompson, and Samih Toukan and Hussam Khoury, founders of [[Maktoob]], an Internet services company purchased by [[Yahoo!]] for $164 million in 2009.<ref name=\"pbond\"/>\\nOn November 14, 2013, a website and an [[iPhone]] app were announced.<ref>{{Cite news|url=https://techcrunch.com/2013/11/14/with-3m-in-funding-qloo-launches-to-let-you-discover-interesting-content-in-eight-categories/|title=With $3M In Funding, Qloo Launches To Let You Discover Interesting Content In Eight Categories|last=Shu|first=Catherine|work=TechCrunch|access-date=2017-09-27|language=en}}</ref><ref name=\"mflamm\"/> The company later released an [[Android (operating system)|Android]] app, and [[Tablet computer|tablet]] versions, in mid-2014.<ref name=\"tspangler\">Todd Spangler, [http://variety.com/2013/digital/news/recommendation-app-qloo-raise-1-6-mil-from-investors-including-producer-tommy-thompson-1200831885/ “Recommendation App Qloo Raises $1.6 Mil from Investors Including Producer Tommy Thompson,”] \\'\\'[[Variety (magazine)|Variety]]\\'\\', November 14, 2013.</ref>\\n\\nIn 2016, Qloo secured $4.5 million in [[venture capital]] investment.<ref>{{cite web|title=Recommendation service Qloo closes Series A with DiCaprio as a backer|url=http://www.bizjournals.com/newyork/news/2016/06/15/recommendation-service-qloo-closes-series-a-with.html|publisher=Biz Journals|date=June 15, 2016}}</ref> The $4.5 million was split between a number of investors, including [[Barry Sternlicht]], [[Pierre Lagrange]] and [[Leonardo DiCaprio]].<ref name=techcrunch>{{cite web|last1=Kolodny|first1=Lora|title=Leonardo DiCaprio, Barry Sternlicht back Qloo, a cultural recommendation engine|url=https://techcrunch.com/2016/06/15/leonardo-dicaprio-barry-sternlicht-back-qloo-a-cultural-recommendation-engine/|publisher=[[TechCrunch]]|date=June 15, 2016}}</ref> In July 2017, Qloo raised $6.5 million in funding rounds from AXA Strategic Ventures and [[Elton John]].<ref>{{Cite web|url=http://oneclickitsolution.com/2017/07/12/elton-john-invests-in-qloo-a-startup-that-analyzes-your-taste/|title=Elton John invests in Qloo, a startup that analyzes your taste|website=OneClick|language=en-US|access-date=2017-10-06}}</ref><ref>{{Cite news|url=https://techcrunch.com/2017/07/11/elton-john-backs-qloo/|title=Elton John invests in Qloo, a startup that analyzes your taste|last=Ha|first=Anthony|work=TechCrunch|access-date=2017-10-06|language=en}}</ref>\\n\\nFollowing the investment, the founders stated in an interview with [[Tech Crunch]] that they would use the investment to expand Qloo\\'s database. They hoped the move would secure larger contracts with corporate clients.<ref name=techcrunch /> At the time, clients already included [[Fortune 500]] companies such as [[Twitter]], [[PepsiCo]] and [[BMW]].<ref>{{cite web|last1=Chakrapani|first1=Harini|title=Leonardo DiCaprio is the latest celebrity to invest in this Manhattan startup|url=http://www.crainsnewyork.com/article/20160615/TECHNOLOGY/160619929/recommendation-app-developer-qloo-raises-4-5-million-from-leonardo-dicaprio-in-a-funding-round-that-included-barry-sternlicht-of-starwood-capital-group-and-pierre-lagrange-of-glg-partners-dicaprio-joins-cedric-the-entertainer-danny-masterson-of-that-70s-show|publisher=[[Crain Communications]]|date=June 15, 2016}}</ref>\\n\\n==Services and features==\\nQloo calls itself a cultural AI platform to provide real-time correlation data across domains of culture and entertainment including:  film, music, television, dining, nightlife, fashion, books and travel.<ref>Alan McGlade, [https://www.forbes.com/sites/alanmcglade/2013/12/27/cracking-the-code-for-film-marketing/ “Cracking The Code For Film Marketing,”] \\'\\'[[Forbes]]\\'\\', December 27, 2013.</ref> Each category contains subcategories.<ref>Dani Fankhauser, [http://mashable.com/2013/12/21/books-taylor-swift/ “If You Like Taylor Swift’s Music, You Might Enjoy These Books,”] Mashable, December 21, 2013.</ref> \\n\\nQloo’s knowledge of a user\\'s taste in one category can be utilized to offer suggestions in other categories.<ref name=\"bahernandez\"/><ref name=\"cshu\">Catherine Shu, [https://techcrunch.com/2013/11/14/with-3m-in-funding-qloo-launches-to-let-you-discover-interesting-content-in-eight-categories/ “With $3M In Funding, Qloo Launches To Let You Discover Interesting Content In Eight Categories,”] [[TechCrunch]], November 14, 2013.</ref> Users then rate the suggestions, providing it with feedback for future suggestions.<ref name=\"mflamm\"/><ref name=\"pbond\"/><ref name=\"lkolodny\"/><ref name=\"mflamm\"/><ref name=\"sclayton\"/>\\nQloo has partnerships with companies such as [[Expedia]] and [[iTunes]].<ref name=\"pbond\"/>\\n\\n==References==\\n{{Reflist|2}}\\n\\n==External links==\\n{{Official website|http://www.qloo.com/}}\\n\\n[[Category:Companies based in New York City]]\\n[[Category:Artificial intelligence]]\\n[[Category:Recommender systems]]\\n[[Category:Business software companies]]\\n[[Category:Big data companies]]\\n[[Category:Deep learning]]\\n[[Category:Machine learning]]\\n[[Category:Artificial intelligence applications]]',\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '41732818'},\n",
       " {'article': 'TensorFlow',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': '{{Infobox software\\n| name                   = TensorFlow\\n| logo                   = TensorFlowLogo.png\\n| author                 =\\n| developer              = [[Google Brain]] Team<ref name=Credits />\\n| released               = {{Start date and age|2015|11|09}}\\n| latest release version = 1.4.0<ref>{{Cite news |url = https://github.com/tensorflow/tensorflow/releases |title = TensorFlow Release |access-date = June 19, 2017 |language = en-US }}</ref>\\n| latest release date    = {{Start date and age|2017|11|02}}\\n| programming language   = [[Python (programming language)|Python]], [[C++]], [[CUDA]]\\n| platform               = [[Linux]], [[macOS]], [[Windows]], [[Android (operating system)|Android]]\\n| genre                  = [[Machine learning]] [[Library (computing)|library]]\\n| license                = [[Apache License|Apache 2.0 open source license]]\\n| website                = {{URL|https://www.tensorflow.org}}\\n}}\\n\\n\\'\\'\\'TensorFlow\\'\\'\\' is an [[open-source]] [[Library (computing)|software library]] for [[dataflow]] programming across a range of tasks. It is a symbolic math library, and also used for [[machine learning]] applications such as [[neural networks]].<ref name=YoutubeClip>[https://www.youtube.com/watch?v=oZikw5k_2FM \"TensorFlow: Open source machine learning\"] \"It is machine learning software being used for various kinds of perceptual and language understanding tasks\" — Jeffrey Dean, minute 0:47 / 2:17 from Youtube clip</ref> It is used for both research and production at [[Google]],{{zwj}}<ref name=YoutubeClip />{{rp|min 0:15/2:17}}&thinsp;<ref name=whitepaper2015 />{{rp|p.2}}&thinsp;<ref name=YoutubeClip />{{rp|0:26/2:17}} often replacing its closed-source predecessor, DistBelief.\\n\\nTensorFlow was developed by the [[Google Brain]] team for internal Google use. It was released under the [[Apache License|Apache 2.0 open source license]] on November 9, 2015.<ref name=\"Credits\">{{cite web |title = Credits |url = http://tensorflow.org/about |website = TensorFlow.org |accessdate = November 10, 2015 }}</ref><ref name=\"Metz-Nov9\">{{cite web |last1 = Metz |first1 = Cade |title = Google Just Open Sourced TensorFlow, Its Artificial Intelligence Engine |url = https://www.wired.com/2015/11/google-open-sources-its-artificial-intelligence-engine/ |website = [[Wired (website)|Wired]] |accessdate = November 10, 2015 |date = November 9, 2015 }}</ref>\\n\\n== History ==\\n=== DistBelief ===\\nStarting in 2011, [[Google Brain]] built DistBelief as a [[Proprietary software|proprietary]] [[machine learning]] system based on [[deep learning]] [[Artificial neural network|neural networks]]. Its use grew rapidly across diverse [[Alphabet Inc.|Alphabet]] companies in both research and commercial applications.<ref name=whitepaper2015>{{cite web |last1 = Dean |first1 = Jeff |last2 = Monga |first2 = Rajat |first3 = Sanjay |last3 = Ghemawat |display-authors = 2 |authorlink1 = Jeff Dean (computer scientist) |title = TensorFlow: Large-scale machine learning on heterogeneous systems |url = http://download.tensorflow.org/paper/whitepaper2015.pdf |website = TensorFlow.org |publisher = Google Research |accessdate = November 10, 2015 |date = November 9, 2015 }}</ref><ref name=Perez>{{cite web |last1 = Perez |first1 = Sarah |title = Google Open-Sources The Machine Learning Tech Behind Google Photos Search, Smart Reply And More |url = https://techcrunch.com/2015/11/09/google-open-sources-the-machine-learning-tech-behind-google-photos-search-smart-reply-and-more/ |website = TechCrunch |accessdate = November 11, 2015 |date = November 9, 2015 }}</ref> Google assigned multiple computer scientists, including [[Jeff Dean (computer scientist)|Jeff Dean]], to simplify and [[Code refactoring|refactor]] the codebase of DistBelief into a faster, more robust application-grade library, which became TensorFlow.<ref name=Oremus>{{cite web |last1 = Oremus |first1 = Will |title = What Is TensorFlow, and Why Is Google So Excited About It? |url = http://www.slate.com/blogs/future_tense/2015/11/09/google_s_tensorflow_is_open_source_and_it_s_about_to_be_a_huge_huge_deal.html |website = Slate |accessdate = November 11, 2015 |date = November 11, 2015 }}</ref> In 2009, the team, led by [[Geoffrey Hinton]], had implemented generalized [[backpropagation]] and other improvements which allowed generation of neural networks with substantially higher accuracy, for instance a 25% reduction in errors in speech recognition.<ref name=Ward-Bailey>{{cite web |last1 = Ward-Bailey |first1 = Jeff |title = Google chairman: We’re making \\'real progress\\' on artificial intelligence |url = http://www.csmonitor.com/Technology/2015/0914/Google-chairman-We-re-making-real-progress-on-artificial-intelligence |website = CSMonitor |accessdate = November 25, 2015 |date = November 25, 2015 }}</ref>\\n\\n=== TensorFlow ===\\nTensorFlow is Google Brain\\'s second generation  system. Version 1.0.0 was released on February 11, 2017.<ref>{{Cite web|url=https://github.com/tensorflow/tensorflow/blob/07bb8ea2379bd459832b23951fb20ec47f3fdbd4/RELEASE.md|title=Tensorflow Release 1.0.0|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}</ref>  While the [[reference implementation]] runs on single devices, TensorFlow can run on multiple [[central processing unit|CPUs]] and [[GPU]]s (with optional [[CUDA]] and [[SYCL]] extensions for [[general-purpose computing on graphics processing units]]).<ref name=Metz-Nov10>{{cite news |last1 = Metz |first1 = Cade |title = TensorFlow, Google\\'s Open Source AI, Points to a Fast-Changing Hardware World |url = https://www.wired.com/2015/11/googles-open-source-ai-tensorflow-signals-fast-changing-hardware-world/ |accessdate = November 11, 2015 |website = Wired |date = November 10, 2015 }}</ref> TensorFlow is available on 64-bit [[Linux]], [[macOS]], [[Windows]], and mobile computing platforms including [[Android (operating system)|Android]] and [[iOS]].\\n\\nTensorFlow computations are expressed as [[State (computer science)|stateful]] [[dataflow programming|dataflow]] [[directed graph|graphs]]. The name TensorFlow derives from the operations that such neural networks perform on multidimensional data arrays. These arrays are referred to as \"[[tensor]]s\". In June 2016, Dean stated that 1,500 repositories on [[GitHub]] mentioned TensorFlow, of which only 5 were from Google.<ref name=\"1500repo\\'s\">[https://www.youtube.com/watch?v=Rnm83GqgqPE  Machine Learning: Google I/O 2016 Minute 07:30/44:44 ] accessdate=2016-06-05</ref>\\n\\n=== Tensor processing unit (TPU) ===\\nIn May 2016 Google announced its [[Tensor processing unit|tensor processing unit (TPU)]], a custom [[Application-specific integrated circuit|ASIC]] built specifically for [[machine learning]] and tailored for TensorFlow. TPU is a programmable [[AI accelerator (computer hardware)|AI accelerator]] designed to provide high [[throughput]] of [[low-precision arithmetic]] (e.g., [[8-bit]]), and oriented toward using or running models rather than [[Supervised learning|training]] them. Google announced they had been running TPUs inside their data centers for more than a year, and have found them to deliver an [[order of magnitude]] better-optimized [[performance per watt]] for machine learning.<ref>{{cite web |last1 = Jouppi |first1 = Norm |title = Google supercharges machine learning tasks with TPU custom chip |url = https://cloudplatform.googleblog.com/2016/05/Google-supercharges-machine-learning-tasks-with-custom-chip.html |website = Google Cloud Platform Blog |accessdate = May 19, 2016 }}</ref>\\n\\nIn May 2017 Google announced the second-generation, as well as the availability of the TPUs in [[Google Compute Engine]].<ref>{{Cite news|url=https://www.blog.google/topics/google-cloud/google-cloud-offer-tpus-machine-learning/|title=Build and train machine learning models on our new Google Cloud TPUs|date=May 17, 2017|work=Google|access-date=May 18, 2017|language=en}}</ref> The second-generation TPUs deliver up to 180 teraflops of performance, and when organized into clusters of 64 TPUs, provide up to 11.5 petaflops.\\n\\n===TensorFlow Lite===\\nIn May 2017 Google announced a software stack specifically for Android development, TensorFlow Lite,<ref>[https://www.theverge.com/2017/5/17/15645908/google-ai-tensorflowlite-machine-learning-announcement-io-2017  Google’s new machine learning framework is going to put more AI on your phone]</ref> beginning with Android Oreo.\\n\\n=== Applications ===\\nGoogle officially released [[RankBrain]] on October 26, 2015, backed by TensorFlow.\\n\\n== Features ==\\nTensorFlow provides a [https://www.tensorflow.org/api_docs/python/ Python API], as well as  [https://www.tensorflow.org/api_docs/cc/ C++], [https://github.com/tensorflow/haskell Haskell], [https://www.tensorflow.org/api_docs/java/reference/org/tensorflow/package-summary Java], [https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go Go], and [https://github.com/tensorflow/rust Rust] APIs. Third party packages are available for [https://github.com/migueldeicaza/TensorFlowSharp C#], [https://github.com/malmaud/TensorFlow.jl Julia], [https://github.com/rstudio/tensorflow R], and [https://github.com/eaplatanios/tensorflow_scala Scala].\\n\\n== Applications ==\\nAmong the applications for which TensorFlow is the foundation, are automated image captioning software, such as [[DeepDream]].<ref name=Byrne>{{cite web |last1 = Byrne |first1 = Michael |title = Google Offers Up Its Entire Machine Learning Library as Open-Source Software |url = http://motherboard.vice.com/en_uk/read/google-offers-up-its-entire-machine-learning-library-as-open-source |website = Vice |accessdate = November 11, 2015 |date = November 11, 2015 }}</ref> RankBrain now handles a substantial number of search queries, replacing and supplementing traditional static algorithm based search results.<ref name=Woollaston>{{cite web |last1 = Woollaston |first1 = Victoria |title = Google releases TensorFlow – Search giant makes its artificial intelligence software available to the public |url = http://www.dailymail.co.uk/sciencetech/article-3311650/Google-releases-TensorFlow-Search-giant-makes-artificial-intelligence-software-available-public.html |website = DailyMail |accessdate = November 25, 2015 |date = November 25, 2015 }}</ref>\\n\\n== See also ==\\n* [[Artificial neural network]]\\n* [[Comparison of deep learning software]]\\n* [[Convolutional neural network]]\\n* [[Deep learning]]\\n* [[Machine learning]]\\n\\n== References ==\\n{{Reflist|30em}}\\n\\n== External links ==\\n* {{Official website|https://www.tensorflow.org}}\\n* {{GitHub|tensorflow/tensorflow|TensorFlow}}\\n* [https://www.openhub.net/p/tensorflow Sources stats]\\n\\n{{Deep Learning Software}}\\n{{Use mdy dates|date=November 2017}}\\n\\n\\n[[Category:Applied machine learning]]\\n[[Category:Data mining and machine learning software]]\\n[[Category:Deep learning]]\\n[[Category:Free software programmed in C++]]\\n[[Category:Free software programmed in Python]]\\n[[Category:Free statistical software]]\\n[[Category:Open-source artificial intelligence]]\\n[[Category:Python scientific libraries]]\\n[[Category:Software using the Apache license]]',\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '48508507'},\n",
       " {'article': 'Theano (software)',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': \"'''Theano''' is a numerical computation [[Library (computing)|library]] for [[Python (programming language)|Python]].<ref>{{cite journal|last=Bergstra|first=J. |author2=O. Breuleux |author3=F. Bastien |author4=P. Lamblin |author5=R. Pascanu |author6=G. Desjardins |author7=J. Turian |author8=D. Warde-Farley |author9=Y. Bengio|title=Theano: A CPU and GPU Math Expression Compiler|journal=Proceedings of the Python for Scientific Computing Conference (SciPy) 2010|date=30 June 2010|url=http://www.iro.umontreal.ca/~lisa/pointeurs/theano_scipy2010.pdf}}</ref>\\nIn Theano, computations are expressed using a [[NumPy]]-esque syntax and [[Compiler|compiled]] to run efficiently on either CPU or [[GPGPU|GPU]] architectures.\\n\\nTheano is an [[open source]] project<ref>{{cite web|title=Github Repository|url=https://github.com/Theano/Theano/}}</ref> primarily developed by a [[machine learning]] group at the [[Université de Montréal]].<ref>{{cite web|url=http://deeplearning.net/|title=deeplearning.net}}</ref>\\n\\nOn September 28, 2017, Pascal Lamblin announced major development would cease after the 1.0 release, due before the end of 2017,<ref>{{cite mailing list |url=https://groups.google.com/forum/#!topic/theano-users/7Poq8BZutbY |title=MILA and the future of Theano |date=2017-09-28 |accessdate=2017-09-28 |mailing-list=theano-users |last=Lamblin |first=Pascal }}</ref> due to competing offerings by strong industrial players.\\n\\n==See also==\\n* [[Comparison of deep learning software]]\\n\\n==References==\\n{{Reflist}}\\n\\n==External links==\\n* {{Official website|https://github.com/Theano/}} (GitHub)\\n* [http://deeplearning.net/software/theano/ Theano] at Deep Learning, Université de Montréal\\n\\n{{Deep Learning Software}}\\n\\n[[Category:Array programming languages]]\\n[[Category:Deep learning]]\\n[[Category:Free science software]]\\n[[Category:Numerical programming languages]]\\n[[Category:Python scientific libraries]]\\n\\n{{Compu-stub}}\",\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '33520809'},\n",
       " {'article': 'Torch (machine learning)',\n",
       "  'category': 'Deep learning',\n",
       "  'content': {'*': '{{Infobox software\\n| name                   = Torch\\n| logo                   = [[File:Torch 2014 logo.png|Torch logo]]\\n| screenshot             =\\n| caption                =\\n| collapsible            =\\n| author                 = Ronan Collobert, Koray Kavukcuoglu, Clement Farabet\\n| developer              =\\n| released               = {{Start date and age|df=yes|2002|October}}<ref name=\"torch-modular\">{{cite web|title=Torch: a modular machine learning software library|url=http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=CBB0C8A5FE34F6D6DAFF997F6B6A205A?doi=10.1.1.8.9850&rep=rep1&type=pdf|date=30 October 2002|accessdate=24 April 2014}}</ref>\\n| latest release version = 7.0\\n| latest release date    = {{Start date and age|2017|02|27}}<ref>{{cite web |first=Ronan|last=Collobert |title=Torch7 |url=http://torch.ch/ |website=[[GitHub]]}}</ref>\\n| latest preview version = \\n| latest preview date    = \\n| frequently updated     = <!-- DO NOT include this parameter unless you know what it does -->\\n| programming language   = [[Lua (programming language)|Lua]], [[LuaJIT]], [[C (programming language)|C]], [[CUDA]] and [[C++]]\\n| operating system       = [[Linux]], [[Android (operating system)|Android]], [[Mac OS X]], [[iOS]]\\n| platform               =\\n| size                   =\\n| language               =\\n| status                 =\\n| genre                  = Library for [[machine learning]] and [[deep learning]]\\n| license                = [[BSD License]]\\n| website                = {{url|http://torch.ch/}}\\n}}\\n\\'\\'\\'Torch\\'\\'\\' is an [[open source]] [[machine learning]] library, \\na [[scientific computing]] framework, and a [[script language]] based on the [[Lua (programming language)|Lua]] programming language.<ref name=\"nips\">{{cite journal\\n|author1=Ronan Collobert\\n|author2=Koray Kavukcuoglu\\n|author3=Clement Farabet\\n|title=Torch7: A Matlab-like Environment for Machine Learning\\n|journal=Neural Information Processing Systems\\n|year=2011\\n|url=http://ronan.collobert.com/pub/matos/2011_torch7_nipsw.pdf\\n}}</ref> It provides a wide range of algorithms for [[deep machine learning]], and uses the scripting language [[LuaJIT]], and an underlying [[C (programming language)|C]] implementation.\\n\\n== torch ==\\nThe core package of Torch is torch. It provides a flexible N-dimensional array or [[Tensor]], which supports basic routines for indexing, slicing, transposing, type-casting, resizing, sharing storage and cloning. This object is used by most other packages and thus forms the core object of the library. The Tensor also supports mathematical operations like <code>max</code>, <code>min</code>, <code>sum</code>,  statistical distributions like [[Uniform distribution (continuous)|uniform]], [[Normal distribution|normal]] and [[Multinomial distribution|multinomial]], and [[BLAS]] operations like [[dot product]], [[matrix-vector multiplication]], [[matrix multiplication|matrix-matrix multiplication]], [[matrix-vector product]] and [[matrix product]].\\n\\nThe following exemplifies using torch via its [[REPL]] interpreter:\\n<syntaxhighlight lang=\"lua\">\\n> a = torch.randn(3,4)\\n\\n> =a\\n-0.2381 -0.3401 -1.7844 -0.2615\\n 0.1411  1.6249  0.1708  0.8299\\n-1.0434  2.2291  1.0525  0.8465\\n[torch.DoubleTensor of dimension 3x4]\\n\\n> a[1][2]\\n-0.34010116549482\\n\\t\\n> a:narrow(1,1,2)\\n-0.2381 -0.3401 -1.7844 -0.2615\\n 0.1411  1.6249  0.1708  0.8299\\n[torch.DoubleTensor of dimension 2x4]\\n\\n> a:index(1, torch.LongTensor{1,2})\\n-0.2381 -0.3401 -1.7844 -0.2615\\n 0.1411  1.6249  0.1708  0.8299\\n[torch.DoubleTensor of dimension 2x4]\\n\\n> a:min()\\n-1.7844365427828\\t\\n</syntaxhighlight>\\n\\nThe torch package also simplifies [[object oriented programming]] and [[serialization]] by providing various convenience functions which are used throughout its packages. The <code>torch.class(classname, parentclass)</code> function can be used to create [[Factory method pattern|object factories]] ([[Class (computer programming)|classes]]). When the [[Constructor (object-oriented programming)|constructor]] is called, torch initializes and sets a Lua [[Lua (programming language)#Tables|table]] with the user-defined [[Lua (programming language)#Metatables|metatable]], which makes the table an [[Object (computer science)|object]].\\n\\nObjects created with the torch factory can also be serialized, as long as they do not contain references to objects that cannot be serialized, such as Lua [[coroutine]]s, and Lua \\'\\'userdata\\'\\'. However, \\'\\'userdata\\'\\' can be serialized if it is wrapped by a table (or metatable) that provides  <code>read()</code> and <code>write()</code> methods.\\n\\n== nn ==\\nThe [https://github.com/torch/nn/blob/master/README.md nn] package is used for building [[neural network]]s. It is divided into modular objects that share a common <code>Module</code> interface. Modules have a <code>forward()</code> and <code>backward()</code> method that allow them to [[Feedforward neural network|feedforward]] and [[backpropagation|backpropagate]], respectively. Modules can be joined together using module [[Composite pattern|composites]], like <code>Sequential</code>, <code>Parallel</code> and <code>Concat</code> to create complex task-tailored graphs. Simpler modules like <code>Linear</code>, <code>Tanh</code> and <code>Max</code> make up the basic component modules. This modular interface provides first-order [[Automatic differentiation|automatic gradient differentiation]]. What follows is an example use-case for building a [[multilayer perceptron]] using Modules:\\n<syntaxhighlight lang=\"lua\">\\n> mlp = nn.Sequential()\\n> mlp:add( nn.Linear(10, 25) ) -- 10 input, 25 hidden units\\n> mlp:add( nn.Tanh() ) -- some hyperbolic tangent transfer function\\n> mlp:add( nn.Linear(25, 1) ) -- 1 output\\n> =mlp:forward(torch.randn(10))\\n-0.1815\\n[torch.Tensor of dimension 1]\\n</syntaxhighlight>\\n\\n[[Loss function]]s are implemented as sub-classes of <code>Criterion</code>, which has a similar interface to <code>Module</code>. It also has <code>forward()</code> and <code>backward()</code> methods for computing the loss and backpropagating gradients, respectively. Criteria are helpful to train neural network on classical tasks. Common criteria are the [[Mean Squared Error]] criterion implemented in <code>MSECriterion</code> and the [[cross-entropy]] criterion implemented in <code>ClassNLLCriterion</code>. What follows is an example of a Lua function that can be iteratively called to train \\nan <code>mlp</code> Module on input Tensor <code>x</code>, target Tensor <code>y</code> with a scalar <code>learningRate</code>:    \\n<syntaxhighlight lang=\"lua\">\\nfunction gradUpdate(mlp,x,y,learningRate)\\n  local criterion = nn.ClassNLLCriterion()\\n  pred = mlp:forward(x)\\n  local err = criterion:forward(pred, y); \\n  mlp:zeroGradParameters();\\n  local t = criterion:backward(pred, y);\\n  mlp:backward(x, t);\\n  mlp:updateParameters(learningRate);\\nend\\n</syntaxhighlight>\\n\\nIt also has <code>StochasticGradient</code> class for training a neural network using [[Stochastic gradient descent]], although the [https://github.com/torch/optim/blob/master/README.md Optim] package provides much more options in this respect, like momentum and weight decay [[Regularization (mathematics)|regularization]].\\n\\n==Other packages==\\nMany packages other than the above official packages are used with Torch. These are listed in the [https://github.com/torch/torch7/wiki/Cheatsheet torch cheatsheet]. These extra packages provide a wide range of utilities such as parallelism, asynchronous input/output, image processing, and so on. They can be installed with [[LuaRocks]], the Lua package manager which is also included with the Torch distribution.\\n\\n==Applications==\\nTorch is used by the Facebook [[AI]] Research Group,<ref>[http://www.kdnuggets.com/2014/02/exclusive-yann-lecun-deep-learning-facebook-ai-lab.html KDnuggets Interview with Yann LeCun, Deep Learning Expert, Director of Facebook AI Lab]</ref> [[IBM]],<ref>[https://news.ycombinator.com/item?id=7928738 Hacker News]</ref> [[Yandex]]<ref>[https://www.facebook.com/yann.lecun/posts/10152077631217143?comment_id=10152089275552143&offset=0&total_comments=6 Yann Lecun\\'s Facebook Page]</ref> and the [[Idiap Research Institute]].<ref>[https://www.idiap.ch/scientific-research/resources/torch IDIAP Research Institute : Torch]</ref> Torch has been extended for use on [[Android (operating system)|Android]]<ref>[https://github.com/soumith/torch-android Torch-android GitHub repository]</ref> and [[iOS]].<ref>[https://github.com/clementfarabet/torch-ios Torch-ios GitHub repository]</ref> It has been used to build hardware implementations for data flows like those found in neural networks.<ref>[http://pub.clement.farabet.net/ecvw11.pdf NeuFlow: A Runtime Reconﬁgurable Dataﬂow Processor for Vision]</ref>\\n\\nFacebook has released a set of extension modules as open source software.<ref>{{cite web |url=https://www.wired.com/2015/01/facebook-open-sources-trove-ai-tools/ |title=Facebook Open-Sources a Trove of AI Tools |website=[[Wired (website)|Wired]] |date=16 January 2015}}</ref>\\n\\n==See also==\\n* [[Comparison of deep learning software]]\\n\\n==References==\\n{{reflist|30em}}\\n\\n==External links==\\n* {{Official website|http://torch.ch}}\\n* {{cite web |url= https://github.com/torch/torch7 |title= Torch |edition= 7 |work= Repository |publisher= GitHub }}\\n\\n{{Deep Learning Software}}\\n{{Lua programming language}}\\n\\n[[Category:Data mining and machine learning software]]\\n[[Category:Deep learning]]\\n[[Category:Free statistical software]]\\n[[Category:Lua software]]',\n",
       "   'contentformat': 'text/x-wiki',\n",
       "   'contentmodel': 'wikitext'},\n",
       "  'page_id': '42571226'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_traverse('Deep learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0/|/  0%|| 0/22 [00:05<?, ?it/s]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Look up article in Mongo Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['admin', 'local', 'my_database', 'test', 'wikipedia'], ['my_collection'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.database_names(), wiki_db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = wiki_col.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'*': '{{Multiple issues|{{refimprove|date=July 2017}}{{more footnotes|date=July 2017}}}}\\n\\n\\'\\'\\'Data exploration\\'\\'\\' is an approach similar to initial data analysis, whereby a data analyst uses visual exploration to understand what is in a dataset and the characteristics of the data, rather than through traditional data management systems<ref name=\"Foster\">[https://www.fosteropenscience.eu/sites/default/files/pdf/2933.pdf FOSTER Open Science], Overview of Data Exploration Techniques: Stratos Idreos, Olga Papaemmonouil, Surajit Chaudhuri.</ref>. These characteristics can include size or amount of data, completeness of the data, correctness of the data, possible relationships amongst data elements or files/tables in the data.\\n\\nData exploration is typically conducted using a combination of automated and manual activities.<ref name=\"Foster\" /><ref name=\"Stanford2011\">[http://vis.stanford.edu/files/2011-Wrangler-CHI.pdf Stanford.edu], 2011 Wrangler: Interactive Visual Specification of Data Transformation Scripts, Kandel, Paepcke, Hellerstein Heer.</ref> Automated activities can include data profiling or data visualization or tabular reports to give the analyst an initial view into the data and an understanding of key characteristics.\\n\\nThis is often followed by manual drill-down or filtering of the data to identify anomalies or patterns identified through the automated actions.  Data exploration can also require manual scripting and queries into the data (e.g. using languages such as SQL or R) or using Excel or similar tools to view the raw data.<ref name=\"Stanford2012\">[http://vis.stanford.edu/files/2012-EnterpriseAnalysisInterviews-VAST.pdf Stanford.edu], IEEE Visual Analytics Science & Technology (VAST), Oct 2012 Enterprise Data Analysis and Visualization: An Interview Study., Sean Kandel, Andreas Paepcke, Joseph Hellerstein, Jeffrey Heer Proc.</ref>\\n\\nAll of these activities are aimed at creating a clear mental model and understanding of the data in the mind of the analyst, and defining basic metadata (statistics, structure, relationships) for the data set that can be used in further analysis.\\n\\nOnce this initial understanding of the data is had, the data can be pruned or refined by removing unusable parts of the data, correcting poorly formatted elements and defining relevant relationships across datasets<ref name=\"Stanford2011\" />. This process is also known as determining [[data quality]]<ref name=\"Stanford2012\" />.\\n\\nAt this stage, the data can be considered ready for deeper analysis or be handed off to other analysts or users who have specific needs for the data.\\n\\nData exploration can also refer to the adhoc querying and visualization of data to identify potential relationships or insights that may be hidden in the data<ref name=\"Foster\" />.  In this scenario, hypotheses may be created and then the data is explored to identify whether those hypotheses are correct. \\n\\nTraditionally, this had been a key area of focus for statisticians, with [[John Tukey]] being a key evangelist in the field. Today, data exploration is more widespread and is the focus of data analysts and [[data scientists]]; the latter being a relatively new role within enterprises and larger organizations.\\n\\n== Interactive Data Exploration ==\\nThis area of data exploration has become an area of interest in the field of machine learning. This is a relatively new field and is still evolving.<ref name=\"Stanford2012\" />  As it’s most basic level, a machine-learning algorithm can be fed a data set and can be used to identify whether a hypothesis is true based on the dataset. Common machine learning algorithms can focus on identifying specific patterns in the data.<ref name=\"Stanford2011\" /> Common patterns include regression, classification or clustering, but there are many possible patterns and algorithms that can be applied to data via machine learning.\\n\\nBy employing machine learning, it is possible to find patterns or relationships in the data that would be difficult or impossible to find via manual inspection, trial and error or traditional exploration techniques.\\n\\n==Software==\\n* [[Trifacta]] – a data preparation and analysis platform\\n* [[Paxata]] – self-service data preparation software\\n* [[Alteryx]] – data blending and advanced data analytics software\\n* IBM Infosphere Analyzer – a data profiling tool\\n* Microsoft [[Power BI]] -  interactive visualization and data analysis tool\\n* [[OpenRefine]] -  a standalone open source desktop application for data clean-up and data transformation \\n* [[Tableau software]] – interactive data visualization software\\n\\n==See also==\\n{{Portal|Information technology}}\\n* [[Exploratory Data Analysis]]\\n* [[Machine Learning]]\\n* [[Data profiling]]\\n* [[Data Visualization]]\\n{{-}}\\n\\n== References ==\\n{{reflist}}\\n\\n[[Category:Machine learning| ]]\\n[[Category:Data analysis]]\\n[[Category:Data management]]\\n[[Category:Data quality]]',\n",
       " 'contentformat': 'text/x-wiki',\n",
       " 'contentmodel': 'wikitext'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(cursor)['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
