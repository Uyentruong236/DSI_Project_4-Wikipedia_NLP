{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is the wikipedia api call for a category search:\n",
    "\n",
    "`http://en.wikipedia.org/w/api.php?action=query&format=json&list=categorymembers&cmtitle=Category%3A+machine+learning&cmlimit=max`\n",
    "\n",
    "`action=query`: query the wikipedia api\n",
    "\n",
    "`format=json`: return a json format\n",
    "\n",
    "`list=categorymembers`: List of pages that belong to a given category, ordered by page sort title\n",
    "\n",
    "`cmtitle=Category%3A+machine+learning`: title of category\n",
    "\n",
    "`climit=max`: return up to the maximum amount of responses (500)\n",
    "\n",
    "You may use this to get page titles from the wikipedia API. Things to watch out for:\n",
    "* The responses contain categories\n",
    "* You will want to fetch articles in those subcategories\n",
    "\n",
    "The API's detailed documentation can be found [here](https://www.mediawiki.org/wiki/API:Main_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a function that formats a request for pages of a category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # use regex to replace name of category in the search string\n",
    "# #'http://en.wikipedia.org/w/api.php?action=query&format=json&list=categorymembers&cmtitle=Category%3A+machine+learning&cmlimit=max'\n",
    "# category = re.sub('\\s', '+', category) # replace spaces in category with +s so can insert into search string\n",
    "# &cmtitle=Category%3A+machine+learning&"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def category_request(category):\n",
    "    \"\"\"\n",
    "    Scrape a category page from Wikipedia API.\n",
    "    \n",
    "    Params:\n",
    "    --------\n",
    "    category: str\n",
    "        The name of the category to be scraped.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame\n",
    "        Pandas DataFrame containing categories \n",
    "        \n",
    "    \"\"\"\n",
    "    my_params = {\n",
    "        'action':'query',\n",
    "        'format':'json',\n",
    "        'list':'categorymembers',\n",
    "        'cmtitle': 'Category:{}'.format(category),\n",
    "        'cmlimit': 'max'\n",
    "        }\n",
    "    page = requests.get('http://en.wikipedia.org/w/api.php', params=my_params)\n",
    "    return pd.DataFrame(page.json()['query']['categorymembers'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_page(title):\n",
    "    \"\"\"\n",
    "    Scrape a page from Wikipedia API.\n",
    "    \n",
    "    Params:\n",
    "    --------\n",
    "    title: str\n",
    "        The name of the page to be scraped.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    List of dictionaries\n",
    "        list of the content of the page\n",
    "        \n",
    "    \"\"\"\n",
    "    my_params = {\n",
    "        'action':'query',\n",
    "        'format':'json',\n",
    "        'titles': title,\n",
    "        'prop': 'revisions',\n",
    "        'rvprop': 'content'\n",
    "    }\n",
    "    content = requests.get('http://en.wikipedia.org/w/api.php', params=my_params)\n",
    "    return list(content.json()['query']['pages'].values())[0]['revisions'][0]\n",
    "# get_page('Machine learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cats_and_pages(category):\n",
    "    \"\"\"\n",
    "    Returns the pages and subcategories of a category\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    category : str\n",
    "        Name of a category\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sub_categories: list \n",
    "        list of sub categories \n",
    "    pages: list\n",
    "        list of pages on the category\n",
    "        \n",
    "    \"\"\"\n",
    "    cats = pd.DataFrame(category_request(category))\n",
    "    cats['title'] = cats.title.astype(str) \n",
    "    #returns a boolean mask of all titles with 'category' in the str\n",
    "    subs_mask = cats['title'].str.contains('Category:')\n",
    "    \n",
    "    #creates list of new sub catagories\n",
    "    children = list(cats['title'][subs_mask].str.replace('Category:', \"\"))\n",
    "    pages = list(cats['title'][~cats.title.str.contains('Category:')])\n",
    "    return pages, children\n",
    "\n",
    "#sub_categories, pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wiki_traverse (category):\n",
    "    \"\"\" \n",
    "    Returns a list of dictionary of categories, page titles and page contents\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    category : str\n",
    "        Name of a category\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    page_content: list \n",
    "        list of dictionaries with categories, page titles and page contents \n",
    "        \n",
    "    \"\"\"\n",
    "        \n",
    "    q = []\n",
    "    q.append(category) \n",
    "\n",
    "    page_content = []\n",
    " \n",
    "    #while the q is not empty\n",
    "    while q: \n",
    "        current_node = q.pop(0) #pop the first element off the list you've created \n",
    "#         print(current_node)\n",
    "        \n",
    "        pages, children = get_cats_and_pages(current_node)\n",
    "        for child in children:\n",
    "            q.append(child)\n",
    "#         print(pages)\n",
    "     \n",
    "        for article in pages:\n",
    "            article_dict = {}\n",
    "            article_dict['category'] = current_node\n",
    "            article_dict['article'] = article\n",
    "            article_dict['content'] = get_page(article)\n",
    "            \n",
    "            page_content.append(article_dict)\n",
    "            \n",
    "    return page_content\n",
    "#     return current_node, page_content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Machine_learning = wiki_traverse('Machine learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Machine_learning = pd.DataFrame(Machine_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Machine_learning.to_csv('machine_learning_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Business_software = wiki_traverse('Business software')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
