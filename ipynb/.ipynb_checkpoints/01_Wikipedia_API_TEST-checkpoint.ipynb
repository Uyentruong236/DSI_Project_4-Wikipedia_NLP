{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import pymongo\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import pymongo\n",
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.en import English\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.en import STOP_WORDS\n",
    "from bs4 import BeautifulSoup\n",
    "nlp = English()\n",
    "stop = set(stopwords.words('english'))\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient('54.201.199.246', 27016)\n",
    "\n",
    "wiki_db = client.wikipedia\n",
    "\n",
    "wiki_col = wiki_db.my_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions to get data from Wiki API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def category_request(category):\n",
    "    \"\"\"\n",
    "    Scrape a category page from Wikipedia API.\n",
    "    \n",
    "    Params:\n",
    "    --------\n",
    "    category: str\n",
    "        The name of the category to be scraped.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame\n",
    "        Pandas DataFrame containing categories \n",
    "        \n",
    "    \"\"\"\n",
    "    my_params = {\n",
    "        'action':'query',\n",
    "        'format':'json',\n",
    "        'list':'categorymembers',\n",
    "        'cmtitle': 'Category:{}'.format(category),\n",
    "        'cmlimit': 'max'\n",
    "        }\n",
    "    page = requests.get('http://en.wikipedia.org/w/api.php', params=my_params)\n",
    "    return pd.DataFrame(page.json()['query']['categorymembers'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(title):\n",
    "    \"\"\"\n",
    "    Scrape a page from Wikipedia API to get the conecnt.\n",
    "    \n",
    "    Params:\n",
    "    --------\n",
    "    title: str\n",
    "        The name of the page to be scraped.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    List of the contents of the page\n",
    "        \n",
    "    \"\"\"\n",
    "    my_params = {\n",
    "        'action':'query',\n",
    "        'format':'json',\n",
    "        'titles': title,\n",
    "        'prop': 'revisions',\n",
    "        'rvprop': 'content'\n",
    "    }\n",
    "    content = requests.get('http://en.wikipedia.org/w/api.php', params=my_params)\n",
    "    return list(content.json()['query']['pages'].values())[0]['revisions'][0]['*']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_content('Machine_learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cats_and_pages(category):\n",
    "    \"\"\"\n",
    "    Returns the pages and subcategories of a category\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    category : str\n",
    "        Name of a category\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sub_categories: list \n",
    "        list of sub categories \n",
    "    pages: list\n",
    "        list of pages on the category\n",
    "        \n",
    "    \"\"\"\n",
    "    cats = pd.DataFrame(category_request(category))\n",
    "    cats['title'] = cats.title.astype(str) \n",
    "    #returns a boolean mask of all titles with 'category' in the str\n",
    "    subs_mask = cats['title'].str.contains('Category:')\n",
    "    \n",
    "    #creates list of new sub catagories\n",
    "    children = list(cats['title'][subs_mask].str.replace('Category:', \"\"))\n",
    "    pages = list(cats['title'][~cats.title.str.contains('Category:')])\n",
    "    page_id = list(cats['pageid'][~cats.title.str.contains('Category:')])\n",
    "    return page_id, pages, children\n",
    "\n",
    "#sub_categories, pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    text = re.sub('&#39;','',text).lower()\n",
    "    text = re.sub('<br />','',text)\n",
    "    text = re.sub('<.*>.*</.*>','', text)\n",
    "    text = re.sub('[\\d]','',text)\n",
    "    text = re.sub('[^a-z ]',' ',text)\n",
    "    text = re.sub(u'<.*>','',text)\n",
    "    text = re.sub(u'[^a-z\\s]',' ',text)\n",
    "    text = re.sub(\"\\\\s+\", \" \", text)\n",
    "    text = nlp(text)\n",
    "    text = [str(i.lemma_) for i in text if str(i.orth_) not in stop]\n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wiki_traverse(category, max_depth=-1):\n",
    "    \"\"\" \n",
    "    Returns a list of dictionary of categories, page titles and page contents\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    category : str\n",
    "        Name of a category\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    page_content: list \n",
    "        list of dictionaries with categories, page titles and page contents \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    if max_depth != 0:\n",
    "\n",
    "        page_id, pages, children = get_cats_and_pages(category)\n",
    "        \n",
    "        for index, article in enumerate(pages):    \n",
    "            article_dict = {}\n",
    "            article_dict['category'] = category\n",
    "            article_dict['article'] = article\n",
    "            article_dict['content'] = cleaner(get_content(article))\n",
    "            article_dict['page_id'] = str(page_id[index])  \n",
    "            \n",
    "            #this line adds each article onto mongo database as each article is being called \n",
    "            wiki_col.insert_one(article_dict)\n",
    "            \n",
    "            \n",
    "        for child in children:\n",
    "            wiki_traverse(child, max_depth-1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_traverse('Business software', max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " wiki_traverse('Machine learning', max_depth=3)           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5652"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_col.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = wiki_col.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5a1522b930b30c0103953a77'),\n",
       " 'article': 'AccuSystems',\n",
       " 'category': 'Business software',\n",
       " 'content': '  multiple issue orphan date february notability company date march infobox company name accusystem logo file accusystems white background png logo caption image image caption trading name b business different legal name native name company name home country language native name lang use iso code e g fr french one native name different language enter name use tl lang instead romanize former type type trade industry document imaging electronic document management document management system genre use medium publish company fate predecessor successor foundation founder defunct end date yyyy mm dd location city pueblo colorado location country united state location number location store office etc area serve key people chri gredig alan wooldridge product production service revenue operating income net income aum use financial service company asset equity owner num employee parent division subsid homepage url http www accusystem com footnote intl bodystyle accusystem llc american company headquarter pueblo colorado develop license support sell document image software electronic document management primarily banking finance industry accusystem make first sale people united bank people bank ref name chieftain accusystem software know accuaccount mainly use electronically scan store manage loan file associate paperwork september accusystem announce acquisition xtria rm accusystem banknew innovative solution award management software solution banktech publish survey take accusystem survey community bank survey find bank use paperless system issue loan reference reflist external link official website http www accusystem com category technology company establish category information technology consulting firm category software company base colorado category banking technology category document management system category business software category business software company category content management system',\n",
       " 'page_id': '41270069'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
