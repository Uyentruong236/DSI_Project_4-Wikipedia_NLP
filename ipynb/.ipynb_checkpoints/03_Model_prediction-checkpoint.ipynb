{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import pymongo\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.en import STOP_WORDS\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient('54.186.181.72', 27016)\n",
    "\n",
    "wiki_db = client.wikipedia\n",
    "\n",
    "wiki_col = wiki_db.my_collection\n",
    "\n",
    "client.database_names(), wiki_db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5654"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_col.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor = wiki_col.find()\n",
    "\n",
    "wiki_df = pd.DataFrame(list(cursor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_df.drop_duplicates(subset=['page_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models to predict categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "wiki_df['cat_numerical'] = le.fit_transform(wiki_df['main_cat'])\n",
    "\n",
    "wiki_df['cat_numerical'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>article</th>\n",
       "      <th>content</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>page_id</th>\n",
       "      <th>sub_cat</th>\n",
       "      <th>cat_numerical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a15de5730b30c01325f0260</td>\n",
       "      <td>Business software</td>\n",
       "      <td>merge enterprise software date october softw...</td>\n",
       "      <td>Business software</td>\n",
       "      <td>1037763</td>\n",
       "      <td>Business software</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a15de5830b30c01325f0261</td>\n",
       "      <td>AccuSystems</td>\n",
       "      <td>multiple issue orphan date february notabili...</td>\n",
       "      <td>Business software</td>\n",
       "      <td>41270069</td>\n",
       "      <td>Business software</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a15de5830b30c01325f0262</td>\n",
       "      <td>Active policy management</td>\n",
       "      <td>active policy management business orient ent...</td>\n",
       "      <td>Business software</td>\n",
       "      <td>5211212</td>\n",
       "      <td>Business software</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a15de5830b30c01325f0263</td>\n",
       "      <td>Alexandria (library software)</td>\n",
       "      <td>use alexandria alexandria browser base softw...</td>\n",
       "      <td>Business software</td>\n",
       "      <td>28502793</td>\n",
       "      <td>Business software</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a15de5930b30c01325f0264</td>\n",
       "      <td>Alteryx</td>\n",
       "      <td>infobox company name alteryx logo file alter...</td>\n",
       "      <td>Business software</td>\n",
       "      <td>44133735</td>\n",
       "      <td>Business software</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                        article  \\\n",
       "0  5a15de5730b30c01325f0260              Business software   \n",
       "1  5a15de5830b30c01325f0261                    AccuSystems   \n",
       "2  5a15de5830b30c01325f0262       Active policy management   \n",
       "3  5a15de5830b30c01325f0263  Alexandria (library software)   \n",
       "4  5a15de5930b30c01325f0264                        Alteryx   \n",
       "\n",
       "                                             content           main_cat  \\\n",
       "0    merge enterprise software date october softw...  Business software   \n",
       "1    multiple issue orphan date february notabili...  Business software   \n",
       "2    active policy management business orient ent...  Business software   \n",
       "3    use alexandria alexandria browser base softw...  Business software   \n",
       "4    infobox company name alteryx logo file alter...  Business software   \n",
       "\n",
       "    page_id            sub_cat  cat_numerical  \n",
       "0   1037763  Business software              0  \n",
       "1  41270069  Business software              0  \n",
       "2   5211212  Business software              0  \n",
       "3  28502793  Business software              0  \n",
       "4  44133735  Business software              0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GS Pipeline with LogisticRegression to predict category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=42, test_size=0.1,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "   ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'vec__ngram_range': [(1, 2)], 'vec__min_df': [10, 30], 'svd__n_components': [100, 300, 500], 'clf__C': array([  1.00000e-02,   1.00000e-01,   1.00000e+00,   1.00000e+01,\n",
       "         1.00000e+02,   1.00000e+03,   1.00000e+04])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = wiki_df['content']\n",
    "y = wiki_df['cat_numerical']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 42)\n",
    "\n",
    "nlp_pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer()),\n",
    "    ('svd', TruncatedSVD()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'vec__ngram_range':[(1,2)],\n",
    "    'vec__min_df':[10,30],\n",
    "    'svd__n_components':[100,300,500],\n",
    "    'clf__C': np.logspace(-2,4,7)\n",
    "}\n",
    "\n",
    "nlp_gs = GridSearchCV(nlp_pipe, \n",
    "                      params, \n",
    "                      cv=StratifiedShuffleSplit(5, random_state=42))\n",
    "\n",
    "nlp_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_gs = nlp_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lr_gs.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr_gs, 'lr_gs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98164251207729469"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_eval(model, X_test, y_test):\n",
    "    preds = model.predict(X_test)\n",
    "    return {\n",
    "        'roc_auc': roc_auc_score(y_test, preds),\n",
    "        'accuracy': accuracy_score(y_test, preds),\n",
    "        'confmat': confusion_matrix(y_test, preds),\n",
    "        'clf_rep': classification_report(y_test, preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "roc_auc\n",
      "0.972970798221\n",
      "------------------------------------------------------------\n",
      "accuracy\n",
      "0.981642512077\n",
      "------------------------------------------------------------\n",
      "confmat\n",
      "[[761   7]\n",
      " [ 12 255]]\n",
      "------------------------------------------------------------\n",
      "clf_rep\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99       768\n",
      "          1       0.97      0.96      0.96       267\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1035\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = score_eval(nlp_gs, X_test, y_test)\n",
    "\n",
    "print('-'*60)\n",
    "for key, value in results.items():\n",
    "    print(key)\n",
    "    print(value)\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_category(source_test, model):\n",
    "    source_test = [source_test]\n",
    "   \n",
    "    predicted = model.predict(source_test)\n",
    "    predicted_probas = model.predict_proba(source_test)\n",
    "\n",
    "    return predicted, predicted_probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), array([[ 0.1949794,  0.8050206]]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 refers to Business Software and 1 refers to Maching Learning \n",
    "predict_category('Each row of the matrix represents the instances in a predicted class', lr_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GS Pipeline with BernoulliNB to predict category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=42, test_size=0.1,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "   ... vocabulary=None)), ('clf', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'vec__min_df': [10, 30]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = wiki_df['content']\n",
    "y = wiki_df['cat_numerical']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 42)\n",
    "\n",
    "nlp_pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer()), \n",
    "    ('clf', BernoulliNB())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'vec__min_df':[10,30],\n",
    "}\n",
    "\n",
    "nlp_bayes_gs = GridSearchCV(nlp_pipe, \n",
    "                      params, \n",
    "                      cv=StratifiedShuffleSplit(5, random_state=42))\n",
    "\n",
    "nlp_bayes_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes_gs = nlp_bayes_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ... vocabulary=None)), ('clf', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_bayes_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95072463768115945"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_bayes_gs.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "roc_auc\n",
      "0.924040262172\n",
      "------------------------------------------------------------\n",
      "accuracy\n",
      "0.950724637681\n",
      "------------------------------------------------------------\n",
      "confmat\n",
      "[[752  16]\n",
      " [ 35 232]]\n",
      "------------------------------------------------------------\n",
      "clf_rep\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97       768\n",
      "          1       0.94      0.87      0.90       267\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1035\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "bayes_results = score_eval(nlp_bayes_gs, X_test, y_test)\n",
    "\n",
    "print('-'*60)\n",
    "for key, value in bayes_results.items():\n",
    "    print(key)\n",
    "    print(value)\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nlp_bayes_gs.pkl']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(bayes_gs, 'nlp_bayes_gs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]), array([[  9.99999993e-01,   6.52289238e-09]]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_category(' It focused on distributed deep learning by partitioning the model\\\n",
    "and data onto nodes in a cluster and parallelize the training', bayes_gs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
