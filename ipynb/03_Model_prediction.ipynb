{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import pymongo\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient('54.201.199.246', 27016)\n",
    "\n",
    "wiki_db = client.wikipedia\n",
    "\n",
    "wiki_col = wiki_db.my_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['admin', 'local', 'my_database', 'test', 'wikipedia'], ['my_collection'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.database_names(), wiki_db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5654"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_col.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = wiki_col.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df = pd.DataFrame(list(cursor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df.drop_duplicates(subset=['page_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models to predict categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "wiki_df['cat_numerical'] = le.fit_transform(wiki_df['main_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3052\n",
       "1    1087\n",
       "Name: cat_numerical, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df['cat_numerical'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=42, test_size=0.1,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "   ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'vec__ngram_range': [(1, 2)], 'vec__min_df': [10, 30], 'svd__n_components': [100, 300, 500], 'clf__C': array([  1.00000e-02,   1.00000e-01,   1.00000e+00,   1.00000e+01,\n",
       "         1.00000e+02,   1.00000e+03,   1.00000e+04])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = wiki_df['content']\n",
    "y = wiki_df['cat_numerical']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 42)\n",
    "\n",
    "nlp_pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer()),\n",
    "#     ('scaler', StandardScaler(with_mean=False)), try with and without scaler and tell Sylvia\n",
    "    #add SVD to decrease dimensionality \n",
    "    #experiment with Bayes \n",
    "    ('svd', TruncatedSVD()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'vec__ngram_range':[(1,2)],#don't need up to 4, too much \n",
    "    'vec__min_df':[10,30],\n",
    "    'svd__n_components':[100,300,500],\n",
    "    'clf__C': np.logspace(-2,4,7)\n",
    "}\n",
    "\n",
    "nlp_gs = GridSearchCV(nlp_pipe, \n",
    "                      params, \n",
    "                      cv=StratifiedShuffleSplit(5, random_state=42))\n",
    "\n",
    "nlp_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 10000.0,\n",
       " 'svd__n_components': 300,\n",
       " 'vec__min_df': 10,\n",
       " 'vec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99163987138263665"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97971014492753628"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_eval(model, X_test, y_test):\n",
    "    preds = model.predict(X_test)\n",
    "    return {\n",
    "        'roc_auc': roc_auc_score(y_test, preds),\n",
    "        'accuracy': accuracy_score(y_test, preds),\n",
    "        'confmat': confusion_matrix(y_test, preds),\n",
    "        'clf_rep': classification_report(y_test, preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "roc_auc\n",
      "0.971668714888\n",
      "------------------------------------------------------------\n",
      "accuracy\n",
      "0.979710144928\n",
      "------------------------------------------------------------\n",
      "confmat\n",
      "[[759   9]\n",
      " [ 12 255]]\n",
      "------------------------------------------------------------\n",
      "clf_rep\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99       768\n",
      "          1       0.97      0.96      0.96       267\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1035\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = score_eval(nlp_gs, X_test, y_test)\n",
    "\n",
    "print('-'*60)\n",
    "for key, value in results.items():\n",
    "    print(key)\n",
    "    print(value)\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "\n",
    "nbayes = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=5, random_state=42, test_size=0.1,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "   ...te=None, tol=0.0)), ('clf', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'vec__min_df': [10, 30], 'svd__n_components': [100, 300, 500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = wiki_df['content']\n",
    "y = wiki_df['cat_numerical']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 42)\n",
    "\n",
    "nlp_pipe = Pipeline([\n",
    "    ('vec', TfidfVectorizer()),\n",
    "#     ('scaler', StandardScaler(with_mean=False)), try with and without scaler and tell Sylvia\n",
    "    #add SVD to decrease dimensionality \n",
    "    #experiment with Bayes \n",
    "    ('svd', TruncatedSVD()),\n",
    "    ('clf', BernoulliNB())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'vec__min_df':[10,30],\n",
    "    'svd__n_components':[100,300,500],\n",
    "}\n",
    "\n",
    "nlp_bayes_gs = GridSearchCV(nlp_pipe, \n",
    "                      params, \n",
    "                      cv=StratifiedShuffleSplit(5, random_state=42))\n",
    "\n",
    "nlp_bayes_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9198067632850242"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_bayes_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "roc_auc\n",
      "0.88243943118\n",
      "------------------------------------------------------------\n",
      "accuracy\n",
      "0.919806763285\n",
      "------------------------------------------------------------\n",
      "confmat\n",
      "[[737  31]\n",
      " [ 52 215]]\n",
      "------------------------------------------------------------\n",
      "clf_rep\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.96      0.95       768\n",
      "          1       0.87      0.81      0.84       267\n",
      "\n",
      "avg / total       0.92      0.92      0.92      1035\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "bayes_results = score_eval(nlp_bayes_gs, X_test, y_test)\n",
    "\n",
    "print('-'*60)\n",
    "for key, value in bayes_results.items():\n",
    "    print(key)\n",
    "    print(value)\n",
    "    print('-'*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
